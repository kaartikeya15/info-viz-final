Professor Name,Professor Link,Research Interests,Paper Name,Description
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Finding frequent items in data streams,"We present a 1-pass algorithm for estimating the most frequent items in a data stream using very limited storage space. Our method relies on a novel data structure called a count sketch, which allows us to estimate the frequencies of all the items in the stream. Our algorithm achieves better space bounds than the previous best known algorithms for this problem for many natural distributions on the item frequencies. In addition, our algorithm leads directly to a 2-pass algorithm for the problem of estimating the items with the largest (absolute) change in frequency between two data streams. To our knowledge, this problem has not been previously studied in the literature."
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",The LCA problem revisited,"We present a very simple algorithm for the Least Common Ancestors problem. We thus dispel the frequently held notion that optimal LCA computation is unwieldy and unimplementable. Interestingly, this algorithm is a sequentialization of a previously known PRAM algorithm."
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Optimal suffix tree construction with large alphabets,Description not available
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Finding frequent items in data streams,Description not available
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",NOTUNG: a program for dating gene duplications and optimizing gene family trees,"Large scale gene duplication is a major force driving the evolution of genetic functional innovation. Whole genome duplications are widely believed to have played an important role in the evolution of the maize, yeast, and vertebrate genomes. The use of evolutionary trees to analyze the history of gene duplication and estimate duplication times provides a powerful tool for studying this process. Many studies in the molecular evolution literature have used this approach on small data sets, using analyses performed by hand. The rapid growth of genetic sequence data will soon allow similar studies on a genomic scale, but such studies will be limited unless the analysis can be automated. Even existing data sets admit alternative hypotheses that would be too tedious to consider without automation. In this paper, we describe a program called NOTUNG that facilitates large scale analysis, using both …"
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Lowest common ancestors in trees and directed acyclic graphs,Description not available
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Let sleeping files lie: Pattern matching in Z-compressed files,Description not available
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Don't thrash: How to cache your hash on flash,"Many large storage systems use approximatemembership-query (AMQ) data structures to deal with the massive amounts of data that they process. An AMQ data structure is a dictionary that trades off space for a false positive rate on membership queries. It is designed to fit into small, fast storage, and it is used to avoid I/Os on slow storage. The Bloom filter is a well-known example of an AMQ data structure. Bloom filters, however, do not scale outside of main memory. This paper describes the Cascade Filter, an AMQ data structure that scales beyond main memory, supporting over half a million insertions/deletions per second and over 500 lookups per second on a commodity flashbased SSD."
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",On the sorting-complexity of suffix tree construction,"The suffix tree of a string is the fundamental data structure of combinatorial pattern matching. We present a recursive technique for building suffix trees that yields optimal algorithms in different computational models. Sorting is an inherent bottleneck in building suffix trees and our algorithms match the sorting lower bound. Specifically, we present the following results. (1) Weiner [1973], who introduced the data structure, gave an optimal 0(n)-time algorithm for building the suffix tree of an n-character string drawn from a constant-size alphabet. In the comparison model, there is a trivial Ο(n log n)-time lower bound based on sorting, and Weiner's algorithm matches this bound. For integer alphabets, the fastest known algorithm is the O(n log n)time comparison-based algorithm, but no super-linear lower bound is known. Closing this gap is the main open question in stringology. We settle this open problem by giving a …"
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",String matching in Lempel-Ziv compressed strings,"String matching and Compression are two widely studied areas of computer science. The theory of string matching has a long association with compression algorithms. Data structures from string matching can be used to derive fast implementations of many important compression schemes, most notably the Lempel-Ziv(LZ1) algorithm. Intuitively, once a string has been compressed–and therefore its repetitive nature has been elucidated—one might be tempted to exploit this knowledge to speed up string matching. The Compressed Matching Problem is that of performing string matching in a compressed text, without uncompressing it. More formally, let ‘T be a text, let Z be the compressed string representing T, and let ‘P be a pattern. The Compressed Matching Problem is that of deciding if P occurs in T, given only P and Z. Compressed matching algorithms have been given for several compression schemes, such as …"
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Cache-oblivious B-trees,Description not available
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",High-performance streaming dictionary,"A method, apparatus and computer program product for storing data in a disk storage system is presented. A high-performance dictionary data structure is defined. The dictionary data structure is stored on a disk storage system. Key-value pairs can be inserted and deleted into the dictionary data structure. Updates run faster than one insertion per disk-head movement. The structure can also be stored on any system with two or more levels of memory. The dictionary is high performance and supports with full transactional semantics, concurrent access from multiple transactions, and logging and recovery. Keys can be looked up with only a logarithmic number of transfers, even for keys that have been recently inserted or deleted. Queries can be performed on ranges of key-value pairs, including recently inserted or deleted pairs, at a constant fraction of the bandwidth of the disk."
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",The level ancestor problem simplified,Description not available
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",On the approximability of numerical taxonomy (fitting distances by tree metrics),"We consider the problem of fitting an n × n distance matrix D by a tree metric T. Let be the distance to the closest tree metric under the norm; that is, . First we present an O(n2 ) algorithm for finding a tree metric T such that . Second we show that it is -hard to find a tree metric T such that . This paper presents the first algorithm for this problem with a performance guarantee."
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",A robust model for finding optimal evolutionary trees,"Constructing evolutionary trees for species sets is a fundamental problem in computational biology. One of the standard models assumes the ability to compute distances between every pair of species and seeks to find an edge-weighted tree T in which the distance@ j in the tree between the leaves of T corresponding to the species i and j fits the observed distance, dij. Sometimes the desired tree is ultrarnetric, so that the tree can be rooted with the root equidistant to each leaf. Many measures for evaluating the “fit” between a distance function d and the path-distance# have been proposed, and most such measures have resulted in NP-hard optimization problems, In this paper we propose a measure of fit which models the inaccuracy in the data, and present several problems for constructing additive and ultrametric trees using this measure, Many of the resultant optimization problems are NP-hard, and one (finding …"
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Two simplified algorithms for maintaining order in a list,"In the Order-Maintenance Problem, the objective is to maintain a total order subject to insertions, deletions, and precedence queries. Known optimal solutions, due to Dietz and Sleator, are complicated. We present new algorithms that match the bounds of Dietz and Sleator. Our solutions are simple, and we present experimental evidence that suggests that they are superior in practice."
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Cache-oblivious streaming B-trees,"A streaming B-tree is a dictionary that efficiently implements insertions and range queries. We present two cache-oblivious streaming B-trees, the shuttle tree, and the cache-oblivious lookahead array (COLA)."
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Cache-oblivious B-trees,"This paper presents two dynamic search trees attaining near-optimal performance on any hierarchical memory. The data structures are independent of the parameters of the memory hierarchy, e.g., the number of memory levels, the block-transfer size at each level, and the relative speeds of memory levels. The performance is analyzed in terms of the number of memory transfers between two memory levels with an arbitrary block-transfer size of B; this analysis can then be applied to every adjacent pair of levels in a multilevel memory hierarchy. Both search trees match the optimal search bound of memory transfers. This bound is also achieved by the classic B-tree data structure on a two-level memory hierarchy with a known block-transfer size B. The first search tree supports insertions and deletions in amortized memory transfers, which matches the B-tree's worst-case bounds. The second search …"
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",{BetrFS}: A {Right-Optimized}{Write-Optimized} file system,"The B ε-tree File System, or BetrFS,(pronounced “better eff ess”) is the first in-kernel file system to use a write-optimized index. Write optimized indexes (WOIs) are promising building blocks for storage systems because of their potential to implement both microwrites and large scans efficiently."
Martin Farach-Colton,https://scholar.google.com/citations?user=2uHUSa8AAAAJ&hl=en&oi=ao,"Algorithms, Data Structures, External Memory, Storage Systems",Optimal superprimitivity testing for strings,"A string w covers another string z if every position of z is within some occurrence of w in z. Clearly, every string is covered by itself. A string that is covered only by itself is superprimitive. We show that the property of being superprimitive is testable on a string of n symbols in O(n) time and space."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Minkowski-type theorems and least-squares clustering,"Dissecting Euclidean d -space with the power diagram of n weighted point sites partitions a given m -point set into clusters, one cluster for each region of the diagram. In this manner, an assignment of points to sites is induced. We show the equivalence of such assignments to constrained Euclidean least-squares assignments. As a corollary, there always exists a power diagram whose regions partition a given d -dimensional m -point set into clusters of prescribed sizes, no matter where the sites are placed. Another consequence is that constrained least-squares assignments can be computed by finding suitable weights for the sites. In the plane, this takes roughly O(n 2 m) time and optimal space O(m) , which improves on previous methods. We further show that a constrained least-squares assignment can be computed by solving a specially structured linear program in n+1 dimensions …"
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms","Fréchet distance for curves, revisited","We revisit the problem of computing the Fréchet distance between polygonal curves, focusing on the discrete Fréchet distance, where only distance between vertices is considered. We develop efficient approximation algorithms for two natural classes of curves: κ-bounded curves and backbone curves, the latter of which are widely used to model molecular structures. We also propose a pseudo–output-sensitive algorithm for computing the discrete Fréchet distance exactly. The complexity of the algorithm is a function of the complexity of the free-space boundary, which is quadratic in the worst case, but tends to be lower in practice."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Small-size ε-nets for axis-parallel rectangles and boxes,"We show the existence of ε-nets of size O(1/ε log log 1/ε) for planar point sets and axis-parallel rectangular ranges. The same bound holds for points in the plane with ""fat"" triangular ranges, and for point sets in reals3 and axis-parallel boxes; these are the first known non-trivial bounds for these range spaces. Our technique also yields improved bounds on the size of ε-nets in the more general context considered by Clarkson and Varadarajan. For example, we show the existence of ε-nets of size"
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",On approximating the depth and related problems,"We study the question of finding a deepest point in an arrangement of regions and provide a fast algorithm for this problem using random sampling, showing it sufficient to solve this problem when the deepest point is shallow. This implies, among other results, a fast algorithm for approximately solving linear programming problems with violations. We also use this technique to approximate the disk covering the largest number of red points, while avoiding all the blue points, given two such sets in the plane. Using similar techniques implies that approximate range counting queries have roughly the same time and space complexity as emptiness range queries."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Quasi-planar graphs have a linear number of edges,A graph is calledquasi-planar if it can be drawn in the plane so that no three of its edges are pairwise crossing. It is shown that the maximum number of edges of a quasi-planar graph withn vertices isO(n).
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",On compatible triangulations of simple polygons,"It is well known that, given two simple n-sided polygons, it may not be possible to triangulate the two polygons in a compatible fashion, if one's choice of triangulation vertices is restricted to polygon corners. Is it always possible to produce compatible triangulations if additional vertices inside the polygon are allowed? We give a positive answer and construct a pair of such triangulations with O(n2) new triangulation vertices. Moreover, we show that there exists a ‘universal’ way of triangulating an n-sided polygon with O(n2) extra triangulation vertices. Finally, we also show that creating compatible triangulations requires a quadratic number of extra vertices in the worst case."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Star unfolding of a polytope with applications,"We introduce the notion of a star unfolding of the surface of a three-dimensional convex polytope with n vertices, and use it to solve several problems related to shortest paths on ."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",On the geodesic Voronoi diagram of point sites in a simple polygon,"Given a simple polygon with n sides in the plane and a set of k point “sites” in its interior or on the boundary, compute the Voronol diagram of the set of sites using the internal “geodesic” distance inside the polygon as the metric. We describe an Ο((n+k) log2(n+k)) time algorithm for solving this problem and sketch a faster Ο((n+k) log(n+k)) algorithm for the case when the set of sites includes all reflex vertices of the polygon in question."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms","On levels in arrangements of lines, segments, planes, and triangles","We consider the problem of bounding the complexity of the k-th level in an arrangement of n curves or surfaces, a problem dual to, and extending, the well-known k-set problem.(a) We review sad simplifi some old proofs in new dwguise and give new proofs of the bound O (n~) for the complexity of the k-th level in an arrangement of n lines.(b) We derive an improved version of Lcn% azLemma in any dimension, and use it to prove a new bound, 0 (n2k2/3), on the complexity of the k-th level in an mangement of n planes in lR3, or on the number of k-sets in a set of n points in three dimensions.(c) We show that the complexity of any single level in an arrangement of n line segments in the plane is O (n312), and that the complexity of any single level in an arrangement of n triangles in 3-space is O (n17’6)."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Nearest-neighbor searching under uncertainty II,"Nearest-neighbor search, which returns the nearest neighbor of a query point in a set of points, is an important and widely studied problem in many fields, and it has a wide range of applications. In many of them, such as sensor databases, location-based services, face recognition, and mobile data, the location of data is imprecise. We therefore study nearest-neighbor queries in a probabilistic framework in which the location of each input point is specified as a probability distribution function. We present efficient algorithms for (i) computing all points that are nearest neighbors of a query point with nonzero probability and (ii) estimating the probability of a point being the nearest neighbor of a query point, either exactly or within a specified additive error."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Nonoverlap of the star unfolding,"A new way of organizing the set of all shortest paths from a fixed point z on the surface P of a (convex) polytope was introduced by Agarwal et al in [AAOS90] and by Chen and Han in [CH90], independently and simultaneously. The main idea already appears in Aleksandrov’s work forty years ago, although he uses it only to show that P can be triangulated. 1 We will follow[AAOS90] and refer to this structure as the star unfolding of a polytope, so called because of the“star-like” appearance of the planar unfolding of the paths. 2 The star unfolding may be obtained by cutting the polytope along the shortest paths from z to each vertex of P, and flattening the surface on the plane. The star unfolding contrasts with the source unjcdding [SS86], which simply lays out all shortest paths around the source z. In comparison, the star unfolding arranges the paths around their destinations, the ends opposite z. These notions will be …"
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Triangles in space or building (and analyzing) castles in the air,"We show that the combinatorial complexity of all non-convex cells in an arrangement of n (possibly intersecting) triangles in 3-space is Ο(n7/3+δ), for any δ>0, and that this bound is almost tight in the worst case. Our bound significantly improves a previous nearly cubic bound of Pach and Sharir. We also present a (nearly) worst-case optimal randomized algorithm for calculating a single cell of the arrangement, analyze some special cases of the problem where improved bounds (and better algorithms) can be obtained, and describe applications of our results to translational motion planning for polyhedra in 3-space."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Computing envelopes in four dimensions with applications,"Let F be a collection of n d-variate, possibly partially defined, functions, all algebraic of some constant maximum degree. We present a randomized algorithm that computes the vertices, edges, and 2-faces of the lower envelope (i.e., pointwise minimum) of F in expected time O(nd+ϵ), for any ϵ>0. For d=3, by combining this algorithm with the point location technique of Preparata and Tamassia, we can compute, in randomized expected time O(n3+ϵ) for any ϵ>0, a data structure of size O(n3+ϵ) that, given any query point q, can determine in O(log2n) time whether q lies above, below or on the envelope. As a consequence, we obtain improved algorithmic solutions to many problems in computational geometry, including (a) computing the width of a point set in 3-space, (b) computing the biggest stick in a simple polygon in the plane, and (c) computing the smallest-width annulus covering a planar point set. The …"
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Selecting distances in the plane,"We describe a randomized algorithm for computing the kth smallest distance in a set of n points in the plane, based on the parametric search technique of Megiddo [Me1]. The expected running time of our algorithm is Ο(n4/3 log 8/3 n). A deterministic version of our procedure runs in time Ο(n3/2 log5/2 n). Both versions improve the previously best known upper bound of Ο(n9/5 log4/5 n) by Chazelle [Ch]. A simple Ο(n log n) time algorithm for computing an approximation of the median distance is also presented."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Can visibility graphs be represented compactly?,"We consider the problem of representing the visibility graph of line segments as a union of cliques and bipartite cliques. Given a graph G, a family G={G1,G2,...,Gk} is called a clique cover of G if (i) each Gi is a clique or a bipartite clique, and (ii) the union of Gi is G. The size of the clique cover G is defined as Σki=1 ni, where ni is the number of vertices in Gi. Our main result is that there exist visibility graphs of n nonintersecting line segments in the plane whose smallest clique cover has size Ω(n2/log2n. An upper bound of 0(n2/log n) on the clique cover follows from a well-known result in extremal graph theory. On the other hand, we show that the visibility graph of a simple polygon always admits a clique cover of size O(n log3 n), and that there are simple polygons whose visibility graphs require a clique cover of size Ω(n log n)."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Crossing families,"Given n points in the plane, a crossing family is a collection of line segments, each joining two of the points, such that any two line segments intersect internally. We show that any n points in general position possess a crossing family of size at least~, and describe an O (n log n)-time algorithm for finding one."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Line transversals of balls and smallest enclosing cylinders in three dimensions,"We establish a near-cubic upper bound on the complexity of the space of line transversals of a collection of n balls in three dimensions, and show that the bound is almost tight, in the worst case. We apply this bound to obtain a near-cubic algorithm for computing a smallest infinite cylinder enclosing a given set of points or balls in 3-space. We also present an approximation algorithm for computing a smallest enclosing cylinder."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",On the zone of a surface in a hyperplane arrangement,"LetH be a collection ofn hyperplanes in ℝ d , letA denote the arrangement ofH, and let σ be a (d−1)-dimensional algebraic surface of low degree, or the boundary of a convex set in ℝ d . Thezone of σ inA is the collection of cells ofA crossed by σ. We show that the total number of faces bounding the cells of the zone of σ isO(n d−1 logn). More generally, if σ has dimensionp, 0≤p<d, this quantity isO(n [(d+p)/2]) ford−p even andO(n [(d+p)/2] logn) ford−p odd. These bounds are tight within a logarithmic factor."
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Points and triangles in the plane and halving planes in space,We prove that for any set S of n points in the plane and n3-α triangles spanned by the points of S there exists a point (not necessarily of S) contained in at least n3-3α/(512 log5 n) of the triangles. This implies that any set of n points in three-dimensional space defines at most 6.4n8/3 log5/3 n halving planes.
Boris Aronov,https://scholar.google.com/citations?user=q82gOawAAAAJ&hl=en,"Computational Geometry, Combinatorial Geometry, Discrete Geometry, Algorithms",Motion planning for multiple robots,"11’~ study the motion-planning problem for pairs and tripIes of robots operating in a shared workspace containing n obstacles. A standard way to solve such problems is to view the collection of robots as one composite robot, whose number of degrees of freedom is d, bhe sum of Bhe numbers of dcgrrcs of freedom of t. he individual robots. We shorn that, it is sufficient to consider a constant number of robot systcms whose number of degrees of freedom is at most (I-1 for pairs of robots, and d-2 for t. riples.(For triples: ve need to assume that a solution with positive clearance esists.) R7e use this to obtain an O (nd) time algorithm to solve the motion-planning problem for a pair of robots; t. his is one order of magnitude faster t. han what the standard method would give. For a triple of robots the running t, irne bl; comes O (nd-‘), v&i h. t c 1s mo orders of magnitude faster than the standard method. We also apply our method …"
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Deep convolutional neural networks and data augmentation for environmental sound classification,Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",A dataset and taxonomy for urban sound research,"Automatic urban sound classification is a growing area of research with applications in multimedia retrieval and urban informatics. In this paper we identify two main barriers to research in this area - the lack of a common taxonomy and the scarceness of large, real-world, annotated data. To address these issues we present a taxonomy of urban sounds and a new dataset, UrbanSound, containing 27 hours of audio with 18.5 hours of annotated sound event occurrences across 10 sound classes. The challenges presented by the new dataset are studied through a series of experiments using a baseline classification system."
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",A tutorial on onset detection in music signals,Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Medleydb: A multitrack dataset for annotation-intensive mir research.,"We introduce MedleyDB: a dataset of annotated, royaltyfree multitrack recordings. The dataset was primarily developed to support research on melody extraction, addressing important shortcomings of existing collections. For each song we provide melody f0 annotations as well as instrument activations for evaluating automatic instrument recognition. The dataset is also useful for research on tasks that require access to the individual tracks of a song such as source separation and automatic mixing. In this paper we provide a detailed description of MedleyDB, including curation, annotation, and musical content. To gain insight into the new challenges presented by the dataset, we run a set of experiments using a state-of-the-art melody extraction algorithm and discuss the results. The dataset is shown to be considerably more challenging than the current test sets used in the MIREX evaluation campaign, thus opening new research avenues in melody extraction research."
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Crepe: A convolutional representation for pitch estimation,Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing","Look, listen, and learn more: Design choices for deep audio embeddings",Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",A Robust Mid-Level Representation for Harmonic Content in Music Signals.,"When considering the problem of audio-to-audio matching, determining musical similarity using low-level features such as Fourier transforms and MFCCs is an extremely difficult task, as there is little semantic information available. Full semantic transcription of audio is an unreliable and imperfect task in the best case, an unsolved problem in the worst. To this end we propose a robust mid-level representation that incorporates both harmonic and rhythmic information, without attempting full transcription. We describe a process for creating this representation automatically, directly from multi-timbral and polyphonic music signals, with an emphasis on popular music. We also offer various evaluations of our techniques. Moreso than most approaches working from raw audio, we incorporate musical knowledge into our assumptions, our models, and our processes. Our hope is that by utilizing this notion of a musically-motivated mid-level representation we may help bridge the gap between symbolic and audio research."
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing","Sonyc: A system for monitoring, analyzing, and mitigating urban noise pollution","SONYC integrates sensors, machine listening, data analytics, and citizen science to address noise pollution in New York City."
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Deep Salience Representations for F0 Estimation in Polyphonic Music.,Background
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Unsupervised feature learning for urban sound classification,Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",On the use of phase and energy for musical onset detection in the complex domain,Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Scaper: A library for soundscape synthesis and augmentation,Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Wav2clip: Learning robust audio representations from clip,Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Complex domain onset detection for musical signals,We present a novel method for onset detection in musical signals. It improves over previous energy-based and phase-based approaches by combining both types of information in the complex domain. It generates a detection function that is sharp at the position of onsets and smooth everywhere else. Results on a handlabelled data-set show that high detection rates can be achieved at very low error rates. The approach is more robust than its predecessors both theoretically and practically.
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Moving beyond feature design: Deep architectures and automatic feature learning in music informatics.,"The short history of content-based music informatics research is dominated by hand-crafted feature design, and our community has grown admittedly complacent with a few de facto standards. Despite commendable progress in many areas, it is increasingly apparent that our efforts are yielding diminishing returns. This deceleration is largely due to the tandem of heuristic feature design and shallow processing architectures. We systematically discard hopefully irrelevant information while simultaneously calling upon creativity, intuition, or sheer luck to craft useful representations, gradually evolving complex, carefully tuned systems to address specific tasks. While other disciplines have seen the benefits of deep learning, it has only recently started to be explored in our field. By reviewing deep architectures and feature learning, we hope to raise awareness in our community about alternative approaches to solving MIR challenges, new and old alike."
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Adaptive pooling operators for weakly labeled sound event detection,Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",A software framework for musical data augmentation.,"Predictive models for music annotation tasks are practically limited by a paucity of well-annotated training data. In the broader context of large-scale machine learning, the concept of “data augmentation”—supplementing a training set with carefully perturbed samples—has emerged as an important component of robust systems. In this work, we develop a general software framework for augmenting annotated musical datasets, which will allow practitioners to easily expand training sets with musically motivated perturbations of both audio and annotations. As a proof of concept, we investigate the effects of data augmentation on the task of recognizing instruments in mixed signals."
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",The implementation of low-cost urban acoustic monitoring devices,"The urban sound environment of New York City (NYC) can be, amongst other things: loud, intrusive, exciting and dynamic. As indicated by the large majority of noise complaints registered with the NYC 311 information/complaints line, the urban sound environment has a profound effect on the quality of life of the city’s inhabitants. To monitor and ultimately understand these sonic environments, a process of long-term acoustic measurement and analysis is required. The traditional method of environmental acoustic monitoring utilizes short term measurement periods using expensive equipment, setup and operated by experienced and costly personnel. In this paper a different approach is proposed to this application which implements a smart, low-cost, static, acoustic sensing device based around consumer hardware. These devices can be deployed in numerous and varied urban locations for long periods of time …"
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Computer-aided melody note transcription using the Tony software: Accuracy and efficiency,Description not available
Juan P Bello,https://scholar.google.com/citations?user=PMHXcoAAAAAJ&hl=en,"Music Information Retrieval, Machine Listening, Audio Signal Processing",Rethinking automatic chord recognition with convolutional neural networks,Description not available
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Faster fully dynamic matchings with small approximation ratios,"Maximum cardinality matching is a fundamental algorithmic problem with many algorithms and applications. The fully dynamic version, in which edges are inserted and deleted over time has also been the subject of much attention. Existing algorithms for dynamic matching (in general n-vertex m-edge graphs) fall into two groups: there are fast (mostly randomized) algorithms that achieve a 2-approximation or worse, and there are slow algorithms with update time that achieve a better-than-2 approximation. Thus the obvious question is whether we can design an algorithm that achieves a tradeoff between these two: a update time and a better-than-2 approximation simultaneously. We answer this question in the affirmative. Previously, such bounds were only known for the special case of bipartite graphs."
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Coresets meet EDCS: algorithms for matching and vertex cover on massive graphs,"There is a rapidly growing need for scalable algorithms that solve classical graph problems, such as maximum matching and minimum vertex cover, on massive graphs. For massive inputs, several different computational models have been introduced, including the streaming model, the distributed communication model, and the massively parallel computation (MPC) model that is a common abstraction of MapReduce-style computation. In each model, algorithms are analyzed in terms of resources such as space used or rounds of communication needed, in addition to the more traditional approximation ratio."
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",A nearly optimal oracle for avoiding failed vertices and edges,"We present an improved oracle for the distance sensitivity problem. The goal is to preprocess a directed graph G = (V,E) with non-negative edge weights to answer queries of the form: what is the length of the shortest path from x to y that does not go through some failed vertex or edge f. The previous best algorithm produces an oracle of size ~O(n2) that has an O(1) query time, and an ~O(n2√m) construction time. It was a randomized Monte Carlo algorithm that worked with high probability. Our oracle also has a constant query time and an ~O(n2) space requirement, but it has an improved construction time of ~O(mn), and it is deterministic. Note that O(1) query, O(n2) space, and O(mn) construction time is also the best known bound (up to logarithmic factors) for the simpler problem of finding all pairs shortest paths in a weighted, directed graph. Thus, barring improved solutions to the all pairs shortest path problem …"
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Fully dynamic matching in bipartite graphs,"We present two fully dynamic algorithms for maximum cardinality matching in bipartite graphs. Our main result is a deterministic algorithm that maintains a approximation in worst-case update time . This algorithm is polynomially faster than all previous deterministic algorithms for any constant approximation, and faster than all previous algorithms (randomized included) that achieve a better-than-2 approximation. We also give stronger results for bipartite graphs whose arboricity is at most , achieving a approximation in worst-case update time , which is for constant . Previous results for small arboricity graphs had similar update times but could only maintain a maximal matching (2-approximation). All these previous algorithms, however, were not limited to bipartite graphs."
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Maintaining shortest paths under deletions in weighted directed graphs,"We present an improved algorithm for maintaining all-pairs 1 + ε approximate shortest paths under deletions and weight-increases. The previous state of the art for this problem was total update time ~O (n2√m/ε) for directed, unweighted graphs [2], and ~O(mn/ε) for undirected, unweighted graphs [12]. Both algorithms were randomized and had constant query time. Note that ~O(mn) is a natural barrier because even with a (1 + ε) approximation, there is no o(mn) combinatorial algorithm for the static all-pairs shortest path problem. Our algorithm works on directed, weighted graphs and has total (randomized) update time ~O (mn log(R)/ε) where R is the ratio of the largest edge weight ever seen in the graph, to the smallest such weight (our query time is constant). Note that log(R) = O(log(n)) as long as weights are polynomial in n. Although ~O(mn log(R)/ε) is the total time over all updates, our algorithm also requires a …"
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Fully dynamic (2+ ε) approximate all-pairs shortest paths with fast query and close to linear update time,Description not available
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",A deamortization approach for dynamic spanner and dynamic maximal matching,"Many dynamic graph algorithms have an amortized update time, rather than a stronger worst-case guarantee. But amortized data structures are not suitable for real-time systems, where each individual operation has to be executed quickly. For this reason, there exist many recent randomized results that aim to provide a guarantee stronger than amortized expected. The strongest possible guarantee for a randomized algorithm is that it is always correct (Las Vegas) and has high-probability worst-case update time, which gives a bound on the time for each individual operation that holds with high probability."
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Improved dynamic algorithms for maintaining approximate shortest paths under deletions,"We present the first dynamic shortest paths algorithms that make any progress beyond a longstanding O(n) update time barrier (while maintaining a reasonable query time), although it is only progress for not-too-sparse graphs. In particular, we obtain new decremental algorithms for two approximate shortest-path problems in unweighted, undirected graphs. Both algorithms are randomized (Las Vegas)."
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms","Deterministic decremental reachability, scc, and shortest paths via directed expanders and congestion balancing",Description not available
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",A nearly optimal algorithm for approximating replacement paths and k shortest simple paths in general graphs,"Let G = (V, E) be a directed graph with positive edge weights, let s, t be two specified vertices in this graph, and let π(s, t) be the shortest path between them. In the replacement paths problem we want to compute, for every edge e on π(s, t), the shortest path from s to t that avoids e. The naive solution to this problem would be to remove each edge e, one at a time, and compute the shortest s – t path each time; this yields a running time of O(mn + n log n). Gotthilf and Lewenstein [8] recently improved this to O(mn + n2 log log n), but no o(mn) algorithms are known."
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Online Bipartite Matching with Amortized O(log 2 n) Replacements,"In the online bipartite matching problem with replacements, all the vertices on one side of the bipartition are given, and the vertices on the other side arrive one-by-one with all their incident edges. The goal is to maintain a maximum matching while minimizing the number of changes (replacements) to the matching. We show that the greedy algorithm that always takes the shortest augmenting path from the newly inserted vertex (denoted the SAP protocol) uses at most amortized O(log 2 n) replacements per insertion, where n is the total number of vertices inserted. This is the first analysis to achieve a polylogarithmic number of replacements for any replacement strategy, almost matching the Ω (log n) lower bound. The previous best strategy known achieved amortized O(√ n) replacements [Bosek, Leniowski, Sankowski, Zych, FOCS 2014]. For the SAP protocol in particular, nothing better than the trivial O(n) bound was …"
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Deterministic decremental sssp and approximate min-cost flow in almost-linear time,Description not available
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Deterministic decremental single source shortest paths: beyond the o (mn) bound,"In this paper we consider the decremental single-source shortest paths (SSSP) problem, where given a graph G and a source node s the goal is to maintain shortest paths between s and all other nodes in G under a sequence of online adversarial edge deletions."
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Fully-dynamic graph sparsifiers against an adaptive adversary,Description not available
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Distributed exact weighted all-pairs shortest paths in near-linear time,"In the distributed all-pairs shortest paths problem (APSP), every node in the weighted undirected distributed network (the CONGEST model) needs to know the distance from every other node using least number of communication rounds (typically called time complexity). The problem admits (1+o(1))-approximation Θ(n)-time algorithm and a nearly-tight Ω(n) lower bound [Nanongkai, STOC’14; Lenzen and Patt-Shamir PODC’15]. For the exact case, Elkin [STOC’17] presented an O(n5/3 log2/3 n) time bound, which was later improved to Õ(n5/4) in [Huang, Nanongkai, Saranurak FOCS’17].It was shown that any super-linear lower bound (in n) requires a new technique [Censor-Hillel, Khoury, Paz, DISC’17], but otherwise it remained widely open whether there exists a Õ(n)-time algorithm for the exact case, which would match the best possible approximation algorithm. This paper resolves this question positively: we …"
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Towards a unified theory of sparsification for matching problems,Description not available
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",A generative theory of similarity,"We argue that similarity judgments are inferences about generative processes, and that two objects appear similar when they are likely to have been generated by the same process. We describe a formal model based on this idea and show how featural and spatial models emerge as special cases. We compare our approach to the transformational approach, and present an experiment where our model performs better than a transformational model."
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Improved bounds for matching in random-order streams,"We study the problem of computing an approximate maximum cardinality matching in the semi-streaming model when edges arrive in a random order. In the semi-streaming model, the edges of the input graph are given as a stream , and the algorithm is allowed to make a single pass over this stream while using space ( and ). If the order of edges is adversarial, a simple single-pass greedy algorithm yields a 1/2-approximation in O(n) space; achieving a better approximation in adversarial streams remains an elusive open question. A line of recent work shows that one can improve upon the 1/2-approximation if the edges of the stream arrive in a random order. The state of the art for this model is two-fold: Assadi et al. [SODA 2019] show how to compute a -approximate matching, but the space requirement is . Very recently, Farhadi et al. [SODA 2020] presented an algorithm with the desired space usage of …"
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Decremental strongly-connected components and single-source reachability in near-linear time,"Computing the Strongly-Connected Components (SCCs) in a graph G=(V,E) is known to take only O(m+n) time using an algorithm by Tarjan from 1972[SICOMP 72] where m = |E|, n=|V|. For fully-dynamic graphs, conditional lower bounds provide evidence that the update time cannot be improved by polynomial factors over recomputing the SCCs from scratch after every update. Nevertheless, substantial progress has been made to find algorithms with fast update time for decremental graphs, i.e. graphs that undergo edge deletions."
Aaron Bernstein,https://scholar.google.com/citations?user=N94spO0AAAAJ&hl=en,"graph algorithms, sublinear algorithms",Improved distance sensitivity oracles via random sampling,"We present improved oracles for the distance sensitivity problem. The goal is to preprocess a graph G=(V, E) with non-negative edge weights to answer queries of the form: what is the length of the shortest path from x to y that does not go through some failed vertex or edge f. There are two state of the art algorithms for this problem. The first produces an oracle of size O (n2) that has an O (1) query time, and an O (mn2) construction time. The second oracle has size O (n2. 5), but the construction time is only O (mn1. 5). We present two new oracles that substantially improve upon both of these results. Both oracles are constructed with randomized, Monte Carlo algorithms. For directed graphs with non-negative edge weights, we present an oracle of size"
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Fliptest: fairness testing via optimal transport,"We present FlipTest, a black-box technique for uncovering discrimination in classifiers. FlipTest is motivated by the intuitive question: had an individual been of a different protected status, would the model have treated them differently? Rather than relying on causal information to answer this question, FlipTest leverages optimal transport to match individuals in different protected groups, creating similar pairs of in-distribution samples. We show how to use these instances to detect discrimination by constructing a flipset: the set of individuals whose classifier output changes post-translation, which corresponds to the set of people who may be harmed because of their group membership. To shed light on why the model treats a given subgroup differently, FlipTest produces a transparency report: a ranking of features that are most associated with the model's behavior on the flipset. Evaluating the approach on three case …"
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning","Model multiplicity: Opportunities, concerns, and solutions","Recent scholarship has brought attention to the fact that there often exist multiple models for a given prediction task with equal accuracy that differ in their individual-level predictions or aggregate properties. This phenomenon—which we call model multiplicity—can introduce a good deal of flexibility into the model selection process, creating a range of exciting opportunities. By demonstrating that there are many different ways of making equally accurate predictions, multiplicity gives model developers the freedom to prioritize other values in their model selection process without having to abandon their commitment to maximizing accuracy. However, multiplicity also brings to light a concerning truth: model selection on the basis of accuracy alone—the default procedure in many deployment scenarios—fails to consider what might be meaningful differences between equally accurate models with respect to other criteria …"
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Feature-wise bias amplification,Description not available
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Consistent counterfactuals for deep models,Description not available
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Leave-one-out unfairness,"We introduce leave-one-out unfairness, which characterizes how likely a model's prediction for an individual will change due to the inclusion or removal of a single other person in the model's training data. Leave-one-out unfairness appeals to the idea that fair decisions are not arbitrary: they should not be based on the chance event of any one person's inclusion in the training data. Leave-one-out unfairness is closely related to algorithmic stability, but it focuses on the consistency of an individual point's prediction outcome over unit changes to the training data, rather than the error of the model in aggregate. Beyond formalizing leave-one-out unfairness, we characterize the extent to which deep models behave leave-one-out unfairly on real data, including in cases where the generalization error is small. Further, we demonstrate that adversarial training and randomized smoothing techniques have opposite effects on …"
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Algorithmic fairness and vertical equity: Income fairness with irs tax audit models,"This study examines issues of algorithmic fairness in the context of systems that inform tax audit selection by the United States Internal Revenue Service (IRS). While the field of algorithmic fairness has developed primarily around notions of treating like individuals alike, we instead explore the concept of vertical equity—appropriately accounting for relevant differences across individuals—which is a central component of fairness in many public policy settings. Applied to the design of the U.S. individual income tax system, vertical equity relates to the fair allocation of tax and enforcement burdens across taxpayers of different income levels. Through a unique collaboration with the Treasury Department and IRS, we use access to detailed, anonymized individual taxpayer microdata, risk-selected audits, and random audits from 2010-14 to study vertical equity in tax administration. In particular, we assess how the …"
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Selective ensembles for consistent predictions,Description not available
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Spectral analysis of molecular dynamics simulations on PDZ: MD sectors,"The idea of protein “sectors” posits that sparse subsets of amino acid residues form cooperative networks that are key elements of protein stability, ligand binding, and allosterism. To date, protein sectors have been calculated by the statistical coupling analysis (SCA) method of Ranganathan and co-workers via the spectral analysis of conservation-weighted evolutionary covariance matrices obtained from a multiple sequence alignments of homologous families of proteins. SCA sectors, a knowledge-based protocol, have been indentified with functional properties and allosterism for a number of systems. In this study, we investigate the utility of the sector idea for the analysis of physics-based molecular dynamics (MD) trajectories of proteins. Our test case for this procedure is PSD95- PDZ3, one of the smallest proteins for which allosterism has been observed. It has served previously as a model system for a number of …"
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Evaluating facial recognition technology: a protocol for performance assessment in new domains,"Facial recognition technology (FRT) raises profound questions about the role of technology in society. The complex ethical and normative concerns about FRT's impact on privacy, speech, racial equity, and the power of the state merit serious debate. Yet one requirement common to proposed legislation and regulation of FRT is the testing and assessment of operational performance: how well does FRT actually work? This poses deep challenges given the rapid uptake of FRT in many new domains, such as retail, finance, travel, and criminal justice. In this Article, we provide research-and science-grounded recommendations for how to concretely test the operational accuracy of FRT that will be central to regulation and oversight."
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Toward Operationalizing Pipeline-aware ML Fairness: A Research Agenda for Developing Practical Guidelines and Tools,"While algorithmic fairness is a thriving area of research, in practice, mitigating issues of bias often gets reduced to enforcing an arbitrarily chosen fairness metric, either by enforcing fairness constraints during the optimization step, post-processing model outputs, or by manipulating the training data. Recent work has called on the ML community to take a more holistic approach to tackle fairness issues by systematically investigating the many design choices made through the ML pipeline, and identifying interventions that target the issue’s root cause, as opposed to its symptoms. While we share the conviction that this pipeline-based approach is the most appropriate for combating algorithmic unfairness on the ground, we believe there are currently very few methods of operationalizing this approach in practice. Drawing on our experience as educators and practitioners, we first demonstrate that without clear guidelines …"
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",A call for universities to develop requirements for community engagement in ai research,"In this piece, we use the term “community engagement” to refer to processes that involve stakeholders outside of academia, industry, or the government in AI research, with the purpose of guiding its design, ideation, and implementation. This engagement should enable “those who must live with the consequences of a decision to make it together”[7]. As Asad et al. observed in their work on citizen engagement in civic technology, levels of engagement may range from merely “tokenistic” to meaningful citizen input and control [3], inspired by Arnstein’s Ladder [2] of civic participation. We thus use “engagement” to refer to levels of interaction above simply “informing or placating”[2], for mechanisms that provide citizens higher levels of control."
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Fliptest: Fairness auditing via optimal transport,Description not available
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Less discriminatory algorithms,"Entities that use algorithmic systems in traditional civil rights domains like housing, employment, and credit should have a duty to search for and implement less discriminatory algorithms (LDAs). Why? Work in computer science has established that, contrary to conventional wisdom, for a given prediction problem there are almost always multiple possible models with equivalent performance—a phenomenon termed model multiplicity. Critically for our purposes, different models of equivalent performance can produce different predictions for the same individual, and, in aggregate, exhibit different levels of impacts across demographic groups. As a result, when an algorithmic system displays a disparate impact, model multiplicity suggests that developers may be able to discover an alternative model that performs equally well, but has less discriminatory impact. Indeed, the promise of model multiplicity is that an equally accurate, but less discriminatory alternative algorithm almost always exists. But without dedicated exploration, it is unlikely developers will discover potential LDAs."
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",How regulators can get facial recognition technology right,Description not available
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Domain Shift and Emerging Questions in Facial Recognition Technology,"In May 2020, we hosted a workshop to discuss the performance of facial recognition technologies that included leading computer scientists, legal scholars, and representatives from industry, government, and civil society. The white paper this workshop produced,“Evaluating Facial Recognition Technology: A Protocol for Performance Assessment in New Domains,” seeks to answer key questions in improving our understanding of this rapidly changing space. While the workshop was held before the nationwide upheaval in the wake of the killings of George Floyd, Breonna Taylor, and Ahmaud Arbery, our recommendations are particularly important as nearly all proposed legislation or regulation of FRT calls for evaluation of its operational performance."
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Generative monoculture in large language models,Description not available
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",The Legal Duty to Search for Less Discriminatory Algorithms,Description not available
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",D-hacking,"Recent regulatory efforts, including Executive Order 14110 and the AI Bill of Rights, have focused on mitigating discrimination in AI systems through novel and traditional application of anti-discrimination laws. While these initiatives rightly emphasize fairness testing and mitigation, we argue that they pay insufficient attention to robust bias measurement and mitigation—and that without doing so, the frameworks cannot effectively achieve the goal of reducing discrimination in deployed AI models. This oversight is particularly concerning given the instability and brittleness of current algorithmic bias mitigation and fairness optimization methods, as highlighted by growing evidence in the algorithmic fairness literature. This instability heightens the risk of what we term discrimination-hacking or d-hacking, a scenario where, inadvertently or deliberately, the selection of models based on favorable fairness metrics within …"
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",Estimating and implementing conventional fairness metrics with probabilistic protected features,Description not available
Emily Black,https://scholar.google.com/citations?user=dBkGY6gAAAAJ&hl=en,"algorithmic fairness, anti-discrimination, machine learning policy, machine learning, deep learning",56 Molecular dynamics simulation studies of protein sectors: motional correlations,Description not available
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Seattle: a platform for educational cloud computing,"Cloud computing is rapidly increasing in popularity. Companies such as RedHat, Microsoft, Amazon, Google, and IBM are increasingly funding cloud computing infrastructure and research, making it important for students to gain the necessary skills to work with cloud-based resources. This paper presents a free, educational research platform called Seattle that is community-driven, a common denominator for diverse platform types, and is broadly deployed."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",{CHAINIAC}: Proactive {Software-Update} transparency via collectively signed skipchains and verified builds,"Software-update mechanisms are critical to the security of modern systems, but their typically centralized design presents a lucrative and frequently attacked target. In this work, we propose CHAINIAC, a decentralized software-update framework that eliminates single points of failure, enforces transparency, and provides efficient verifiability of integrity and authenticity for software-release processes. Independent witness servers collectively verify conformance of software updates to release policies, build verifiers validate the source-to-binary correspondence, and a tamper-proof release log stores collectively signed updates, thus ensuring that no release is accepted by clients before being widely disclosed and validated. The release log embodies a skipchain, a novel data structure, enabling arbitrarily out-of-date clients to efficiently validate updates and signing keys. Evaluation of our CHAINIAC prototype on reproducible Debian packages shows that the automated update process takes the average of 5 minutes per release for individual packages, and only 20 seconds for the aggregate timeline. We further evaluate the framework using real-world data from the PyPI package repository and show that it offers clients security comparable to verifying every single update themselves while consuming only one-fifth of the bandwidth and having a minimal computational overhead."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Survivable key compromise in software update systems,"Today's software update systems have little or no defense against key compromise. As a result, key compromises have put millions of software update clients at risk. Here we identify three classes of information whose authenticity and integrity are critical for secure software updates. Analyzing existing software update systems with our framework, we find their ability to communicate this information securely in the event of a key compromise to be weak or nonexistent. We also find that the security problems in current software update systems are compounded by inadequate trust revocation mechanisms. We identify core security principles that allow software update systems to survive key compromise. Using these ideas, we design and implement TUF, a software update framework that increases resilience to key compromise."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",A look in the mirror: Attacks on package managers,"This work studies the security of ten popular package managers. These package managers use different security mechanisms that provide varying levels of usability and resilience to attack. We find that, despite their existing security mechanisms, all of these package managers have vulnerabilities that can be exploited by a man-in-the-middle or a malicious mirror. While all current package managers suffer from vulnerabilities, their security is also positively or negatively impacted by the distribution's security practices. Weaknesses in package managers are more easily exploited when distributions use third-party mirrors as official mirrors. We were successful in using false credentials to obtain an official mirror on all five of the distributions we attempted. We also found that some security mechanisms that control where a client obtains metadata and packages from may actually decrease security. We analyze current …"
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",""" On the internet, nobody knows you're a dog"" a twitter case study of anonymity in social networks","Twitter does not impose a Real-Name policy for usernames, giving users the freedom to choose how they want to be identified. This results in some users being Identifiable (disclosing their full name) and some being Anonymous (disclosing neither their first nor last name)."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",It's the psychology stupid: how heuristics explain software vulnerabilities and how priming can illuminate developer's blind spots,"Despite the security community's emphasis on the importance of building secure software, the number of new vulnerabilities found in our systems is increasing. In addition, vulnerabilities that have been studied for years are still commonly reported in vulnerability databases. This paper investigates a new hypothesis that software vulnerabilities are blind spots in developer's heuristic-based decision-making processes. Heuristics are simple computational models to solve problems without considering all the information available. They are an adaptive response to our short working memory because they require less cognitive effort. Our hypothesis is that as software vulnerabilities represent corner cases that exercise unusual information flows, they tend to be left out from the repertoire of heuristics used by developers during their programming tasks."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Uptane: Securing software updates for automobiles,"Software update systems for automobiles can deliver significant benefits, but, if not implemented carefully, they could potentially incur serious security vulnerabilities. Previous solutions for securing software updates consider standard attacks and deploy widely understood security mechanisms, such as digital signatures for the software updates, and hardware security modules (HSM) to sign software updates. However, no existing solution considers more advanced security objectives, such as resilience against a repository compromise, or freeze attacks to the vehicle’s update mechanism, or a compromise at a supplier’s site. Solutions developed for the PC world do not generalize to automobiles for two reasons: first, they do not solve problems that are unique to the automotive industry (eg, that there are many different types of computers to be updated on a vehicle), and second, they do not address security attacks that can cause a vehicle to fail (eg a man-in-themiddle attack without compromising any signing key) or that can cause a vehicle to become unsafe. In this paper, we present Uptane, the first software update framework for automobiles that counters a comprehensive array of security attacks, and is resilient to partial compromises. Uptane adds strategic features to the state-of-the-art software update framework, TUF, in order to address automotivespecific vulnerabilities and limitations. Uptane is flexible and easy to adopt, and its design details were developed together with the main automotive industry stakeholders in the USA."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",{API} blindspots: Why experienced developers write vulnerable code,"Despite the best efforts of the security community, security vulnerabilities in software are still prevalent, with new vulnerabilities reported daily and older ones stubbornly repeating themselves. One potential source of these vulnerabilities is shortcomings in the used language and library APIs. Developers tend to trust APIs, but can misunderstand or misuse them, introducing vulnerabilities. We call the causes of such misuse blindspots. In this paper, we study API blindspots from the developers' perspective to:(1) determine the extent to which developers can detect API blindspots in code and (2) examine the extent to which developer characteristics (ie, perception of code correctness, familiarity with code, confidence, professional experience, cognitive function, and personality) affect this capability. We conducted a study with 109 developers from four countries solving programming puzzles that involve Java APIs known to contain blindspots. We find that (1) The presence of blindspots correlated negatively with the developers' accuracy in answering implicit security questions and the developers' ability to identify potential security concerns in the code. This effect was more pronounced for I/O-related APIs and for puzzles with higher cyclomatic complexity.(2) Higher cognitive functioning and more programming experience did not predict better ability to detect API blindspots.(3) Developers exhibiting greater openness as a personality trait were more likely to detect API blindspots. This study has the potential to advance API security in (1) design, implementation, and testing of new APIs;(2) addressing blindspots in legacy APIs;(3) development of novel …"
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Understanding password database compromises,"Despite continuing advances in cyber security, website incursions, in which password databases are compromised, occur for high profile sites dozens of times each year. Dumps of recently stolen credentials appear on a regular basis at websites like pastebin. com and pastie. com, as do stories concerning significant breaches. As a result of these observations, we chose to examine this phenomenon."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Understanding misunderstandings in source code,"Humans often mistake the meaning of source code, and so misjudge a program's true behavior. These mistakes can be caused by extremely small, isolated patterns in code, which can lead to significant runtime errors. These patterns are used in large, popular software projects and even recommended in style guides. To identify code patterns that may confuse programmers we extracted a preliminary set of `atoms of confusion' from known confusing code. We show empirically in an experiment with 73 participants that these code patterns can lead to a significantly increased rate of misunderstanding versus equivalent code without the patterns. We then go on to take larger confusing programs and measure (in an experiment with 43 participants) the impact, in terms of programmer confusion, of removing these confusing patterns. All of our instruments, analysis code, and data are publicly available online for …"
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Retaining sandbox containment despite bugs in privileged memory-safe code,"Flaws in the standard libraries of secure sandboxes represent a major security threat to billions of devices worldwide. The standard libraries are hard to secure because they frequently need to perform low-level operations that are forbidden in untrusted application code. Existing designs have a single, large trusted computing base that contains security checks at the boundaries between trusted and untrusted code. Unfortunately, flaws in the standard library often allow an attacker to escape the security protections of the sandbox."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Diplomat: Using delegations to protect community repositories,"Community repositories, such as Docker Hub, PyPI, and RubyGems, are bustling marketplaces that distribute software. Even though these repositories use common software signing techniques (eg, GPG and TLS), attackers can still publish malicious packages after a server compromise. This is mainly because a community repository must have immediate access to signing keys in order to certify the large number of new projects that are registered each day."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Selectively taming background android apps to improve battery lifetime,"Background activities on mobile devices can cause significant battery drain with little visibility or recourse to the user. They can range from useful but sometimes overly aggressive tasks, such as polling for messages or updates from sensors and online services, to outright bugs that cause resources to be held unnecessarily. In this paper we instrument the Android OS to characterize background activities that prevent the device from sleeping. We present T AMER, an OS mechanism that interposes on events and signals that cause task wakeups, and allows for their detailed monitoring, filtering, and rate-limiting. We demonstrate how T AMER can help reduce battery drain in scenarios involving popular Android apps with background tasks. We also show how T AMER can mitigate the effects of well-known energy bugs while maintaining most of the apps’ functionality. Finally, we elaborate on how developers and users can devise their own application-control policies for T AMER to maximize battery lifetime."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",A first look at vehicle data collection via smartphone sensors,Description not available
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Uptane: Security and customizability of software updates for vehicles,Description not available
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",User anonymity on twitter,Description not available
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",{Lock-in-Pop}: Securing Privileged Operating System Kernels by Keeping on the Beaten Path,"Virtual machines (VMs) that try to isolate untrusted code are widely used in practice. However, it is often possible to trigger zero-day flaws in the host Operating System (OS) from inside of such virtualized systems. In this paper, we propose a new security metric showing strong correlation between “popular paths” and kernel vulnerabilities. We verify that the OS kernel paths accessed by popular applications in everyday use contain significantly fewer security bugs than less-used paths. We then demonstrate that this observation is useful in practice by building a prototype system which locks an application into using only popular OS kernel paths. By doing so, we demonstrate that we can prevent the triggering of zero-day kernel bugs significantly better than three other competing approaches, and argue that this is a practical approach to secure system design."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Measuring the fitness of fitness trackers,Description not available
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",Package management security,"Package management is the task of determining which packages should be installed on a host and then downloading and installing those packages. This paper examines the popular package managers APT and YUM and presents nine feasible attacks on them. There are attacks that install malicious packages, deny users package updates, or cause the host to crash. This work identifies three rules of package management security: don’t trust the repository, the trusted entity with the most information should be the one who signs, and don’t install untrusted packages. The violation of these rules leads to the described vulnerabilities. Unfortunately, many of the flaws are architectural in nature, so repair requires more than patches to APT and YUM."
Justin Cappos,https://scholar.google.com/citations?user=COE6KUgAAAAJ&hl=en,"Security, software supply chain, virtualization, cloud computing, software verification",{NetCheck}: Network Diagnoses from Blackbox Traces,"This paper introduces NetCheck, a tool designed to diagnose network problems in large and complex applications. NetCheck relies on blackbox tracing mechanisms, such as strace, to automatically collect sequences of network system call invocations generated by the application hosts. NetCheck performs its diagnosis by (1) totally ordering the distributed set of input traces, and by (2) utilizing a network model to identify points in the totally ordered execution where the traces deviated from expected network semantics."
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",External-memory graph algorithms,Description not available
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Dynamic algorithms in computational geometry,Description not available
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Interactive out-of-core isosurface extraction,Description not available
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",I/O optimal isosurface extraction,Description not available
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Out-of-core algorithms for scientific visualization and computer graphics,"Recently, several external memory techniques have been developed for a wide variety of graphics and visualization problems, including surface simplification, volume rendering, isosurface generation, ray tracing, surface reconstruction, and so on. This work has had significant impact given that in recent years there has been a rapid increase in the raw size of datasets. Several technological trends are contributing to this, such as the development of high-resolution 3D scanners, and the need to visualize ASCI-size (Accelerated Strategic Computing Initiative) datasets. Another important push for this kind of technology is the growing speed gap between main memory and caches, such a gap penalizes algorithms which do not optimize for coherence of access. Because of these reasons, much research in computer graphics focuses on developing out-of-core (and often cache-friendly) techniques. This paper surveys fundamental issues, current problems, and unresolved solutions, and aims to provide students and graphics researchers and professionals with an effective knowledge of current techniques, as well as the foundation to develop novel techniques on their own."
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",External memory view‐dependent simplification,"In this paper, we propose a novel external‐memory algorithm to support view‐dependent simplification for datasets much larger than main memory. In the preprocessing phase, we use a new spanned sub‐meshes simplification technique to build view‐dependence trees I/O‐efficiently, which preserves the correct edge collapsing order and thus assures the run‐time image quality. We further process the resulting view‐dependence trees to build the meta‐node trees, which can facilitate the run‐time level‐of‐detail rendering and is kept in disk. During run‐time navigation, we keep in main memory only the portions of the meta‐node trees that are necessary to render the current level of details, plus some prefetched portions that are likely to be needed in the near future. The prefetching prediction takes advantage of the nature of the run‐time traversal of the meta‐node trees, and is both simple and accurate. We also …"
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Geometric algorithms for conflict detection/resolution in air traffic management,Description not available
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Simple and optimal output-sensitive construction of contour trees using monotone paths,Description not available
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",A unified infrastructure for parallel out-of-core isosurface extraction and volume rendering of unstructured grids,Description not available
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Two-point Euclidean shortest path queries in the plane,"We consider the two-point query version of the fundamental geometric shortest path problem: Given a set h of polygonal obstacles in the plane, having a total of n vertices, build a data structure such that for any two query points s and t we can e ciently determine the length, d (s; t), of an Euclidean shortest obstacle-avoiding path,(s; t), from s to t. Additionally, our data structure should allow one to report the path (s; t), in time proportional to its (combinatorial) size. We present various methods for solving this two-point query problem, including algorithms with o (n), O (log n+h), O (hlog n), O (log2 n) or optimal O (log n) query times, using polynomial-space data structures, with various tradeo s between space and query time. While several results have been known for approximate two-point Euclidean shortest path queries, it has been a well-publicized open problem to obtain sublinear query time for the exact version of the problem. Our methods also yield data structures for two-point shortest path queries on nonconvex polyhedral surfaces."
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Progressive simplification of tetrahedral meshes preserving all isosurface topologies,"In this paper, we propose a novel technique for constructing multiple levels of a tetrahedral volume dataset whilepreserving the topologies of all isosurfaces embedded in the data. Our simplification technique has two majorphases. In the segmentation phase, we segment the volume data into topological‐equivalence regions, that is, thesub‐volumes within each of which all isosurfaces have the same topology. In the simplification phase, we simplifyeach topological‐equivalence region independently, one by one, by collapsing edges from the smallest to the largesterrors (within the user‐specified error tolerance, for a given error metrics), and ensure that we do not collapseedges that may cause an isosurface‐topology change. We also avoid creating a tetrahedral cell of negative volume(i.e., avoid the fold‐over problem). In this way, we guarantee to preserve all isosurface topologies in the entiresimplification process …"
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry","A unified approach to dynamic point location, ray shooting, and shortest paths in planar maps","We describe a new technique for dynamically maintaining the trapezoidal decomposition of a connected planar map with n vertices and apply it to the development of a unified dynamic data structure that supports point-location, ray-shooting, and shortest-path queries in . The space requirement is . Point-location queries take time . Ray-shooting and shortest-path queries take time (plus time if the k edges of the shortest path are reported in addition to its length). Updates consist of insertions and deletions of vertices and edges, and take time (amortized for vertex updates). This is the first polylog-time dynamic data structure for shortest-path and ray-shooting queries. It is also the first dynamic point-location data structure for connected planar maps that achieves optimal query time."
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",External Memory Techniques for Isosurface Extractions in Scientific Visualization,"Isosurface extraction is one of the most effective and powerful techniques for the investigation of volume datasets in scientific visualization. Previous isosurface techniques are all main-memory algorithms, often not applicable to large scientific visualization applications. In this paper we survey our recent work that gives the first external memory techniques for isosurface extraction. The first technique, I/O-filter, uses the existing I/O-optimal interval tree as the indexing data structure (where the corner structure is not implemented), together with the isosurface engine of Vtk (one of the currently best visualization packages). The second technique improves the first version of I/O-filter by replacing the I/O interval tree with the metablock tree (whose corner structure is not implemented). The third method further improves the first two, by using a two-level indexing scheme, together with a new meta-cell technique and a new I/O-optimal indexing data structure (the binary-blocked I/O interval tree) that is simpler and more space-efficient in practice (whose corner structure is not implemented). The experiments show that the first two methods perform isosurface queries faster than Vtk by a factor of two orders of magnitude for datasets larger than main memory. The third method further reduces the disk space requirement from 7.2–7.7 times the original dataset size to 1.1–1.5 times, at the cost of slightly increasing the query time; this method also exhibits a smooth trade-off between disk space and query time."
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",On minimum-area hulls,"We study some minimum-area hull problems that generalize the notion of convex hull to star-shaped and monotone hulls. Specifically, we consider the minimum-area star-shaped hull problem: Given an n -vertex simple polygon P , find a minimum-area, star-shaped polygon P * containing P . This problem arises in lattice packings of translates of multiple, nonidentical shapes in material layout problems (e.g., in clothing manufacture), and has been recently posed by Daniels and Milenkovic. We consider two versions of the problem: the restricted version, in which the vertices of P * are constrained to be vertices of P , and the unrestricted version, in which the vertices of P * can be anywhere in the plane. We prove that the restricted problem falls in the class of ``3sum-hard'' (sometimes called ``n 2 -hard'') problems, which are …"
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",On the maximum scatter traveling salesperson problem,"We study the problem of computing a Hamiltonian tour (cycle) or path on a set of points in order to maximize the minimum edge length in the tour or path. This ""maximum scatter"" traveling salesperson problem (TSP) is closely related to the bottleneck TSP and is motivated by applications in manufacturing (e.g., sequencing of rivet operations) and medical imaging. In this paper, we give the first algorithmic study of these problems, including complexity results, approximation algorithms, and exact algorithms for special cases. In an attempt to model more accurately the real problems that arise in practice, we also generalize the basic problem to consider a more general measure of ""scatter"" in which points on a tour or path should be far not only from their immediate predecessor and successor, but also from other near-neighbors along the tour or path."
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",On soft predicates in subdivision motion planning,"We propose to design new algorithms for motion planning problems using the well-known Domain Subdivision paradigm, coupled with ""soft"" predicates. Unlike the traditional exact predicates in computational geometry, our primitives are only exact in the limit. We introduce the notion of resolution-exact algorithms in motion planning: such an algorithm has an ""accuracy"" constant K> 1, and takes an arbitrary input ""resolution"" parameter ε>0 such that: if there is a path with clearance Kε, it will output a path with clearance ε/K; if there are no paths with clearance ε/K, it reports ""no path"". Besides the focus on soft predicates, our framework also admits a variety of global search strategies including forms of the A* search and probabilistic search."
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Dynamic and I/O-efficient algorithms for computational geometry and graph problems: theoretical and experimental results,"As most important applications today are large-scale in nature, high-performance methods are becoming indispensable. Two promising computational paradigms for large-scale applications are dynamic and I/O-efficient computations. We give efficient dynamic data structures for several fundamental problems in computational geometry, including point location, ray shooting, shortest path, and minimum-link path. We also develop a collection of new techniques for designing and analyzing I/O-efficient algorithms for graph problems, and illustrate how these techniques can be applied to a wide variety of specific problems, including list ranking, Euler tour, expression-tree evaluation, least-common ancestors, connected and biconnected components, minimum spanning forest, ear decomposition, topological sorting, reachability, graph drawing, and visibility representation. Finally, we present an extensive experimental …"
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Out-of-core isosurface extraction of time-varying fields over irregular grids,Description not available
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Experiments on the practical I/O efficiency of geometric algorithms: Distribution sweep vs. plane sweep,"We present an extensive experimental study comparing the performance of four algorithms for the orthogonal segment intersection problem. The algorithms under evaluation are distribution sweep, which has optimal I/O cost, and three variations of plane sweep, which is optimal in terms of internal computation. We generate the test data by using a random number generator while producing some interesting properties that are predicted by our theoretical analysis. The sizes of the test data range from 250 thousand segments to 2.5 million segments. The experiments provide detailed quantitative evaluation of the performance of the four algorithms. This is the first experimental work comparing the practical performance between external-memory algorithms and conventional algorithms with large-scale test data."
Yi-Jen Chiang,https://scholar.google.com/citations?user=ZcDNvvEAAAAJ&hl=en,"Data Analysis and Visualization, Geometric Processing, Robot Motion Planning, Algorithms, Computational Geometry",Dynamization of the trapezoid method for planar point location in monotone subdivisions,"We present a fully dynamic data structure for point location in a monotone subdivision, based on the trapezoid method. The operations supported are insertion and deletion of vertices and edges, and horizontal translation of vertices. Let n be the current number of vertices of the subdivision. Point location queries take O(log n) time, while updates take O (log2 n) time (amortized for vertex insertion/deletion and worst-case for the other updates). The space requirement is O(n log n). This is the first fully dynamic point location data structure for monotone subdivisions that achieves optimal query time."
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",COVID-19 transforms health care through telemedicine: evidence from the field,"This study provides data on the feasibility and impact of video-enabled telemedicine use among patients and providers and its impact on urgent and nonurgent healthcare delivery from one large health system (NYU Langone Health) at the epicenter of the coronavirus disease 2019 (COVID-19) outbreak in the United States. Between March 2nd and April 14th 2020, telemedicine visits increased from 102.4 daily to 801.6 daily. (683% increase) in urgent care after the system-wide expansion of virtual urgent care staff in response to COVID-19. Of all virtual visits post expansion, 56.2% and 17.6% urgent and nonurgent visits, respectively, were COVID-19–related. Telemedicine usage was highest by patients 20 to 44 years of age, particularly for urgent care. The COVID-19 pandemic has driven rapid expansion of telemedicine use for urgent care and nonurgent care visits beyond baseline periods. This reflects an …"
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Social and news media enable estimation of epidemiological patterns early in the 2010 Haitian cholera outbreak,"During infectious disease outbreaks, data collected through health institutions and official reporting structures may not be available for weeks, hindering early epidemiologic assessment. By contrast, data from informal media are typically available in near real-time and could provide earlier estimates of epidemic dynamics. We assessed correlation of volume of cholera-related HealthMap news media reports, Twitter postings, and government cholera cases reported in the first 100 days of the 2010 Haitian cholera outbreak. Trends in volume of informal sources significantly correlated in time with official case data and was available up to 2 weeks earlier. Estimates of the reproductive number ranged from 1.54 to 6.89 (informal sources) and 1.27 to 3.72 (official sources) during the initial outbreak growth period, and 1.04 to 1.51 (informal) and 1.06 to 1.73 (official) when Hurricane Tomas afflicted Haiti. Informal data can be …"
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Participatory epidemiology: use of mobile phones for community-based health reporting,"Clark Freifeld and colleagues discuss mobile applications, including their own smartphone application, that show promise for health monitoring and information sharing."
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Telemedicine and Healthcare Disparities: A cohort study in a large healthcare system in New York City during COVID-19,"Through the coronavirus disease 2019 (COVID-19) pandemic, telemedicine became a necessary entry point into the process of diagnosis, triage, and treatment. Racial and ethnic disparities in healthcare have been well documented in COVID-19 with respect to risk of infection and in-hospital outcomes once admitted, and here we assess disparities in those who access healthcare via telemedicine for COVID-19."
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Monitoring influenza epidemics in china with search query from baidu,"Several approaches have been proposed for near real-time detection and prediction of the spread of influenza. These include search query data for influenza-related terms, which has been explored as a tool for augmenting traditional surveillance methods. In this paper, we present a method that uses Internet search query data from Baidu to model and monitor influenza activity in China. The objectives of the study are to present a comprehensive technique for: (i) keyword selection, (ii) keyword filtering, (iii) index composition and (iv) modeling and detection of influenza activity in China. Sequential time-series for the selected composite keyword index is significantly correlated with Chinese influenza case data. In addition, one-month ahead prediction of influenza cases for the first eight months of 2012 has a mean absolute percent error less than 11%. To our knowledge, this is the first study on the use of search query data from Baidu in conjunction with this approach for estimation of influenza activity in China."
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing","Uncertainty as a Form of Transparency: Measuring, Communicating, and Using Uncertainty","Algorithmic transparency entails exposing system properties to various stakeholders for purposes that include understanding, improving, and contesting predictions. Until now, most research into algorithmic transparency has predominantly focused on explainability. Explainability attempts to provide reasons for a machine learning model's behavior to stakeholders. However, understanding a model's specific behavior alone might not be enough for stakeholders to gauge whether the model is wrong or lacks sufficient knowledge to solve the task at hand. In this paper, we argue for considering a complementary form of transparency by estimating and communicating the uncertainty associated with model predictions. First, we discuss methods for assessing uncertainty. Then, we characterize how uncertainty can be used to mitigate model unfairness, augment decision-making, and build trustworthy systems. Finally, we …"
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Flu Near You: Crowdsourced Symptom Reporting Spanning 2 Influenza Seasons,Objectives. We summarized Flu Near You (FNY) data from the 2012–2013 and 2013–2014 influenza seasons in the United States.
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",A Case Study of the New York City 2012-2013 Influenza Season With Daily Geocoded Twitter Data From Temporal and Spatiotemporal Perspectives,"Background: Twitter has shown some usefulness in predicting influenza cases on a weekly basis in multiple countries and on different geographic scales. Recently, Broniatowski and colleagues suggested Twitter’s relevance at the city-level for New York City. Here, we look to dive deeper into the case of New York City by analyzing daily Twitter data from temporal and spatiotemporal perspectives. Also, through manual coding of all tweets, we look to gain qualitative insights that can help direct future automated searches."
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Twitter as a sentinel in emergency situations: lessons from the Boston marathon explosions,"Immediately following the Boston Marathon attacks, individuals near the scene posted a deluge of data to social media sites. Previous work has shown that these data can be leveraged to provide rapid insight during natural disasters, disease outbreaks and ongoing conflicts that can assist in the public health and medical response. Here, we examine and discuss the social media messages posted immediately after and around the Boston Marathon bombings, and find that specific keywords appear frequently prior to official public safety and news media reports. Individuals immediately adjacent to the explosions posted messages within minutes via Twitter which identify the location and specifics of events, demonstrating a role for social media in the early recognition and characterization of emergency events.* Christopher Cassa and Rumi Chunara contributed equally to this work."
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Public health for the people: participatory infectious disease surveillance in the digital age,"The 21st century has seen the rise of Internet-based participatory surveillance systems for infectious diseases. These systems capture voluntarily submitted symptom data from the general public and can aggregate and communicate that data in near real-time. We reviewed participatory surveillance systems currently running in 13 different countries. These systems have a growing evidence base showing a high degree of accuracy and increased sensitivity and timeliness relative to traditional healthcare-based systems. They have also proven useful for assessing risk factors, vaccine effectiveness, and patterns of healthcare utilization while being less expensive, more flexible, and more scalable than traditional systems. Nonetheless, they present important challenges including biases associated with the population that chooses to participate, difficulty in adjusting for confounders, and limited specificity …"
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Machine learning and algorithmic fairness in public and population health,"Until now, much of the work on machine learning and health has focused on processes inside the hospital or clinic. However, this represents only a narrow set of tasks and challenges related to health; there is greater potential for impact by leveraging machine learning in health tasks more broadly. In this Perspective we aim to highlight potential opportunities and challenges for machine learning within a holistic view of health and its influences. To do so, we build on research in population and public health that focuses on the mechanisms between different cultural, social and environmental factors and their effect on the health of individuals and communities. We present a brief introduction to research in these fields, data sources and types of tasks, and use these to identify settings where machine learning is relevant and can contribute to new knowledge. Given the key foci of health equity and disparities within public …"
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Fairness Violations and Mitigation under Covariate Shift,Description not available
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing","Race, Ethnicity and National Origin-based Discrimination in Social Media and Hate Crimes Across 100 US Cities","We study malicious online content via a specific type of hate speech: race, ethnicity and national-origin based discrimination in social media, alongside hate crimes motivated by those characteristics, in 100 cities across the United States. We develop a spatially-diverse training dataset and classification pipeline to delineate targeted and self-narration of discrimination on social media, accounting for language across geographies. Controlling for census parameters, we find that the proportion of discrimination that is targeted is associated with the number of hate crimes. Finally, we explore the linguistic features of discrimination Tweets in relation to hate crimes by city, features used by users who Tweet different amounts of discrimination, and features of discrimination compared to non-discrimination Tweets. Findings from this spatial study can inform future studies of how discrimination in physical and virtual worlds vary by place, or how physical and virtual world discrimination may synergize."
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Suspended microchannel resonators with piezoresistive sensors,Description not available
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Characterizing sleep issues using Twitter,"Sleep issues such as insomnia affect over 50 million Americans and can lead to serious health problems, including depression and obesity, and can increase risk of injury. Social media platforms such as Twitter offer exciting potential for their use in studying and identifying both diseases and social phenomenon."
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Flu Near You: An Online Self-reported Influenza Surveillance System in the USA,Objective
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Assessing the Online Social Environment for Surveillance of Obesity Prevalence,Understanding the social environmental around obesity has been limited by available data. One promising approach used to bridge similar gaps elsewhere is to use passively generated digital data.
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Phased array systems in silicon,Description not available
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing",Preventing pandemics via international development: a systems approach,"Tiffany Bogich and colleagues find that breakdown or absence of public health infrastructure is most often the driver in pandemic outbreaks, whose prevention requires mainstream development funding rather than emergency funding."
Rumi Chunara,https://scholar.google.com/citations?user=7NhhkR8AAAAJ&hl=en,"ML/AI in Public Health, Data Science, Health Inequities, Social Computing","Determinants of Participants’ Follow-Up and Characterization of Representativeness in Flu Near You, A Participatory Disease Surveillance System",Background: Flu Near You (FNY) is an Internet-based participatory surveillance system in the United States and Canada that allows volunteers to report influenza-like symptoms using a brief weekly symptom report.
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Security and privacy considerations in digital death,"Death is an uncomfortable subject for many people, and digital systems are rarely designed to deal with this event. In particular, the wide array of existing digital authentication infrastructure rarely deals with gracefully retiring credentials in a uniform fashion."
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",A model for summer undergraduate research experiences in emerging technologies,"Integrating emerging technologies into the curriculum is expected in our evolving discipline, although finding the time to master these can prove difficult. Institutional expectations for scholarly achievement need not take precedence; the use of an overarching theme for a summer research experience is presented as one approach to join a group of people with a unifying topic for study and discussion leading to the natural incorporation of the emergent technology into the curriculum.This paper presents a successful model for undergraduate summer research where participants, both faculty and students, investigated information security (IS) topics and learned from IS professionals. This was applied to individual research projects in disconnected areas in computing. The unifying experiences encouraged a collegial and supportive environment, firmly establishing peer and faculty / student collaboration. Student …"
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Model driven development of a service oriented architecture (SOA) using colored Petri nets,"Service-Oriented Architecture (SOA) is achieving widespread acceptance in a variety of enterprise systems, due to its inherent flexibility and interoperability, improving upon the more tradition and less supportable “stovepipe” approach. The high degree of concurrency and both synchronous and asynchronous communications inherent in SOA makes it a good candidate for a Petri Nets based model driven development (MDD). Such an approach, with its underlying verification and validation implications, becomes more crucial in mission-critical applications, such as those with defense implications. This paper reports on our experience with using Colored Petri Nets (CPNs) for model driven development and quality assessment of a defense-targeted serviceoriented software architecture. We identify features of CPN that have resulted in ease of adoption as a modeling tool in our present setting. Preliminary results are provided which support the use of CPNs as a basis for model driven software development, and verification and validation (V&V) for quality assurance of highly concurrent and mission-critical SOAs."
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Java interface for asserting interactive telerobotic control,Description not available
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Programming with Alice and Java,"To ease readers into Java, Programming with Alice and Javaintertwines the ideas of object-oriented programming in both languages. Programming in Alice is explored first to establish fundamental principles and skills using 3D animations in a fun, visually rich environment. With Alice as a foundation, Chapter 6 introduces readers to Java. The remaining chapters implement concepts in the Java programming language using interesting examples and drawing parallels between the two languages to keep readers engaged. Alice: Objects; Methods and Data; Control Statements; Events; Lists and Arrays. Java: Objects and Classes; Events; Lists and Arrays; Inheritance; Exceptions and I/O; Recursion. For all readers interested in an introduction to programming using Alice and Java."
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Evaluation of subsetting programming language elements in a novice's programming environment,"In this paper, we evaluate the effects of applying programming language subsets to the programming environment used by novice (CS1) students in a closed-laboratory setting, as well as reducing the complexity of the user interface for the environment. Our goal in this effort was to assess if such interface and application-level changes adversely impact the student or hinder the later migration to a traditional professional-strength programming environment.We focus on the comparison of the quantitative data captured from the closed-laboratory sessions (assignment grades, number of syntax / semantic errors, and the number of compilation / execution attempts) involving subjects that used a new programming environment featuring a less complex interface in two forms: one lacking support of language subsets, and one supporting the application of language subsets.We found that while using the environment …"
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Implications on the learning of programming through the implementation of subsets in program development environments,"The undergraduate Computer Science program at Virginia Tech is the largest in the Commonwealth of Virginia, of which a key component is “CS 1044: Introduction to Programming”, and is typical of a first course in computer programming throughout the USA. While the student access to learning resources has improved considerably with the development of web-based assets, students are still expected to use the same sophisticated program development tools as are used in industry. The perceived complexity of the learning environment currently in use drives many women and minority students from the Computer Science program. A great deal of attention has been paid to the need to administer the student assignments and the grading system for this course, so as to minimize the teaching/grading load, but little attention has been paid to the methodologies of learning the material through practice. The work …"
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Java Foundations: Introduction to program design and data structures,"Inspired by the success of their best-selling introductory programming text, Java Software Solutions, authors Lewis, DePasquale, and Chase now release Java Foundations, Second Edition. This text is a comprehensive resource for instructors who want a two-or three-semester introduction to programming textbook that includes detail on data structures topics. Java Foundations introduces a Software Methodology early on and revisits it throughout to ensure students develop sound program development skills from the beginning. Control structures are covered before writing classes, providing a solid foundation of fundamental concepts and sophisticated topics."
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Subsetting language elements in novice programming environments,"This author has concerns of two issues with respect to student instruction in CS1 courses (1st semester programming courses). The first is that novice programming students need not be exposed to professional strength programming tools so early on in their curriculum. Many of these environments have highly complex interfaces and include a plethora of features and tools (including profilers, project management features, etc.) which are not needed initially by novice programmers. In the author's experience, many times these additional"" features"" only confuse and frustrate the student. Secondly, I argue that a novice programmer's environment should grow in lockstep with their in-class experience. Novice programmers generally are introduced to simple, stand-alone concepts that can be easily digested and understood. Further concepts are then added in an iterative manner as additional language elements are introduced. In essence, what educators are doing in the classroom is subsetting a programming language and introducing successive supersets to the student participants. The programming environment novice programmers utilize should be modeled after the pedagogical style used in the classroom."
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Exploiting on-line data sources as the basis of programming projects,"The Internet is an exciting place to find real, interesting, and interactive sources of data for use in the classroom. This data (often real world), can provide the basis of interesting projects for CS1 and CS2 courses. Additionally, the source or exchange protocol can be used as a gentle introduction for novice computer science majors to the myriad of data formats and emerging technologies available today. Presented here are a number of interesting data sources used during the 2004-2005 academic year in our own CS2 data structures course."
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",//todo: Help students improve commenting practices,Description not available
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty","A model for summer undergraduate research experiences in emerging technologies, proceedings of the 37th SIGCSE Technical Symposium on Computer Science Education",Description not available
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Bringing industry into the university experience,A large percentage of students in any computing program will graduate and take jobs in industry. Part of the challenge in the college curriculum is creating real-world experiences for students while still in school that will help prepare them for the challenges that lay ahead in their future work in professional practice. This panel will examine different approaches to providing students with industry experiences and perspectives while they are still students to help better prepare them for their professional lives.
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Identifying effective pedagogical practices for commenting computer source code,"Few, if any, pedagogical practices exist for helping students embrace best practices in writing software documentation, particularly source code comments. Although instructors often stress the importance of good commenting, two problems exist. First, it can be difficult to actually define these best practices, and second, it can be difficult to grade or assess students' application of such methods/practices. This Birds-of-a-Feather session focuses on capturing for dissemination a concrete list of code commenting best practices used by the attendees as they teach their classes."
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Teaching students effective practices for commenting computer source code: tutorial presentation,"Tired of slogging through pages of printouts to grade student source code comments? Are your eyes burning from reading dense, unorganized, and unstructured comments? Are you thirsting in a desert of code bereft of comments explaining what the program does? Do your students feel like documentation is a waste of time and effort?"
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Getting started with cloud services: a hands-on workshop,"The proliferation of high-speed (wired and wireless) networks has enabled cloud computing as a viable solution for many hosted computing needs. Beyond the hype, cloud computing provides a robust platform for large scale computing resources in a pay-as-you-need-them model. This commoditization goes beyond hosted servers, extending to storage, databases, domain name resolution, and many other aspects of a traditional IT infrastructure. In this workshop, we will use the Amazon Web Services (AWS) offerings to introduce cloud computing and we as computer science educators can leverage these services in our classrooms and across the curriculum."
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Getting started with the Amazon cloud: introduction and discussion of curriculum integration,"The proliferation of high speed (wired and wireless) networks has enabled cloud computing as a viable solution for many hosted computing needs. Beyond the hype, cloud computing provides a robust platform for large scale computing resources in a pay-as-you-need-them model. This commoditization goes beyond hosted servers, extending to storage, databases, domain name resolution, and many other aspects of a traditional IT infrastructure. In this session, we will explore the multiple Amazon Web Services (AWS) offerings to introduce cloud computing and how as computer science educators we can leverage these services in our classrooms and across the curriculum."
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Getting started with the Amazon cloud: a hands-on experience,"In this section session, we will explore the Amazon Web Services (AWS) offerings directly through through hands-on activities involving the hosted virtual servers, databases, email service and more. Participants should be comfortable with using ssh to connect to UNIX servers, compiling and executing Java code, downloading and uncompressing files via the command line, and general UNIX command line activities (cd, more, vi, etc.). [Participation in the previous tutorial, Getting Started with the Amazon Cloud: Introduction and Discussion of Curriculum Integration, is recommended, but not required.]"
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",//TODO: Help students improve commenting practices,"One implicit purpose of writing software code is to communicate ideas. Commenting source code helps explain these ideas and provides background on the semantics of a program. Yet, enabling students to acquire good commenting practices remains difficult. Instructors can find it hard to meaningfully discuss such practices in both introductory and advanced undergraduate courses. Furthermore, comment grading is an imprecise, labor-intensive procedure at best. But just what practices should we be encouraging students to emulate? To help address these issues (learning about professional code commenting patterns and best practices, objectively grading student comments), we developed the COMTOR tool as an open source project and web service. COMTOR provides a platform for helping assess source code documentation in an objective, structured fashion. We conducted two experiments using COMTOR …"
Peter DePasquale,https://scholar.google.com/citations?user=ScyBbe8AAAAJ&hl=en,"Computer Science Education, Cloud Computing, Web Development and Secuirty",Exploiting on-line data sources in the data structures course (and elsewhere),"The Internet provides a rich data source for student projects across the curriculum. As such, several years ago I set out to broaden my students' familiarity and knowledge of such topics as XML, RSS, 3rd-party APIs, URLs, and the like by including live data obtained in real-time in their data structures projects, rather than using static data (class enrollment lists, etc.). The response by the students was encouraging, as they had the opportunity to explore technical subjects of which they often had a cursory knowledge."
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Facebook users have become much more private: A large-scale study,Description not available
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Estimating age privacy leakage in online social networks,Description not available
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",An analysis of united states online political advertising transparency,Description not available
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Topology mapping and geolocating for China's Internet,Description not available
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",A closer look at third-party OSN applications: are they leaking your personal information?,"We examine third-party Online Social Network (OSN) applications for two major OSNs: Facebook and RenRen. These third-party applications typically gather, from the OSN, user personal information. We develop a measurement platform to study the interaction between OSN applications and fourth parties. We use this platform to study the behavior of 997 Facebook applications and 377 RenRen applications. We find that the Facebook and RenRen applications interact with hundreds of different fourth-party tracking entities. More worrisome, 22% of Facebook applications and 69% of RenRen applications provide users’ personal information to one or more fourth-party tracking entities."
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",China’s Internet: Topology Mapping and Geolocating,Description not available
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Profiling high-school students with facebook: how online privacy laws can actually increase minors' risk,"Lawmakers, children's advocacy groups and modern society at large recognize the importance of protecting the Internet privacy of minors (under 18 years of age). Online Social Networks, in particular, take precautions to prevent third parties from using their services to discover and profile minors. These precautions include displaying only minimal information in registered minors' public profiles, not listing minors when searching for users by high school or city, and banning young children from joining altogether. In this paper we show how an attacker can circumvent these precautions. We develop efficient crawling and data mining methodologies to discover and profile most of the high school students in a targeted high school. In particular, using Facebook and for a given target high school, the methodology finds most of the students in the school, and for each discovered student infers a profile that includes …"
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",The city privacy attack: Combining social media and public records for detailed profiles of adults and children,"Data brokers have traditionally collected data from businesses, government records, and other publicly available offline sources. While each data source may provide only a few elements about a person's activities, data brokers combine these elements to form a detailed, composite view of the consumer's life. The emergence of social media gives data brokers unprecedented opportunities to enhance their profiles. Data brokers are increasingly interested in combining the information collected from offline sources with information publicly available in social networks to profile not only adults but also children."
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",What is Zoom not telling you: Lessons from an online course during COVID-19,Description not available
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Estimating Heights from Photo Collections: A Data-Driven Approach,"A photo can potentially reveal a tremendous amount of information about an individual, including the individual's height, weight, gender, ethnicity, hair color, skin condition, interests, and wealth. A {\em photo collection} -- a set of inter-related photos including photos of many people appearing in two or more photos -- could potentially reveal a more vivid picture of the individuals in the collection."
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Online teaching amid COVID-19: the case of zoom,Description not available
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Data-Driven Privacy Attacks in Online Social Networks,"Online Social Networks (OSN) are now an integral part of people’s life. Users spend a lot of time on OSN sites and reveal a lot of personal information about themselves. At the same time, third party attackers such as insurance companies, data brokers, employment agencies, and government agencies are using OSNs to find their prey. OSNs are vulnerable to privacy leakages, whereby specific information about a user (political affiliation, sexual orientation, gender and so on) can sometimes be determined by a third party although the user does not intend to make the information available to the general public. In this thesis, we explore to what extent users’ private information can be inferred using data-driven technologies such as big data, machine learning and customized heuristics. We have exposed several data-driven privacy leakages in this thesis."
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Supplementary file of the TPDS manuscript,This supplementary file contains the supporting materials of the TPDS manuscript—“Stability-Optimal Grouping Strategy of Peer-to-Peer Systems.” It improves the solidity and completeness of the TPDS manuscript.
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Chameleon: Image Style Transfer Based on Image Classification Networks,Description not available
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",A closer look at third-party OSN applications,"We examine third-party Online Social Network (OSN) applications for two major OSNs: Facebook and RenRen. These third-party applications typically gather, from the OSN, user personal information. We develop a measurement platform to study the interaction between OSN applications and fourth parties. We use this platform to study the behavior of 997 Facebook applications and 377 RenRen applications. We find that the Facebook and RenRen applications interact with hundreds of different fourth-party tracking entities. More worrisome, 22% of Facebook applications and 69% of RenRen applications provide users' personal information to one or more fourth-party tracking entities.© 2014 Springer International Publishing Switzerland."
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Profiling high-school students with facebook,Description not available
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement","Technical Report: November 16, 2012","Lawmakers, children’s advocacy groups and mod-ern society at large recognize the importance of protecting the Internet privacy of minors (under 18 years of age). Online Social Networks, in particular, take precautions to prevent third parties from using their services to discover and profile minors. These precautions include banning young children from joining, not listing minors when searching for users by high school or city, and displaying only minimal information in registered minors’ public profiles, no matter how they configure their privacy settings."
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",SESOC 2012: Fourth International Workshop on SECurity and SOCial Networking 0 Program,"!""# $% $!""# $% $"" &'("")*+,**+!""""-.//'01 2 & 0/3. &'!'01 2 & 0/3-"" &/'01 3)***** 4! & $$%/%-$ &%! &%"" &)* 56* 57# $% &'(!!)"" 2 8#//& 3 9$: &#//& 3 9$';) 2#//& 9)* 5,* 7+*(1 $9< & $"" & 0/?//1&@"" &"" & 0/?//1&)*, A*,,.# $#-%@'9 8@')*, B* B*'(-= & 1 &//. 8$; 1; 1 &. 1 2-$. 0 2 (8. 1.)* B5* C6)/(& 8 D & 8$$# D & E 0/& 8$%/& D & 8$)* CA* C, xxxi"
Ratan Dey,https://scholar.google.com/citations?user=I0g7OHwAAAAJ&hl=en,"Privacy & Security, Online Social Networks, AI & Machine Learning, Big Data & Databases, Internet Measurement",Attacking Age Privacy in Online Social Networks,"Birth year is a fundamental human attribute, and for many people a private one. We have found that in our sample dataset of 1.47 million Facebook users from New York City, only 1.5% of them specify their age in their public profile, confirming that age is indeed a private attribute for most users. In this paper, we investigate whether it is possible to estimate the age of each of the remaining 98.5% of the the New York City Facebook users. To estimate Facebook user ages, we develop a novel two-step procedure. In the first step, we exploit side information such as high-school graduation year and high-school graduation years of friends with the same high school name to accurately estimate the age for a large set of users. In the second step, we exploit the underlying social network structure to design an iterative algorithm, which derives age estimates based on friends’s ages, friends of friends’ ages, and so on. Our overall methodology is able to estimate age of 84% users with a 4-year mean absolute error. However, we find that for many older users, age is difficult to estimate accurately, and may thus remain private within OSNs. We also develop a technique for another related privacy violation–classifying a user as a minor (under 18 years of age) or as an adult. Our work casts serious doubts on age privacy and children online privacy in OSNs."
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Badnets: Identifying vulnerabilities in the machine learning model supply chain,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Fine-pruning: Defending against backdooring attacks on deep neural networks,"Deep neural networks (DNNs) provide excellent performance across a wide range of classification tasks, but their training requires high computational resources and is often outsourced to third parties. Recent work has shown that outsourced training introduces the risk that a malicious trainer will return a backdoored DNN that behaves normally on most inputs but causes targeted misclassifications or degrades the accuracy of the network when a trigger known only to the attacker is present. In this paper, we provide the first effective defenses against backdoor attacks on DNNs. We implement three backdoor attacks from prior work and use them to investigate two promising defenses, pruning and fine-tuning. We show that neither, by itself, is sufficient to defend against sophisticated attackers. We then evaluate fine-pruning, a combination of pruning and fine-tuning, and show that it successfully weakens or even …"
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Badnets: Evaluating backdooring attacks on deep neural networks,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Starcoder: may the source be with you!,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Lava: Large-scale automated vulnerability addition,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Asleep at the keyboard? assessing the security of github copilot’s code contributions,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Virtuoso: Narrowing the semantic gap in virtual machine introspection,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Examining zero-shot vulnerability repair with large language models,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Robust signatures for kernel data structures,"Kernel-mode rootkits hide objects such as processes and threads using a technique known as Direct Kernel Object Manipulation (DKOM). Many forensic analysis tools attempt to detect these hidden objects by scanning kernel memory with handmade signatures; however, such signatures are brittle and rely on non-essential features of these data structures, making them easy to evade. In this paper, we present an automated mechanism for generating signatures for kernel data structures and show that these signatures are robust: attempts to evade the signature by modifying the structure contents will cause the OS to consider the object invalid. Using dynamic analysis, we profile the target data structure to determine commonly used fields, and we then fuzz those fields to determine which are essential to the correct operation of the OS. These fields form the basis of a signature for the data structure. In our experiments …"
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Repeatable reverse engineering with PANDA,"We present PANDA, an open-source tool that has been purpose-built to support whole system reverse engineering. It is built upon the QEMU whole system emulator, and so analyses have access to all code executing in the guest and all data. PANDA adds the ability to record and replay executions, enabling iterative, deep, whole system analyses. Further, the replay log files are compact and shareable, allowing for repeatable experiments. A nine billion instruction boot of FreeBSD, e.g., is represented by only a few hundred MB. PANDA leverages QEMU's support of thirteen different CPU architectures to make analyses of those diverse instruction sets possible within the LLVM IR. In this way, PANDA can have a single dynamic taint analysis, for example, that precisely supports many CPUs. PANDA analyses are written in a simple plugin architecture which includes a mechanism to share functionality between plugins …"
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Forensic analysis of the Windows registry in memory,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",The VAD tree: A process-eye view of physical memory,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Lost at c: A user study on the security implications of large language model code assistants,"Large Language Models (LLMs) such as OpenAI Codex are increasingly being used as AI-based coding assistants. Understanding the impact of these tools on developers’ code is paramount, especially as recent work showed that LLMs may suggest cybersecurity vulnerabilities. We conduct a security-driven user study (N= 58) to assess code written by student programmers when assisted by LLMs. Given the potential severity of low-level bugs as well as their relative frequency in real-world projects, we tasked participants with implementing a singly-linked ‘shopping list’structure in C. Our results indicate that the security impact in this setting (low-level C with pointer and array manipulations) is small: AI-assisted users produce critical security bugs at a rate no greater than 10% more than the control, indicating the use of LLMs does not introduce new security risks."
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Tappan zee (north) bridge: mining memory accesses for introspection,"The ability to introspect into the behavior of software at runtime is crucial for many security-related tasks, such as virtual machine-based intrusion detection and low-artifact malware analysis. Although some progress has been made in this task by automatically creating programs that can passively retrieve kernel-level information, two key challenges remain. First, it is currently difficult to extract useful information from user-level applications, such as web browsers. Second, discovering points within the OS and applications to hook for active monitoring is still an entirely manual process. In this paper we propose a set of techniques to mine the memory accesses made by an operating system and its applications to locate useful places to deploy active monitoring, which we call tap points. We demonstrate the efficacy of our techniques by finding tap points for useful introspection tasks such as finding SSL keys and …"
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Benchmarking large language models for automated verilog rtl code generation,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Verigen: A large language model for verilog code generation,"In this study, we explore the capability of Large Language Models (LLMs) to automate hardware design by automatically completing partial Verilog code, a common language for designing and modeling digital systems. We fine-tune pre-existing LLMs on Verilog datasets compiled from GitHub and Verilog textbooks. We evaluate the functional correctness of the generated Verilog code using a specially designed test suite, featuring a custom problem set and testing benches. Here, our fine-tuned open-source CodeGen-16B model outperforms the commercial state-of-the-art GPT-3.5-turbo model with a 1.1% overall increase. Upon testing with a more diverse and complex problem set, we find that the fine-tuned model shows competitive performance against state-of-the-art gpt-3.5-turbo, excelling in certain scenarios. Notably, it demonstrates a 41% improvement in generating syntactically correct Verilog code across …"
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Danish Contractor,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Leveraging forensic tools for virtual machine introspection,Description not available
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Nnoculation: Catching badnets in the wild,"This paper proposes a novel two-stage defense (NNoculation) against backdoored neural networks (BadNets) that, repairs a BadNet both pre-deployment and online in response to backdoored test inputs encountered in the field. In the pre-deployment stage, NNoculation retrains the BadNet with random perturbations of clean validation inputs to partially reduce the adversarial impact of a backdoor. Post-deployment, NNoculation detects and quarantines backdoored test inputs by recording disagreements between the original and pre-deployment patched networks. A CycleGAN is then trained to learn transformations between clean validation and quarantined inputs; i.e., it learns to add triggers to clean validation images. Backdoored validation images along with their correct labels are used to further retrain the pre-deployment patched network, yielding our final defense. Empirical evaluation on a comprehensive …"
Brendan Dolan-Gavitt,https://scholar.google.com/citations?user=MzAxRscAAAAJ&hl=en,"Security, Machine Learning",Bug synthesis: Challenging bug-finding tools with deep faults,"In spite of decades of research in bug detection tools, there is a surprising dearth of ground-truth corpora that can be used to evaluate the efficacy of such tools. Recently, systems such as LAVA and EvilCoder have been proposed to automatically inject bugs into software to quickly generate large bug corpora, but the bugs created so far differ from naturally occurring bugs in a number of ways. In this work, we propose a new automated bug injection system, Apocalypse, that uses formal techniques—symbolic execution, constraint-based program synthesis and model counting—to automatically inject fair (can potentially be discovered by current bug-detection tools), deep (requiring a long sequence of dependencies to be satisfied to fire), uncorrelated (each bug behaving independent of others), reproducible (a trigger input being available) and rare (can be triggered by only a few program inputs) bugs in large software …"
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",The open provenance model core specification (v1. 1),Description not available
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Provenance and scientific workflows: challenges and opportunities,"Provenance in the context of workflows, both for the data they derive and for their specification, is an essential component to allow for result reproducibility, sharing, and knowledge re-use in the scientific community. Several workshops have been held on the topic, and it has been the focus of many research projects and prototype systems. This tutorial provides an overview of research issues in provenance for scientific workflows, with a focus on recent literature and technology in this area. It is aimed at a general database research audience and at people who work with scientific data and workflows. We will (1) provide a general overview of scientific workflows, (2) describe research on provenance for scientific workflows and show in detail how provenance is supported in existing systems; (3) discuss emerging applications that are enabled by provenance; and (4) outline open problems and new directions for …"
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Reproducibility and Replicability in Science,Description not available
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",VisTrails: visualization meets data management,"Scientists are now faced with an incredible volume of data to analyze. To successfully analyze and validate various hypothesis, it is necessary to pose several queries, correlate disparate data, and create insightful visualizations of both the simulated processes and observed phenomena. Often, insight comes from comparing the results of multiple visualizations. Unfortunately, today this process is far from interactive and contains many error-prone and time-consuming tasks. As a result, the generation and maintenance of visualizations is a major bottleneck in the scientific process, hindering both the ability to mine scientific data and the actual use of the data. The VisTrails system represents our initial attempt to improve the scientific discovery process and reduce the time to insight. In VisTrails, we address the problem of visualization from a data management perspective: VisTrails manages the data and metadata of a …"
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Provenance for computational tasks: A survey,Description not available
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Visual exploration of big spatio-temporal urban data: A study of new york city taxi trips,Description not available
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",The ALPS project release 2.0: open source software for strongly correlated systems,"We present release 2.0 of the ALPS (Algorithms and Libraries for Physics Simulations) project, an open source software project to develop libraries and application programs for the simulation of strongly correlated quantum lattice models such as quantum magnets, lattice bosons, and strongly correlated fermion systems. The code development is centered on common XML and HDF5 data formats, libraries to simplify and speed up code development, common evaluation and plotting tools, and simulation programs. The programs enable non-experts to start carrying out serial or parallel numerical simulations by providing basic implementations of the important algorithms for quantum lattice models: classical and quantum Monte Carlo (QMC) using non-local updates, extended ensemble simulations, exact and full diagonalization (ED), the density matrix renormalization group (DMRG) both in a static version and a …"
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Vistrails: Enabling interactive multiple-view visualizations,Description not available
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",From XML schema to relations: A cost-based approach to XML storage,Description not available
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Method and apparatus for web-site-independent personalization from multiple sites having user-determined extraction functionality,METHOD AND APPARATUS FOR WEB-SITE-INDEPENDENT PERSONALIZATION FROM MULTIPLE SITES HAVING USER-DETERMINED EXTRACTION FUNCTIONALITY
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Managing rapidly-evolving scientific workflows,"We give an overview of VisTrails, a system that provides an infrastructure for systematically capturing detailed provenance and streamlining the data exploration process. A key feature that sets VisTrails apart from previous visualization and scientific workflow systems is a novel action-based mechanism that uniformly captures provenance for data products and workflows used to generate these products. This mechanism not only ensures reproducibility of results, but it also simplifies data exploration by allowing scientists to easily navigate through the space of workflows and parameter settings for an exploration task."
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",The first provenance challenge,"The first Provenance Challenge was set up in order to provide a forum for the community to understand the capabilities of different provenance systems and the expressiveness of their provenance representations. To this end, a functional magnetic resonance imaging workflow was defined, which participants had to either simulate or run in order to produce some provenance representation, from which a set of identified queries had to be implemented and executed. Sixteen teams responded to the challenge, and submitted their inputs. In this paper, we present the challenge workflow and queries, and summarize the participants' contributions. Copyright © 2007 John Wiley & Sons, Ltd."
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",The open provenance model: An overview,"Provenance is well understood in the context of art or digital libaries, where it respectively refers to the documented history of an art object, or the documentation of processes in a digital object’s life cycle. Interest for provenance in the “e-science community” [12] is also growing, since provenance is perceived as a crucial component of workflow systems that can help scientists ensure reproducibility of their scientific analyses and processes [2,4]."
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Reprozip: Using provenance to support computational reproducibility,Description not available
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",ReproZip: computational reproducibility with ease,Description not available
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",A Large-scale Study about Quality and Reproducibility of Jupyter Notebooks,Description not available
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",An adaptive crawler for locating hidden-web entry points,"In this paper we describe new adaptive crawling strategies to efficiently locate the entry points to hidden-Web sources. The fact that hidden-Web sources are very sparsely distributedmakes the problem of locating them especially challenging. We deal with this problem by using the contents ofpages to focus the crawl on a topic; by prioritizing promisinglinks within the topic; and by also following links that may not lead to immediate benefit. We propose a new frameworkwhereby crawlers automatically learn patterns of promisinglinks and adapt their focus as the crawl progresses, thus greatly reducing the amount of required manual setup andtuning. Our experiments over real Web pages in a representativeset of domains indicate that online learning leadsto significant gains in harvest rates' the adaptive crawlers retrieve up to three times as many forms as crawlers thatuse a fixed focus strategy."
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",VeriWeb: Automatically testing dynamic web sites,"Web sites are becoming increasingly complex as more and more services and information are made available over the Internet and intranets. At the same time, the correct behavior of sites has become crucial to the success of businesses and organizations and thus should be tested thoroughly and frequently. Although traditional software testing is already a notoriously hard, time-consuming and expensive process, testing Web sites presents even greater challenges: Web interfaces are very dynamic; the environment of Web applications is more complex than that of typical monolithic or client-server applications; Web applications, most notably e-commerce sites, have a large number of users who have no training on how to use the application and hence are more likely to exercise it in unpredictable ways. Existing testing tools for automating the process of testing dynamic Web sites require the specification of test …"
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Method and apparatus for creating and providing personalized access to web content and services from terminals having diverse capabilities,METHOD AND APPARATUS FOR CREATING AND PROVIDING PERSONALIZED ACCESS TO WEB CONTENT AND SERVICES FROM TERMINALS HAVING DIVERSE CAPABILITIES
Juliana Freire,https://scholar.google.com/citations?user=sSzAlq0AAAAJ&hl=en,"data management, visualization, provenance, reproducibility, big data",Siphoning hidden-web data through keyword-based interfaces,"In this paper, we study the problem of automating the retrieval of data hidden behind simple search interfaces that accept keyword-based queries. Our goal is to automatically retrieve all available results (or, as many as possible). We propose a new approach to siphon hidden data that automatically generates a small set of representative keywords and builds queries which lead to high coverage. We evaluate our algorithms over several real Web sites. Preliminary results indicate our approach is effective: coverage of over 90% is obtained for most of the sites considered."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy","Detecting hoaxes, frauds, and deception in writing style online",Description not available
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",A critical evaluation of website fingerprinting attacks,"Recent studies on Website Fingerprinting (WF) claim to have found highly effective attacks on Tor. However, these studies make assumptions about user settings, adversary capabilities, and the nature of the Web that do not necessarily hold in practical scenarios. The following study critically evaluates these assumptions by conducting the attack where the assumptions do not hold. We show that certain variables, for example, user's browsing habits, differences in location and version of Tor Browser Bundle, that are usually omitted from the current WF model have a significant impact on the efficacy of the attack. We also empirically show how prior work succumbs to the base rate fallacy in the open-world scenario. We address this problem by augmenting our classification method with a verification step. We conclude that even though this approach reduces the number of false positives over 63\%, it does not completely …"
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",De-anonymizing programmers via code stylometry,"Source code authorship attribution is a significant privacy threat to anonymous code contributors. However, it may also enable attribution of successful attacks from code left behind on an infected system, or aid in resolving copyright, copyleft, and plagiarism issues in the programming fields. In this work, we investigate machine learning methods to de-anonymize source code authors of C/C++ using coding style. Our Code Stylometry Feature Set is a novel representation of coding style found in source code that reflects coding style from properties derived from abstract syntax trees."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Adversarial Stylometry: Circumventing Authorship Recognition to Preserve Privacy and Anonymity,Description not available
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Phishzoo: Detecting phishing websites by looking at them,Description not available
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy","Active authentication on mobile devices via stylometry, application usage, web browsing, and GPS location",Description not available
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Covert messaging through TCP timestamps,"Covert channels exist in most communications systems and allow individuals to communicate truly undectably. However, covert channels are seldom used due to their complexity. A protocol for sending data over a common class of low-bandwidth covert channels has been developed. The protocol is secure against attack by powerful adversaries. The design of a practical system implementing the protocol on a standard platform (Linux) exploiting a channel in a common communications system (TCP timestamps) is presented. A partial implementation of this system has been accomplished."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Doppelgänger finder: Taking stylometry to the underground,Description not available
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",When coding style survives compilation: De-anonymizing programmers from executable binaries,Description not available
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Use Fewer Instances of the Letter “i”: Toward Writing Style Anonymization,"This paper presents Anonymouth, a novel framework for anonymizing writing style. Without accounting for style, anonymous authors risk identification. This framework is necessary to provide a tool for testing the consistency of anonymized writing style and a mechanism for adaptive attacks against stylometry techniques. Our framework defines the steps necessary to anonymize documents and implements them. A key contribution of this work is this framework, including novel methods for identifying which features of documents need to change and how they must be changed to accomplish document anonymization. In our experiment, 80% of the user study participants were able to anonymize their documents in terms of a fixed corpus and limited feature set used. However, modifying pre-written documents were found to be difficult and the anonymization did not hold up to more extensive feature sets. It is …"
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Practical attacks against authorship recognition techniques,"The use of statistical AI techniques in authorship recognition (or stylometry) has contributed to literary and historical breakthroughs. These successes have led to the use of these techniques in criminal investigations and prosecutions. However, few have studied adversarial attacks and their devastating effect on the robustness of existing classification methods. This paper presents a framework for adversarial attacks including obfuscation attacks, where a subject attempts to hide their identity and imitation attacks, where a subject attempts to frame another subject by imitating their writing style. The major contribution of this research is that it demonstrates that both attacks work very well. The obfuscation attack reduces the effectiveness of the techniques to the level of random guessing and the imitation attack succeeds with 68-91% probability depending on the stylometric technique used. These results are made more significant by the fact that the experimental subjects were unfamiliar with stylometric techniques, without specialized knowledge in linguistics, and spent little time on the attacks. This paper also provides another significant contribution to the field in using human subjects to empirically validate the claim of high accuracy for current techniques (without attacks) by reproducing results for three representative stylometric methods."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Source code authorship attribution using long short-term memory based networks,"Machine learning approaches to source code authorship attribution attempt to find statistical regularities in human-generated source code that can identify the author or authors of that code. This has applications in plagiarism detection, intellectual property infringement, and post-incident forensics in computer security. The introduction of features derived from the Abstract Syntax Tree (AST) of source code has recently set new benchmarks in this area, significantly improving over previous work that relied on easily obfuscatable lexical and format features of program source code. However, these AST-based approaches rely on hand-constructed features derived from such trees, and often include ancillary information such as function and variable names that may be obfuscated or manipulated."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Why we can't be bothered to read privacy policies models of privacy economics as a lemons market,"Consumers want to interact with web sites, but they also want to keep control of their private information. Asymmetric information about whether web sites will sell private information or not leads to a lemons market for privacy. We discuss privacy policies as signals in a lemons market and ways in which current realizations of privacy policies may fail to be effective signals. As a result of these shortcomings, we consider a ""lemons market with testing,"" where consumers have a cost of determining whether a site meets their privacy requirement. Our model explains empirical data concerning privacy policies and privacy seals. We end by discussing cyclic instability in the number of web sites that sell consumer information."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Approaches to adversarial drift,"In this position paper, we argue that to be of practical interest, a machine-learning based security system must engage with the human operators beyond feature engineering and instance labeling to address the challenge of drift in adversarial environments. We propose that designers of such systems broaden the classification goal into an explanatory goal, which would deepen the interaction with system's operators."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Privacy detective: Detecting private information and collective privacy behavior in a large social network,"Detecting the presence and amount of private information being shared in online media is the first step towards analyzing information revealing habits of users in social networks and a useful method for researchers to study aggregate privacy behavior. In this work, we aim to find out if text contains private content by using our novel learning based approach `privacy detective' that combines topic modeling, named entity recognition, privacy ontology, sentiment analysis, and text normalization to represent privacy features. Privacy detective investigates a broader range of privacy concerns compared to previous approaches that focus on keyword searching or profile related properties. We collected 500,000 tweets from 100,000 Twitter users along with other information such as tweet linkages and follower relationships. We reach 95.45% accuracy in a two-class task classifying Twitter users who do not reveal much …"
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Analysis of privacy loss in distributed constraint optimization,"Distributed Constraint Optimization (DCOP) is rapidly emerging as a prominent technique for multiagent coordination. However, despite agent privacy being a key motivation for applying DCOPs in many applications, rigorous quantitative evaluations of privacy loss in DCOP algorithms have been lacking. Recently,[Maheswaran et al. 2005] introduced a framework for quantitative evaluations of privacy in DCOP algorithms, showing that some DCOP algorithms lose more privacy than purely centralized approaches and questioning the motivation for applying DCOPs. This paper addresses the question of whether state-of-the art DCOP algorithms suffer from a similar shortcoming by investigating several of the most efficient DCOP algorithms, including both DPOP and ADOPT. Furthermore, while previous work investigated the impact on efficiency of distributed contraint reasoning design decisions (eg constraint-graph topology, asynchrony, message-contents), this paper examines the privacy aspect of such decisions, providing an improved understanding of privacy-efficiency tradeoffs."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",Use of machine learning in big data analytics for insider threat detection,Description not available
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy",The tools and tactics used in intimate partner surveillance: An analysis of online infidelity forums,"Abusers increasingly use spyware apps, account compromise, and social engineering to surveil their intimate partners, causing substantial harms that can culminate in violence. This form of privacy violation, termed intimate partner surveillance (IPS), is a profoundly challenging problem to address due to the physical access and trust present in the relationship between the target and attacker. While previous research has examined IPS from the perspectives of survivors, we present the first measurement study of online forums in which (potential) attackers discuss IPS strategies and techniques. In domains such as cybercrime, child abuse, and human trafficking, studying the online behaviors of perpetrators has led to better threat intelligence and techniques to combat attacks. We aim to provide similar insights in the context of IPS. We identified five online forums containing discussion of monitoring cellphones and other means of surveilling an intimate partner, including three within the context of investigating relationship infidelity. We perform a mixed-methods analysis of these forums, surfacing the tools and tactics that attackers use to perform surveillance. Via qualitative analysis of forum content, we present a taxonomy of IPS strategies used and recommended by attackers, and synthesize lessons for technologists seeking to curb the spread of IPS."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy","Blogs, twitter feeds, and reddit comments: Cross-domain authorship attribution","Stylometry is a form of authorship attribution that relies on the linguistic information to attribute documents of unknown authorship based on the writing styles of a suspect set of authors. This paper focuses on the cross-domain subproblem where the known and suspect documents differ in the setting in which they were created. Three distinct domains, Twitter feeds, blog entries, and Reddit comments, are explored in this work. We determine that state-of-the-art methods in stylometry do not perform as well in cross-domain situations (34.3% accuracy) as they do in in-domain situations (83.5% accuracy) and propose methods that improve performance in the cross-domain setting with both feature and classification level techniques which can increase accuracy to up to 70%. In addition to testing these approaches on a large real world dataset, we also examine real world adversarial cases where an author is actively attempting to hide their identity. Being able to identify authors across domains facilitates linking identities across the Internet making this a key security and privacy concern; users can take other measures to ensure their anonymity, but due to their unique writing style, they may not be as anonymous as they believe."
Rachel Greenstadt,https://scholar.google.com/citations?user=FsbND-sAAAAJ&hl=en,"Computer Science, Artificial Intelligence, Computer Security, Privacy","Privacy, anonymity, and perceived risk in open collaboration: A study of Tor users and Wikipedians","This qualitative study examines privacy practices and concerns among contributors to open collaboration projects. We collected interview data from people who use the anonymity network Tor who also contribute to online projects and from Wikipedia editors who are concerned about their privacy to better understand how privacy concerns impact participation in open collaboration projects. We found that risks perceived by contributors to open collaboration projects include threats of surveillance, violence, harassment, opportunity loss, reputation loss, and fear for loved ones. We explain participants' operational and technical strategies for mitigating these risks and how these strategies affect their contributions. Finally, we discuss chilling effects associated with privacy loss, the need for open collaboration projects to go beyond attracting and educating participants to consider their privacy, and some of the social and …"
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Model-based compressive sensing,Description not available
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Sparse signal recovery using markov random fields,"Compressive Sensing (CS) combines sampling and compression into a single sub-Nyquist linear measurement process for sparse and compressible signals. In this paper, we extend the theory of CS to include signals that are concisely represented in terms of a graphical model. In particular, we use Markov Random Fields (MRFs) to represent sparse signals whose nonzero coefficients are clustered. Our new model-based reconstruction algorithm, dubbed Lattice Matching Pursuit (LaMP), stably recovers MRF-modeled signals using many fewer measurements and computations than the current state-of-the-art algorithms."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Collaborative deep learning in fixed topology networks,"There is significant recent interest to parallelize deep learning algorithms in order to handle the enormous growth in data and model sizes. While most advances focus on model parallelization and engaging multiple computing agents via using a central parameter server, aspect of data parallelization along with decentralized computation has not been explored sufficiently. In this context, this paper presents a new consensus-based distributed SGD (CDSGD)(and its momentum variant, CDMSGD) algorithm for collaborative deep learning over fixed topology networks that enables data parallelization as well as decentralized computation. Such a framework can be extremely useful for learning agents with access to only local/private data in a communication constrained environment. We analyze the convergence properties of the proposed algorithm with strongly convex and nonconvex objective functions with fixed and diminishing step sizes using concepts of Lyapunov function construction. We demonstrate the efficacy of our algorithms in comparison with the baseline centralized SGD and the recently proposed federated averaging algorithm (that also enables data parallelism) based on benchmark datasets such as MNIST, CIFAR-10 and CIFAR-100."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Solving linear inverse problems using gan priors: An algorithm with provable guarantees,Description not available
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Random projections for manifold learning,"We propose a novel method for {\em linear} dimensionality reduction of manifold modeled data. First, we show that with a small number of {\em random projections} of sample points in $\reals^ N $ belonging to an unknown -dimensional Euclidean manifold, the intrinsic dimension (ID) of the sample set can be estimated to high accuracy. Second, we rigorously prove that using only this set of random projections, we can estimate the structure of the underlying manifold. In both cases, the number random projections required is linear in and logarithmic in , meaning that $ K"
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",An introduction to compressive sensing,2.1 Introduction to vector spaces................................................................ 5 2.2 Bases and frames............................................................................ 7 2.3 Sparse representations....................................................................... 8 2.4 Compressible signals........................................................................ 11 3 Sensing Matrices
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Semantic adversarial attacks: Parametric transformations that fool deep classifiers,"Deep neural networks have been shown to exhibit an intriguing vulnerability to adversarial input images corrupted with imperceptible perturbations. However, the majority of adversarial attacks assume global, fine-grained control over the image pixel space. In this paper, we consider a different setting: what happens if the adversary could only alter specific attributes of the input image? These would generate inputs that might be perceptibly different, but still natural-looking and enough to fool a classifier. We propose a novel approach to generate such"" semantic"" adversarial examples by optimizing a particular adversarial loss over the range-space of a parametric conditional generative model. We demonstrate implementations of our attacks on binary classifiers trained on face images, and show that such natural-looking semantic adversarial examples exist. We evaluate the effectiveness of our attack on synthetic and real data, and present detailed comparisons with existing attack methods. We supplement our empirical results with theoretical bounds that demonstrate the existence of such parametric adversarial examples."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Recovery of clustered sparse signals from compressive measurements,"We introduce a new signal model, called (K, C)-sparse, to capture K-sparse signals in N dimensions whose nonzero coefficients are contained within at most C clusters, with C< K<< N. In contrast to the existing work in the sparse approximation and compressive sensing literature on block sparsity, no prior knowledge of the locations and sizes of the clusters is assumed. We prove that O (K+ C log (N/C))) random projections are sufficient for (K, C)-model sparse signal recovery based on subspace enumeration. We also provide a robust polynomialtime recovery algorithm for (K, C)-model sparse signals with provable estimation guarantees."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",A nearly-linear time framework for graph-structured sparsity,"We introduce a framework for sparsity structures defined via graphs. Our approach is flexible and generalizes several previously studied sparsity models. Moreover, we provide efficient projection algorithms for our sparsity model that run in nearly-linear time. In the context of sparse recovery, we show that our framework achieves an information-theoretically optimal sample complexity for a wide range of parameters. We complement our theoretical analysis with experiments demonstrating that our algorithms improve on prior work also in practice."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",NuMax: a convex approach for learning near-isometric linear embeddings,Description not available
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Algorithmic guarantees for inverse imaging with untrained network priors,"Deep neural networks as image priors have been recently introduced for problems such as denoising, super-resolution and inpainting with promising performance gains over hand-crafted image priors such as sparsity. Unlike learned generative priors they do not require any training over large datasets. However, few theoretical guarantees exist in the scope of using untrained network priors for inverse imaging problems. We explore new applications and theory for untrained neural network priors. Specifically, we consider the problem of solving linear inverse problems, such as compressive sensing, as well as non-linear problems, such as compressive phase retrieval. We model images to lie in the range of an untrained deep generative network with a fixed seed. We further present a projected gradient descent scheme that can be used for both compressive sensing and phase retrieval and provide rigorous theoretical guarantees for its convergence. We also show both theoretically as well as empirically that with deep neural network priors, one can achieve better compression rates for the same image quality as compared to when hand crafted priors are used."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",On the computational complexity of self-attention,"Transformer architectures have led to remarkable progress in many state-of-art applications. However, despite their successes, modern transformers rely on the self-attention mechanism, whose time-and space-complexity is quadratic in the length of the input. Several approaches have been proposed to speed up self-attention mechanisms to achieve sub-quadratic running time; however, the large majority of these works are not accompanied by rigorous error guarantees. In this work, we establish lower bounds on the computational complexity of self-attention in a number of scenarios. We prove that the time complexity of self-attention is necessarily quadratic in the input length, unless the Strong Exponential Time Hypothesis (SETH) is false. This argument holds even if the attention computation is performed only approximately, and for a variety of attention mechanisms. As a complement to our lower bounds, we show that it is indeed possible to approximate dot-product self-attention using finite Taylor series in linear-time, at the cost of having an exponential dependence on the polynomial order."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Joint manifolds for data fusion,Description not available
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Approximation algorithms for model-based compressive sensing,Description not available
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",When do neural nets outperform boosted trees on tabular data?,"Tabular data is one of the most commonly used types of data in machine learning. Despite recent advances in neural nets (NNs) for tabular data, there is still an active discussion on whether or not NNs generally outperform gradient-boosted decision trees (GBDTs) on tabular data, with several recent works arguing either that GBDTs consistently outperform NNs on tabular data, or vice versa. In this work, we take a step back and question the importance of this debate. To this end, we conduct the largest tabular data analysis to date, comparing 19 algorithms across 176 datasets, and we find that the'NN vs. GBDT'debate is overemphasized: for a surprisingly high number of datasets, either the performance difference between GBDTs and NNs is negligible, or light hyperparameter tuning on a GBDT is more important than choosing between NNs and GBDTs. Next, we analyze dozens of metafeatures to determine what\emph {properties} of a dataset make NNs or GBDTs better-suited to perform well. For example, we find that GBDTs are much better than NNs at handling skewed or heavy-tailed feature distributions and other forms of dataset irregularities. Our insights act as a guide for practitioners to determine which techniques may work best on their dataset. Finally, with the goal of accelerating tabular data research, we release the TabZilla Benchmark Suite: a collection of the 36'hardest'of the datasets we study. Our benchmark suite, codebase, and all raw results are available at https://github. com/naszilla/tabzilla."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Spatiotemporally Constrained Action Space Attacks on Deep Reinforcement Learning Agents,"Robustness of Deep Reinforcement Learning (DRL) algorithms towards adversarial attacks in real world applications such as those deployed in cyber-physical systems (CPS) are of increasing concern. Numerous studies have investigated the mechanisms of attacks on the RL agent's state space. Nonetheless, attacks on the RL agent's action space (corresponding to actuators in engineering systems) are equally perverse, but such attacks are relatively less studied in the ML literature. In this work, we first frame the problem as an optimization problem of minimizing the cumulative reward of an RL agent with decoupled constraints as the budget of attack. We propose the white-box Myopic Action Space (MAS) attack algorithm that distributes the attacks across the action space dimensions. Next, we reformulate the optimization problem above with the same objective function, but with a temporally coupled constraint on the attack budget to take into account the approximated dynamics of the agent. This leads to the white-box Look-ahead Action Space (LAS) attack algorithm that distributes the attacks across the action and temporal dimensions. Our results showed that using the same amount of resources, the LAS attack deteriorates the agent's performance significantly more than the MAS attack. This reveals the possibility that with limited resource, an adversary can utilize the agent's dynamics to malevolently craft attacks that causes the agent to fail. Additionally, we leverage these attack strategies as a possible tool to gain insights on the potential vulnerabilities of DRL agents."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Compressive sensing recovery of spike trains using a structured sparsity model,Description not available
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Sampling and recovery of pulse streams,Description not available
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation",Fast and near-optimal algorithms for approximating distributions by histograms,"Histograms are among the most popular structures for the succinct summarization of data in a variety of database applications. In this work, we provide fast and near-optimal algorithms for approximating arbitrary one dimensional data distributions by histograms."
Chinmay Hegde,https://scholar.google.com/citations?user=eJAV17IAAAAJ&hl=en,"Machine Learning, Algorithms, Signal Processing, Materials Design, Transportation","Fast, sample-efficient algorithms for structured phase retrieval","We consider the problem of recovering a signal x in R^ n, from magnitude-only measurements, yi=| ai^ T x| for i={1, 2... m}. Also known as the phase retrieval problem, it is a fundamental challenge in nano-, bio-and astronomical imaging systems, astronomical imaging, and speech processing. The problem is ill-posed, and therefore additional assumptions on the signal and/or the measurements are necessary. In this paper, we first study the case where the underlying signal x is s-sparse. We develop a novel recovery algorithm that we call Compressive Phase Retrieval with Alternating Minimization, or CoPRAM. Our algorithm is simple and can be obtained via a natural combination of the classical alternating minimization approach for phase retrieval, with the CoSaMP algorithm for sparse recovery. Despite its simplicity, we prove that our algorithm achieves a sample complexity of O (s^ 2 log n) with Gaussian samples, which matches the best known existing results. It also demonstrates linear convergence in theory and practice and requires no extra tuning parameters other than the signal sparsity level s. We then consider the case where the underlying signal x arises from to structured sparsity models. We specifically examine the case of block-sparse signals with uniform block size of b and block sparsity k= s/b. For this problem, we design a recovery algorithm that we call Block CoPRAM that further reduces the sample complexity to O (ks log n). For sufficiently large block lengths of b= Theta (s), this bound equates to O (s log n). To our knowledge, this constitutes the first end-to-end linearly convergent family of algorithms for phase retrieval where …"
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Learning read-once formulas with queries,"A read-once formula is a Boolean formula in which each variable occurs, at most, once. Such formulas are also called μ-formulas or Boolean trees. This paper treats the problem of exactly identifying an unknown read-once formula using specific kinds of queries."
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Coding techniques for handling failures in large disk arrays,"A crucial issue in the design of very large disk arrays is the protection of data against catastrophic disk failures. Although today single disks are highly reliable, when a disk array consists of 100 or 1000 disks, the probability that at least one disk will fail within a day or a week is high. In this paper we address the problem of designing erasure-correcting binary linear codes that protect against the loss of data caused by disk failures in large disk arrays. We describe how such codes can be used to encode data in disk arrays, and give a simple method for data reconstruction. We discuss important reliability and performance constraints of these codes, and show how these constraints relate to properties of the parity check matrices of the codes. In so doing, we transform code design problems into combinatorial problems. Using this combinatorial framework, we present codes and prove they are optimal with respect …"
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Failure correction techniques for large disk arrays,"The ever increasing need for I/O bandwidth will be met with ever larger arrays of disks. These arrays require redundancy to protect against data loss. This paper examines alternative choices for encodings, or codes, that reliably store information in disk arrays. Codes are selected to maximize mean time to data loss or minimize disks containing redundant data, but are all constrained to minimize performance penalties associated with updating information or recovering from catastrophic disk failures. We also codes that give highly reliable data storage with low redundant data overhead for arrays of 1000 information disks."
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,How many queries are needed to learn?,"We investigate the query complexity of exact learning in the membership and (proper) equivalence query model. We give a complete characterization of concept classes that are learnable with a polynomial number of polynomial sized queries in this model. We give applications of this characterization, including results on learning a natural subclass of DNF formulas, and on learning with membership queries alone. Query complexity has previously been used to prove lower bounds on the time complexity of exact learning. We show a new relationship between query complexity and time complexity in exact learning: If any “honest” class is exactly and properly learnable with polynomial query complexity, but not learnable in polynomial time, then P = NP. In particular, we show that an honest class is exactly polynomial-query learnable if and only if it is learnable using an oracle for Γp4."
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Coding techniques for handling failures in large disk arrays,"The ever increasing need for I/O bandwidth will be met with ever larger arrays of disks. These arrays require redundancy to protect against data loss. This paper examines alternative choices for encodings, or codes, that reliably store information in disk arrays. Codes are selected to maximize mean time to data loss or minimize disks containing redundant data, but are all constrained to minimize performance penalties associated with updating information or recovering from catastrophic disk failures. We show codes that give highly reliable data storage with low redundant data overhead for arrays of 1000 information disks."
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Learning in the presence of finitely or infinitely many irrelevant attributes,Description not available
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,On compression-based text classification,"Compression-based text classification methods are easy to apply, requiring virtually no preprocessing of the data. Most such methods are character-based, and thus have the potential to automatically capture non-word features of a document, such as punctuation, word-stems, and features spanning more than one word. However, compression-based classification methods have drawbacks (such as slow running time), and not all such methods are equally effective. We present the results of a number of experiments designed to evaluate the effectiveness and behavior of different compression-based text classification methods on English text. Among our experiments are some specifically designed to test whether the ability to capture non-word (including super-word) features causes character-based text compression methods to achieve more accurate classification."
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Equational characterizations of Boolean function classes,Description not available
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Learning arithmetic read-once formulas,"A formula is read-once if each variable appears at most once in it. An arithmetic read-once formula is one in which the operators are addition, subtraction, multiplication, and division. We present polynomial time algorithm for exactly learning (or interpolating) arithmetic read-once formulas computing functions over a field. We present an algorithm that uses randomized membership queries (or substitutions) to identify such formulas over large finite fields and infinite fields. We also present a deterministic algorithm that uses equivalence queries as well as membership queries to identify arithmetic read-once formulas over small finite fields. We then non-constructively show the existence of deterministic membership query (interpolation) algorithms for arbitrary formulas over fields of characteristic 0 and for division-free formulas over large or infinite fields. Our algorithms assume we are able to efficiently perform arithmetic …"
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Minimizing Disjunctive Normal Form Formulas and Circuits Given a Truth Table,"For circuit classes R, the fundamental computational problem Min-R asks for the minimum R-size of a Boolean function presented as a truth table. Prominent examples of this problem include Min-DNF, which asks whether a given Boolean function presented as a truth table has a k-term disjunctive normal form (DNF), and Min-Circuit (also called the minimum circuit size problem (MCSP)), which asks whether a Boolean function presented as a truth table has a size k Boolean circuit. We present a new reduction proving that Min-DNF is NP-complete. It is significantly simpler than the known reduction of Masek [Some NP-Complete Set Covering Problems, manuscript, 1979], which is from Circuit-SAT. We then give a more complex reduction, yielding the result that Min-DNF cannot be approximated to within a factor smaller than , for some constant , assuming that NP is not contained in quasi-polynomial time. The standard …"
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Attribute-efficient learning in query and mistake-bound models,"We consider the problem of attribute-e ficient learning in query and mistake-bound models. Attribute-efficient algorithms make a number of queries or mistakes that is polynomial in the number of relevant variables in the target function, but only sublinear in the number of irrelevant variables. We consider a variant of the membership query model in which the learning algorithm is given as input the number of relevant variables of the target function. Using a number-theoretic coloring technique, we show that in this model, any class of functions (including parity) that can be learned in polynomial time can be learned attributeefficiently in polynomial time. We show that this does not hold in the randomized membership query model. In the mistake-bound model, we consider the problem of learning attribute-efficiently using hypotheses that are formulas of small depth. Our results extend the work of Blum et al.[3] and Bshouty …"
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Approximation algorithms for stochastic boolean function evaluation and stochastic submodular set cover,We present approximation algorithms for two problems: Stochastic Boolean Function Evaluation (SBFE) and Stochastic Submodular Set Cover (SSSC). Our results for SBFE problems are obtained by reducing them to SSSC problems through the construction of appropriate utility functions.
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Read-thrice DNF is hard to learn with membership and equivalence queries,"A general technique is developed to obtain nonlearnability results in the model of exact learning from equivalence and membership queries. The technique is applied to show that, assuming NP not= co-NP, there does not exist a polynomial-time membership and equivalence query algorithm for exactly learning read-thrice DNF formulas-boolean formulas in disjunctive normal form where each variable appears at most three times. This result adds evidence to the conjecture that DNF is hard to learn in the membership and equivalence query model."
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,PAC learning with irrelevant attributes,Description not available
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Complexity theoretic hardness results for query learning,"We investigate the complexity of learning for the well-studied model in which the learning algorithm may ask membership and equivalence queries. While complexity theoretic techniques have previously been used to prove hardness results in various learning models, these techniques typically are not strong enough to use when a learning algorithm may make membership queries. We develop a general technique for proving hardness results for learning with membership and equivalence queries (and for more general query models). We apply the technique to show that, assuming $ {\rm NP} \neq \hbox {\rm co-NP} $, no polynomial-time membership and (proper) equivalence query algorithms exist for exactly learning read-thrice DNF formulas, unions of halfspaces over the Boolean domain, or some other related classes. Our hardness results are representation dependent, and do not preclude the …"
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Learning boolean read-once formulas with arbitrary symmetric and constant fan-in gates,"A formula is read-once if each variable appears on at most a single input. Angluin, Hellerstein, and Karpinski have shown that boolean formulas with AND, OR, and NOT gates are exactly identifiable in polynomial time using membership and equivalence queries [AHK89]. Hancock and Hellerstein have generalized this to allow a wider subclass of symmetric basis functions [HH91]. We show a polynomial time algorithm in this model for identifying read-once formulas whose gates compute arbitrary functions of fan-in k or less for some constant k (i.e. any f :{0,1}1≤c≤k → {0,1}). We further show that if there is a polynomial time membership and equivalence query algorithm to identify read-once formulas over some set of functions B that meets certain technical conditions, then there is also such an algorithm to identify read-once formulas over Bυ{f:{0,1}1≤c≤k → {0,1}}. Finally, we extend the previous results to show that …"
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Learning read-once formulas over fields and extended bases,"A polynomial-time algorithm is presented for exactly learning the class of read-twice DNF formulas, ie Boolean formulas in disjunctive normal form where each variable appears at most twice. The (standard) protocol used allows the learning algorithm to..."
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Learning read-once formulas with queries,"A read-once formula is a boolean formula in which each variable occurs at most once. Such formulas are also called, u-formulas or booiean trees. This paper treats the problem of exactly identifying an unknown read-once formula using speciﬁc kinds of queries. The main results are a polynomial time algorithm for exact identiﬁcation of monotone read~ once formulas using only membership queries, and a polynomial time algorithm for exact identiﬁcation of general read-once formulas using equivalence and membership queries (a protocol based on the notion of a mirtimally adequate teacher [1]). Our results improve on"
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,On PAC learning algorithms for rich boolean function classes,Description not available
Lisa Hellerstein,https://scholar.google.com/citations?user=A45mhtsAAAAJ&hl=en,,Learning boolean read-once formulas over generalized bases,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",The Human Tumor Atlas Network: charting tumor transitions across space and time at single-cell resolution,"Crucial transitions in cancer—including tumor initiation, local expansion, metastasis, and therapeutic resistance—involve complex interactions between cells within the dynamic tumor ecosystem. Transformative single-cell genomics technologies and spatial multiplex in situ methods now provide an opportunity to interrogate this complexity at unprecedented resolution. The Human Tumor Atlas Network (HTAN), part of the National Cancer Institute (NCI) Cancer Moonshot Initiative, will establish a clinical, experimental, computational, and organizational framework to generate informative and accessible three-dimensional atlases of cancer transitions for a diverse set of tumor types. This effort complements both ongoing efforts to map healthy organs and previous large-scale cancer genomics approaches focused on bulk sequencing at a single point in time. Generating single-cell, multiparametric, longitudinal atlases …"
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",ScatterBlogs2: Real-Time Monitoring of Microblog Messages through User-Guided Filtering.,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",TrajectoryLenses–A Set‐based Filtering and Exploration Technique for Long‐term Trajectory Data,"The visual analysis of spatiotemporal movement is a challenging task. There may be millions of routes of different length and shape with different origin and destination, extending over a long time span. Furthermore there can be various correlated attributes depending on the data domain, e.g. engine measurements for mobility data or sensor data for animal tracking. Visualizing such data tends to produce cluttered and incomprehensible images that need to be accompanied by sophisticated filtering methods. We present TrajectoryLenses, an interaction technique that extends the exploration lens metaphor to support complex filter expressions and the analysis of long time periods. Analysts might be interested only in movements that occur in a given time range, traverse a certain region, or end at a given area of interest (AOI). Our lenses can be placed on an interactive map to identify such geospatial AOIs. They can …"
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Integrating Predictive Analytics and Social Media,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Visual analysis of movement behavior using web data for context enrichment,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Visual Interaction with Deep Learning Models through Collaborative Semantic Inference,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Facetto: Combining Unsupervised and Supervised Learning for Hierarchical Phenotype Analysis in Multi-Channel Image Data,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Can Twitter really save your Life? A Case Study of Visual Social Media Analytics for Situation Awareness,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",MITI minimum information guidelines for highly multiplexed tissue images,"The imminent release of tissue atlases combining multichannel microscopy with single-cell sequencing and other omics data from normal and diseased specimens creates an urgent need for data and metadata standards to guide data deposition, curation and release. We describe a Minimum Information about Highly Multiplexed Tissue Imaging (MITI) standard that applies best practices developed for genomics and for other microscopy data to highly multiplexed tissue images and traditional histology."
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Semantic Enrichment of Movement Behavior with Foursquare-A Visual Analytics Approach,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Immersive Modular Factory Layout Planning using Augmented Reality,"We present an immersive analytics approach to enhance production line planning. It enables experts to analyze the performance and spatial implications of already drafted production layouts in-situ on the shop floor. The approach is implemented as an augmented reality application prototype. Experts can interactively combine the computational capabilities of layout simulations with their experience allowing to consider possibly unmodeled restrictions. Our interactive approach is enhanced by automated layout suggestions using a genetic algorithm as well as an automated layout comparison. Further, we provide information about the layout’s optimization potential based on the calculation and visualization of critical paths in the layout."
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Lymphocyte networks are dynamic cellular communities in the immunoregulatory landscape of lung adenocarcinoma,"Lymphocytes are key for immune surveillance of tumors, but our understanding of the spatial organization and physical interactions that facilitate lymphocyte anti-cancer functions is limited. We used multiplexed imaging, quantitative spatial analysis, and machine learning to create high-definition maps of lung tumors from a Kras/Trp53-mutant mouse model and human resections. Networks of interacting lymphocytes (""lymphonets"") emerged as a distinctive feature of the anti-cancer immune response. Lymphonets nucleated from small T cell clusters and incorporated B cells with increasing size. CXCR3-mediated trafficking modulated lymphonet size and number, but T cell antigen expression directed intratumoral localization. Lymphonets preferentially harbored TCF1+ PD-1+ progenitor CD8+ T cells involved in responses to immune checkpoint blockade (ICB) therapy. Upon treatment of mice with ICB or an antigen …"
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Can Twitter save lives? A broad-scale study on visual social media analytics for public safety,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",TravelDiff: Visual comparison analytics for massive movement patterns derived from Twitter,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Visual Interactive Map Matching,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",GenNI: Human-AI Collaboration for Data-Backed Text Generation,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis","Minerva: a light-weight, narrative image browser for multiplexed tissue images","Advances in highly multiplexed tissue imaging are transforming our understanding of human biology by enabling detection and localization of 10-100 proteins at subcellular resolution (Bodenmiller, 2016). Efforts are now underway to create public atlases of multiplexed images of normal and diseased tissues (Rozenblatt-Rosen et al., 2020). Both research and clinical applications of tissue imaging benefit from recording data from complete specimens so that data on cell state and composition can be studied in the context of overall tissue architecture. As a practical matter, specimen size is limited by the dimensions of microscopy slides (2.5× 7.5 cm or~ 2-8 cm 2 of tissue depending on shape). With current microscopy technology, specimens of this size can be imaged at sub-micron resolution across~ 60 spectral channels and~ 10 6 cells, resulting in image files of terabyte size. However, the rich detail and multiscale …"
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Using large scale aggregated knowledge for social media location discovery,Description not available
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Narrative online guides for the interpretation of digital-pathology images and tissue-atlas data,"Multiplexed tissue imaging facilitates the diagnosis and understanding of complex disease traits. However, the analysis of such digital images heavily relies on the experience of anatomical pathologists for the review, annotation and description of tissue features. In addition, the wider use of data from tissue atlases in basic and translational research and in classrooms would benefit from software that facilitates the easy visualization and sharing of the images and the results of their analyses. In this Perspective, we describe the ecosystem of software available for the analysis of tissue images and discuss the need for interactive online guides that help histopathologists make complex images comprehensible to non-specialists. We illustrate this idea via a software interface (Minerva), accessible via web browsers, that integrates multi-omic and tissue-atlas features. We argue that such interactive narrative guides can …"
Robert Krueger,https://scholar.google.com/citations?user=UHmEAooAAAAJ&hl=en&oi=sra,"Visual Analytics, Visualization, Biomedical Visualization, Geovisualization, Movement Analysis",Scope2Screen: Focus+ Context Techniques for Pathology Tumor Assessment in Multivariate Image Data,Description not available
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Experimental security analysis of a modern automobile,Description not available
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Comprehensive experimental analyses of automotive attack surfaces,"Modern automobiles are pervasively computerized, and hence potentially vulnerable to attack. However, while previous research has shown that the internal networks within some modern cars are insecure, the associated threat model—requiring prior physical access—has justifiably been viewed as unrealistic. Thus, it remains an open question if automobiles can also be susceptible to remote compromise. Our work seeks to put this question to rest by systematically analyzing the external attack surface of a modern automobile. We discover that remote exploitation is feasible via a broad range of attack vectors (including mechanics tools, CD players, Bluetooth and cellular radio), and further, that wireless communications channels allow long distance vehicle control, location tracking, in-cabin audio exfiltration and theft. Finally, we discuss the structural characteristics of the automotive ecosystem that give rise to such problems and highlight the practical challenges in mitigating them."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",A fistful of bitcoins: characterizing payments among men with no names,"Bitcoin is a purely online virtual currency, unbacked by either physical commodities or sovereign obligation; instead, it relies on a combination of cryptographic protection and a peer-to-peer protocol for witnessing settlements. Consequently, Bitcoin has the unintuitive property that while the ownership of money is implicitly anonymous, its flow is globally visible. In this paper we explore this unique characteristic further, using heuristic clustering to group Bitcoin wallets based on evidence of shared authority, and then using re-identification attacks (i.e., empirical purchasing of goods and services) to classify the operators of those clusters. From this analysis, we characterize longitudinal changes in the Bitcoin market, the stresses these changes are placing on the system, and the challenges for those seeking to use Bitcoin for criminal or fraudulent purposes at scale."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",{Trafﬁcking} Fraudulent Accounts: The Role of the Underground Market in Twitter Spam and Abuse,"As web services such as Twitter, Facebook, Google, and Yahoo now dominate the daily activities of Internet users, cyber criminals have adapted their monetization strategies to engage users within these walled gardens. To facilitate access to these sites, an underground market has emerged where fraudulent accounts–automatically generated credentials used to perpetrate scams, phishing, and malware–are sold in bulk by the thousands. In order to understand this shadowy economy, we investigate the market for fraudulent Twitter accounts to monitor prices, availability, and fraud perpetrated by 27 merchants over the course of a 10-month period. We use our insights to develop a classifier to retroactively detect several million fraudulent accounts sold via this marketplace, 95% of which we disable with Twitter’s help. During active months, the 27 merchants we monitor appeared responsible for registering 10–20% of all accounts later flagged for spam by Twitter, generating $127–459K for their efforts."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Shining light in dark places: Understanding the Tor network,"To date, there has yet to be a study that characterizes the usage of a real deployed anonymity service. We present observations and analysis obtained by participating in the Tor network. Our primary goals are to better understand Tor as it is deployed and through this understanding, propose improvements. In particular, we are interested in answering the following questions: (1) How is Tor being used? (2) How is Tor being mis-used? (3) Who is using Tor?"
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Low-resource routing attacks against Tor,Tor has become one of the most popular overlay networks for anonymizing TCP traffic. Its popularity is due in part to its perceived strong anonymity properties and its relatively low latency service. Low latency is achieved through Tor's ability to balance the traffic load by optimizing Tor router selection to probabilistically favor routers with high bandwidth capabilities.
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",An analysis of underground forums,"Underground forums, where participants exchange information on abusive tactics and engage in the sale of illegal goods and services, are a form of online social network (OSN). However, unlike traditional OSNs such as Facebook, in underground forums the pattern of communications does not simply encode pre-existing social relationships, but instead captures the dynamic trust relationships forged between mutually distrustful parties. In this paper, we empirically characterize six different underground forums --- BlackHatWorld, Carders, HackSector, HackE1ite, Freehack, and L33tCrew --- examining the properties of the social networks formed within, the content of the goods and services being exchanged, and lastly, how individuals gain and lose trust in this setting."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Click trajectories: End-to-end analysis of the spam value chain,Description not available
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Passive Data Link Layer 802.11 Wireless Device Driver Fingerprinting.,"Motivated by the proliferation of wireless-enabled devices and the suspect nature of device driver code, we develop a passive fingerprinting technique that identifies the wireless device driver running on an IEEE 802.11 compliant device. This technique is valuable to an attacker wishing to conduct reconnaissance against a potential target so that he may launch a driver-specific exploit."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Manufacturing compromise: the emergence of exploit-as-a-service,"We investigate the emergence of the exploit-as-a-service model for driveby browser compromise. In this regime, attackers pay for an exploit kit or service to do the ""dirty work"" of exploiting a victim's browser, decoupling the complexities of browser and plugin vulnerabilities from the challenges of generating traffic to a website under the attacker's control. Upon a successful exploit, these kits load and execute a binary provided by the attacker, effectively transferring control of a victim's machine to the attacker."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Re:{CAPTCHAs—Understanding}{CAPTCHA-Solving} Services in an Economic Context,"Reverse Turing tests, or CAPTCHAs, have become an ubiquitous defense used to protect open Web resources from being exploited at scale. An effective CAPTCHA resists existing mechanistic software solving, yet can be solved with high probability by a human being. In response, a robust solving ecosystem has emerged, reselling both automated solving technology and realtime human labor to bypass these protections. Thus, CAPTCHAs can increasingly be understood and evaluated in purely economic terms; the market price of a solution vs the monetizable value of the asset being protected. We examine the market-side of this question in depth, analyzing the behavior and dynamics of CAPTCHA-solving service providers, their price performance, and the underlying labor markets driving this economy."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Tracking ransomware end-to-end,Description not available
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",The Spyware Used in Intimate Partner Violence,Description not available
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Improving wireless privacy with an identifier-free link layer protocol,"We present the design and evaluation of an 802.11-like wireless link layer protocol that obfuscates all transmitted bits to increase privacy. This includes explicit identifiers such as MAC addresses, the contents of management messages, and other protocol fields that the existing 802.11 protocol relies on to be sent in the clear. By obscuring these fields, we greatly increase the difficulty of identifying or profiling users from their transmissions in ways that are otherwise straightforward. Our design, called SlyFi, is nearly as efficient as existing schemes such as WPA for discovery, link setup, and data delivery despite its heightened protections; transmission requires only symmetric key encryption and reception requires a table lookup followed by symmetric key decryption. Experiments using our implementation on Atheros 802.11 drivers show that SlyFi can discover and associate with networks faster than 802.11 using WPA …"
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Doppelgänger finder: Taking stylometry to the underground,Description not available
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Pharmaleaks: Understanding the business of online pharmaceutical affiliate programs,"Online sales of counterfeit or unauthorized products drive a robust underground advertising industry that includes email spam,“black hat” search engine optimization, forum abuse and so on. Virtually everyone has encountered enticements to purchase drugs, prescription-free, from an online “Canadian Pharmacy.” However, even though such sites are clearly economically motivated, the shape of the underlying business enterprise is not well understood precisely because it is “underground.” In this paper we exploit a rare opportunity to view three such organizations—the GlavMed, SpamIt and RX-Promotion pharmaceutical affiliate programs—from the inside. Using “ground truth” data sets including four years of raw transaction logs covering over $170 million in sales, we provide an in-depth empirical analysis of worldwide consumer demand, the key role of independent third-party advertisers, and a detailed cost accounting of the overall business model."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",You've got vulnerability: Exploring effective vulnerability notifications,"Security researchers can send vulnerability notifications to take proactive measures in securing systems at scale. However, the factors affecting a notification’s efficacy have not been deeply explored. In this paper, we report on an extensive study of notifying thousands of parties of security issues present within their networks, with an aim of illuminating which fundamental aspects of notifications have the greatest impact on efficacy. The vulnerabilities used to drive our study span a range of protocols and considerations: exposure of industrial control systems; apparent firewall omissions for IPv6-based services; and exploitation of local systems in DDoS amplification attacks. We monitored vulnerable systems for several weeks to determine their rate of remediation. By comparing with experimental controls, we analyze the impact of a number of variables: choice of party to contact (WHOIS abuse contacts versus national CERTs versus US-CERT), message verbosity, hosting an information website linked to in the message, and translating the message into the notified party’s local language. We also assess the outcome of the emailing process itself (bounces, automated replies, human replies, silence) and characterize the sentiments and perspectives expressed in both the human replies and an optional anonymous survey that accompanied our notifications."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Show me the money: Characterizing spam-advertised revenue,"Modern spam is ultimately driven by product sales: goods purchased by customers online. However, while this model is easy to state in the abstract, our understanding of the concrete business environment—how many orders, of what kind, from which customers, for how much—is poor at best. This situation is unsurprising since such sellers typically operate under questionable legal footing, with “ground truth” data rarely available to the public. However, absent quantifiable empirical data,“guesstimates” operate unchecked and can distort both policy making and our choice of appropriate interventions. In this paper, we describe two inference techniques for peering inside the business operations of spam-advertised enterprises: purchase pair and basket inference. Using these, we provide informed estimates on order volumes, product sales distribution, customer makeup and total revenues for a range of spam-advertised programs."
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security","Sok: Hate, harassment, and the changing landscape of online abuse",Description not available
Damon McCoy,https://scholar.google.com/citations?user=pT8-2f0AAAAJ&hl=en,"security, privacy, computer security",Ad injection at scale: Assessing deceptive advertisement modifications,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression","Context-based, adaptive, lossless image coding",Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",PassPoints: Design and longitudinal evaluation of a graphical password system,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression","Resolving rightful ownerships with invisible watermarking techniques: Limitations, attacks, and implications",Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression","Using host symptoms, host roles, and/or host reputation for detection of host infection","Detecting and mitigating threats to a computer network is important to the health of the network. Currently firewalls, intrusion detection systems, and intrusion prevention systems are used to detect and mitigate attacks. As the attackers get Smarter and attack Sophistication increases, it becomes diffi cult to detect attacks in real-time at the perimeter. Failure of perimeter defenses leaves networks with infected hosts. At least two of symptoms, roles, and reputations of hosts in (and even outside) a network are used to identify infected hosts. Virus or malware signatures are not required."
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Secret and public key image watermarking schemes for image authentication and ownership verification,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Steganalysis using image quality metrics,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",An efficient and robust method for detecting copy-move forgery,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Analysis of LSB based image steganography techniques,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Counterfeiting attacks on oblivious block-wise independent invisible watermarking schemes,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Image steganography and steganalysis: Concepts and practice,"In the last few years, we have seen many new and powerful steganography and steganalysis techniques reported in the literature. In the following paper we go over some general concepts and ideas that apply to steganography and steganalysis. Specifically we establish a framework and define notion of security for a steganographic system. We show how conventional definitions do not really adequately cover image steganography and an provide alternate definition. We also review some of the more recent image steganography and steganalysis techniques."
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Authentication using graphical passwords: Effects of tolerance and image choice,"Graphical passwords are an alternative to alphanumeric passwords in which users click on images to authenticate themselves rather than type alphanumeric strings. We have developed one such system, called PassPoints, and evaluated it with human users. The results of the evaluation were promising with respect to rmemorability of the graphical password. In this study we expand our human factors testing by studying two issues: the effect of tolerance, or margin of error, in clicking on the password points and the effect of the image used in the password system. In our tolerance study, results show that accurate memory for the password is strongly reduced when using a small tolerance (10 x 10 pixels) around the user's password points. This may occur because users fail to encode the password points in memory in the precise manner that is necessary to remember the password over a lapse of time. In our image …"
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",A buyer-seller watermarking protocol,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Source camera identification based on CFA interpolation,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Blind source camera identification,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Protecting digital media content,"• Ownership assertion. In order to establish ownership over some content (such as an image), Alice can use a private key to generate a watermark and embed it into the original image. She then makes the watermarked image publicly available. Later, when Bob claims he owns an image derived from this public image, Alice can produce the unmarked original and demonstrate the presence of her watermark in Bob’s image. Since Alice’s original image is unavailable to Bob, he cannot do the same. For such a scheme to work, the watermark has to survive common image-processing operations. It also needs to be a function of the original image to avoid counterfeiting attacks.• Fingerprinting. To avoid unauthorized duplication and distribution of publicly available multimedia content, an author can embed a distinct watermark (or fingerprint) into each copy of the data. If unauthorized copies are found later, the origin of the …"
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Biometric-rich gestures: a novel approach to authentication on multi-touch devices,"In this paper, we present a novel multi-touch gesture-based authentication technique. We take advantage of the multi-touch surface to combine biometric techniques with gestural input. We defined a comprehensive set of five-finger touch gestures, based upon classifying movement characteristics of the center of the palm and fingertips, and tested them in a user study combining biometric data collection with usability questions. Using pattern recognition techniques, we built a classifier to recognize unique biometric gesture characteristics of an individual. We achieved a 90% accuracy rate with single gestures, and saw significant improvement when multiple gestures were performed in sequence. We found user ratings of a gestures desirable characteristics (ease, pleasure, excitement) correlated with a gestures actual biometric recognition rate - that is to say, user ratings aligned well with gestural security, in contrast …"
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Can invisible watermarks resolve rightful ownerships?,Description not available
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Modeling user choice in the PassPoints graphical password scheme,"We develop a model to identify the most likely regions for users to click in order to create graphical passwords in the PassPoints system. A PassPoints password is a sequence of points, chosen by a user in an image that is displayed on the screen. Our model predicts probabilities of likely click points; this enables us to predict the entropy of a click point in a graphical password for a given image. The model allows us to evaluate automatically whether a given image is well suited for the PassPoints system, and to analyze possible dictionary attacks against the system. We compare the predictions provided by our model to results of experiments involving human users. At this stage, our model and the experiments are small and limited; but they show that user choice can be modeled and that expansions of the model and the experiments are a promising direction of research."
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Image steganalysis with binary similarity measures,We present a novel technique for steganalysis of images that have been subjected to embedding by steganographic algorithms. The seventh and eighth bit planes in an image are used for the computation of several binary similarity measures. The basic idea is that the correlation between the bit planes as well as the binary texture characteristics within the bit planes will differ between a stego image and a cover image. These telltale marks are used to construct a classifier that can distinguish between stego and cover images. We also provide experimental results using some of the latest steganographic algorithms. The proposed scheme is found to have complementary performance vis-à-vis Farid's scheme in that they outperform each other in alternate embedding techniques.
Nasir Memon,https://scholar.google.com/citations?user=Pz0YttAAAAAJ&amp%3Bhl=en&amp%3Boi=ao,"Media Forensics, Biometrics, Authentication, Network Security, Data Compression",Protecting biometric templates with sketch: Theory and practice,Description not available
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Dimensionality Reduction for k-means Clustering and Low-rank Approximation,"We show how to approximate a data matrix A with a much smaller sketch ~A that can be used to solve a general class of constrained k-rank approximation problems to within (1+ε) error. Importantly, this class includes k-means clustering and unconstrained low rank approximation (i.e. principal component analysis). By reducing data points to just O(k) dimensions, we generically accelerate any exact, approximate, or heuristic algorithm for these ubiquitous problems. For k-means dimensionality reduction, we provide (1+ε) relative error results for many common sketching techniques, including random row projection, column selection, and approximate SVD. For approximate principal component analysis, we give a simple alternative to known algorithms that has applications in the streaming setting. Additionally, we extend recent work on column-based matrix reconstruction, giving column subsets that not only 'cover' a …"
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Randomized Block Krylov Methods for Stronger and Faster Approximate Singular Value Decomposition,"Since being analyzed by Rokhlin, Szlam, and Tygert and popularized by Halko, Martinsson, and Tropp, randomized Simultaneous Power Iteration has become the method of choice for approximate singular value decomposition. It is more accurate than simpler sketching algorithms, yet still converges quickly for any matrix, independently of singular value gaps. After~ O (1/epsilon) iterations, it gives a low-rank approximation within (1+ epsilon) of optimal for spectral norm error. We give the first provable runtime improvement on Simultaneous Iteration: a randomized block Krylov method, closely related to the classic Block Lanczos algorithm, gives the same guarantees in just~ O (1/sqrt (epsilon)) iterations and performs substantially better experimentally. Our analysis is the first of a Krylov subspace method that does not depend on singular value gaps, which are unreliable in practice. Furthermore, while it is a simple accuracy benchmark, even (1+ epsilon) error for spectral norm low-rank approximation does not imply that an algorithm returns high quality principal components, a major issue for data applications. We address this problem for the first time by showing that both Block Krylov Iteration and Simultaneous Iteration give nearly optimal PCA for any matrix. This result further justifies their strength over non-iterative sketching methods."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Uniform Sampling for Matrix Approximation,"Random sampling has become a critical tool in solving massive matrix problems. For linear regression, a small, manageable set of data rows can be randomly selected to approximate a tall, skinny data matrix, improving processing time significantly. For theoretical performance guarantees, each row must be sampled with probability proportional to its statistical leverage score. Unfortunately, leverage scores are difficult to compute. A simple alternative is to sample rows uniformly at random. While this often works, uniform sampling will eliminate critical row information for many natural instances."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Recursive Sampling for the Nyström Method,"We give the first algorithm for kernel Nystrom approximation that runs in linear time in the number of training points and is provably accurate for all kernel matrices, without dependence on regularity or incoherence conditions. The algorithm projects the kernel onto a set of s landmark points sampled by their ridge leverage scores, requiring just O (ns) kernel evaluations and O (ns^ 2) additional runtime. While leverage score sampling has long been known to give strong theoretical guarantees for Nystrom approximation, by employing a fast recursive sampling scheme, our algorithm is the first to make the approach scalable. Empirically we show that it finds more accurate kernel approximations in less time than popular techniques such as classic Nystrom approximation and the random Fourier features method."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees,"Random Fourier features is one of the most popular techniques for scaling up kernel methods, such as kernel ridge regression. However, despite impressive empirical results, the statistical properties of random Fourier features are still not well understood. In this paper we take steps toward filling this gap. Specifically, we approach random Fourier features from a spectral matrix approximation point of view, give tight bounds on the number of Fourier features required to achieve a spectral approximation, and show how spectral matrix approximation bounds imply statistical guarantees for kernel ridge regression."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Analyzing the Impact of Filter Bubbles on Social Network Polarization,"While social networks have increased the diversity of ideas and information available to users, they are also blamed for increasing the polarization of user opinions. Eli Pariser's ""filter bubble"" hypothesis [55] explains this counterintuitive phenomenon by linking user polarization to algorithmic filtering: to increase user engagement, social media companies connect users with ideas they are already likely to agree with, thus creating echo chambers of users with very similar beliefs."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Input Sparsity Time Low-rank Approximation via Ridge Leverage Score Sampling,"We present a new algorithm for finding a near optimal low-rank approximation of a matrix A in O(nnz(A)) time. Our method is based on a recursive sampling scheme for computing a representative subset of A‘s columns, which is then used to find a low-rank approximation."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Single Pass Spectral Sparsification in Dynamic Streams,"We present the first single pass algorithm for computing spectral sparsifiers for graphs in the dynamic semi-streaming model. Given a single pass over a stream containing insertions and deletions of edges to a graph , our algorithm maintains a randomized linear sketch of the incidence matrix of into dimension . Using this sketch, at any point, the algorithm can output a spectral sparsifier for with high probability. While space algorithms are known for computing cut sparsifiers in dynamic streams [K. J. Ahn, S. Guha, and A. McGregor, in Proceedings of the 31st ACM Symposium on Principles of Database Systems, 2012, pp. 5--14; A. Goel, M. Kapralov, and I. Post, \hrefhttp://arXiv.org/abs/1203.4900 arXiv:1203.4900, 2002] and spectral sparsifiers in insertion-only streams [J. A. Kelner and A. Levin, Theory Comput. Syst., 53 (2013), pp. 243--262], prior to our work, the best known single pass algorithm for …"
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Minimizing Polarization and Disagreement in Social Networks,"The rise of social media and online social networks has been a disruptive force in society. Opinions are increasingly shaped by interactions on online social media, and social phenomena including disagreement and polarization are now tightly woven into everyday life. In this work we initiate the study of the following question: \beginquotation \noindent Given n agents, each with its own initial opinion that reflects its core value on a topic, and an opinion dynamics model, what is the structure of a social network that minimizes \em disagreementand \em controversy simultaneously? \endquotation \noindent This question is central to recommender systems: should a recommender system prefer a link suggestion between two online users with similar mindsets in order to keep disagreement low, or between two users with different opinions in order to expose each to the others viewpoint of the world, and decrease overall levels of …"
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Hutch++: Optimal Stochastic Trace Estimation,"We study the problem of estimating the trace of a matrix A that can only be accessed through matrix-vector multiplication. We introduce a new randomized algorithm, Hutch++, which computes a (1±∊) approximation to tr(A) for any positive semidefinite (PSD) A using just O(1/∊) matrix-vector products. This improves on the ubiquitous Hutchinson's estimator, which requires O(1/∊2) matrix-vector products. Our approach is based on a simple technique for reducing the variance of Hutchinson's estimator using a low-rank approximation step, and is easy to implement and analyze. Moreover, we prove that, up to a logarithmic factor, the complexity of Hutch++ is optimal amongst all matrix-vector query algorithms, even when queries can be chosen adaptively. We show that it significantly outperforms Hutchinson's method in experiments. While our theory requires A to be positive semidefinite, empirical gains extend to …"
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Near Optimal Linear Algebra in the Online and Sliding Window Models,Description not available
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Stability of the Lanczos Method for Matrix Function Approximation,"Theoretically elegant and ubiquitous in practice, the Lanczos method can approximate f (A)x for any symmetric matrix A ∊ ℝn × n, vector x ∊ ℝn, and function f. In exact arithmetic, the method's error after k iterations is bounded by the error of the best degree-k polynomial uniformly approximating the scalar function f(x) on the range [λmin(A), λmax(A)]. However, despite decades of work, it has been unclear if this powerful guarantee holds in finite precision."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Correlation Sketches for Approximate Join-correlation Queries,"The increasing availability of structured datasets, from Web tables and open-data portals to enterprise data, opens up opportunities to enrich analytics and improve machine learning models through relational data augmentation. In this paper, we introduce a new class of data augmentation queries: join-correlation queries. Given a column Q and a join column KQ from a query table TQ, retrieve tables TX in a dataset collection such that TX is joinable with TQ on KQ and there is a column C ∈ TX such that Q is correlated with C. A naïve approach to evaluate these queries, which first finds joinable tables and then explicitly joins and computes correlations between Q and all columns of the discovered tables, is prohibitively expensive. To efficiently support correlated column discovery, we 1) propose a sketching method that enables the construction of an index for a large number of tables and that provides accurate …"
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",A Universal Sampling Method for Reconstructing Signals with Simple Fourier Transforms,"Reconstructing continuous signals based on a small number of discrete samples is a fundamental problem across science and engineering. We are often interested in signals with ""simple'' Fourier structure -- e.g., those involving frequencies within a bounded range, a small number of frequencies, or a few blocks of frequencies -- i.e., bandlimited, sparse, and multiband signals, respectively. More broadly, any prior knowledge on a signal's Fourier power spectrum can constrain its complexity. Intuitively, signals with more highly constrained Fourier structure require fewer samples to reconstruct."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Principal Component Projection without Principal Component Analysis,"We show how to efficiently project a vector onto the top principal components of a matrix,* without explicitly computing these components*. Specifically, we introduce an iterative algorithm that provably computes the projection using few calls to any black-box routine for ridge regression. By avoiding explicit principal component analysis (PCA), our algorithm is the first with no runtime dependence on the number of top principal components. We show that it can be used to give a fast iterative method for the popular principal component regression problem, giving the first major runtime improvement over the naive method of combining PCA with regression. To achieve our results, we first observe that ridge regression can be used to obtain a"" smooth projection"" onto the top principal components. We then sharpen this approximation to true projection using a low-degree polynomial approximation to the matrix step function. Step function approximation is a topic of long-term interest in scientific computing. We extend prior theory by constructing polynomials with simple iterative structure and rigorously analyzing their behavior under limited precision."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Active Linear Regression for ℓp Norms and Beyond,Description not available
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Fast and Space Efficient Spectral Sparsification in Dynamic Streams,"In this paper, we resolve the complexity problem of spectral graph sparcification in dynamic streams up to polylogarithmic factors. Using a linear sketch we design a streaming algorithm that uses Õ(n) space, and with high probability, recovers a spectral sparsifier from the sketch in Õ(n) time.1 Prior results either achieved near optimal Õ(n) space, but Ω(n2) recovery time [Kapralov et al. ‘14], or ran in o(n2) time, but used polynomially suboptimal space [Ahn et al ‘13]."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",A Sketch-based Index for Correlated Dataset Search,Description not available
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Principled Sampling for Anomaly Detection,"Anomaly detection plays an important role in protecting computer systems from unforeseen attack by automatically recognizing and filter atypical inputs. However, it can be difficult to balance the sensitivity of a detector–an aggressive system can filter too many benign inputs while a conservative system can fail to catch anomalies. Accordingly, it is important to rigorously test anomaly detectors to evaluate potential error rates before deployment. However, principled systems for doing so have not been studied–testing is typically ad hoc, making it difficult to reproduce results or formally compare detectors."
Christopher Musco,https://scholar.google.com/citations?user=HXXSrNMAAAAJ&hl=en,"Algorithms, Theory of Computation, Machine Learning",Sublinear Time Spectral Density Estimation,"We present a new sublinear time algorithm for approximating the spectral density (eigenvalue distribution) of an n× n normalized graph adjacency or Laplacian matrix. The algorithm recovers the spectrum up to є accuracy in the Wasserstein-1 distance in O(n· (1/є)) time given sample access to the graph. This result compliments recent work by David Cohen-Steiner, Weihao Kong, Christian Sohler, and Gregory Valiant (2018), which obtains a solution with runtime independent of n, but exponential in 1/є. We conjecture that the trade-off between dimension dependence and accuracy is inherent."
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education",Geospatial resolution of human and bacterial diversity with city-scale metagenomics,"The panoply of microorganisms and other species present in our environment influence human health and disease, especially in cities, but have not been profiled with metagenomics at a city-wide scale. We sequenced DNA from surfaces across the entire New York City (NYC) subway system, the Gowanus Canal, and public parks. Nearly half of the DNA (48%) does not match any known organism; identified organisms spanned 1,688 bacterial, viral, archaeal, and eukaryotic taxa, which were enriched for genera associated with skin (e.g., Acinetobacter). Predicted ancestry of human DNA left on subway surfaces can recapitulate U.S. Census demographic data, and bacterial signatures can match a station's history, such as marine-associated bacteria in a hurricane-flooded station. This baseline metagenomic map of NYC could help long-term disease surveillance, bioterrorism threat mitigation, and health …"
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education",Genome assembly and geospatial phylogenomics of the bed bug Cimex lectularius,"The common bed bug (Cimex lectularius) has been a persistent pest of humans for thousands of years, yet the genetic basis of the bed bug’s basic biology and adaptation to dense human environments is largely unknown. Here we report the assembly, annotation and phylogenetic mapping of the 697.9-Mb Cimex lectularius genome, with an N50 of 971 kb, using both long and short read technologies. A RNA-seq time course across all five developmental stages and male and female adults generated 36,985 coding and noncoding gene models. The most pronounced change in gene expression during the life cycle occurs after feeding on human blood and included genes from the Wolbachia endosymbiont, which shows a simultaneous and coordinated host/commensal response to haematophagous activity. These data provide a rich genetic resource for mapping activity and density of C. lectularius across human …"
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education",Fungal high‐throughput taxonomic identification tool for use with next‐generation sequencing (FHiTINGS),"Improvements in DNA sequencing technology provide unprecedented opportunities to explore fungal diversity, but also present challenges in data analysis due to the large number of sequences generated. Here, we describe an open source software program “FHiTINGS” that utilizes the output of a BLASTn (blastall) search to rapidly identify, classify, and parse internal transcribed spacer (ITS) DNA sequences produced in fungal ecology studies that utilize next‐generation DNA sequencing. This tool was designed for use with 454 pyrosequencing and is also appropriate for use with any sequencing platform that allows for BLAST searches against the indicated ITS database. For each sequence, FHiTINGS uses the lowest common ancestor method (LCA) to produce a single identification from BLAST output results, and then assigns taxonomic ranks from species through kingdom when possible for each sequence …"
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education","A Genome Sequence Resource for the Aye-Aye (Daubentonia madagascariensis), a Nocturnal Lemur from Madagascar","We present a high-coverage draft genome assembly of the aye-aye (Daubentonia madagascariensis), a highly unusual nocturnal primate from Madagascar. Our assembly totals ∼3.0 billion bp (3.0 Gb), roughly the size of the human genome, comprised of ∼2.6 million scaffolds (N50 scaffold size = 13,597 bp) based on short paired-end sequencing reads. We compared the aye-aye genome sequence data with four other published primate genomes (human, chimpanzee, orangutan, and rhesus macaque) as well as with the mouse and dog genomes as nonprimate outgroups. Unexpectedly, we observed strong evidence for a relatively slow substitution rate in the aye-aye lineage compared with these and other primates. In fact, the aye-aye branch length is estimated to be ∼10% shorter than that of the human lineage, which is known for its low substitution rate. This finding may be explained, in part, by the …"
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education",Optimization of de novo transcriptome assembly from high-throughput short read sequencing data improves functional annotation for non-model organisms,"The k-mer hash length is a key factor affecting the output of de novo transcriptome assembly packages using de Bruijn graph algorithms. Assemblies constructed with varying single k-mer choices might result in the loss of unique contiguous sequences (contigs) and relevant biological information. A common solution to this problem is the clustering of single k-mer assemblies. Even though annotation is one of the primary goals of a transcriptome assembly, the success of assembly strategies does not consider the impact of k-mer selection on the annotation output. This study provides an in-depth k-mer selection analysis that is focused on the degree of functional annotation achieved for a non-model organism where no reference genome information is available. Individual k-mers and clustered assemblies (CA) were considered using three representative software packages. Pair …"
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education",Geospatial resolution of human and bacterial diversity with city-scale metagenomics. Cell Syst 1: 72–87,Description not available
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education",Modern methods for delineating metagenomic complexity,"Figure 3B has been corrected to show the general coverage of the Yersinia pestis pMT1 plasmid, but not the murine toxin gene (yMT). The initial claim of ‘‘. consistent 203 coverage across the murine toxin gene.’’was erroneously based on looking at annotations from related plasmids and comparing different reference sequences. In actuality no reads mapped to the yMT gene. The result of low coverage to the"
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education",Algal biorefinery for high-value platform chemicals,"The production of renewable and sustainable biofuels is of long-term importance for both scientific and political necessities. The reliance of fossil fuels has increased the amount of greenhouse gases in the atmosphere and geographically separated the production of fuel from its ultimate use. Meanwhile, due to their rapid growth and genetic flexibility, microalgae are under increasing scrutiny as potential feedstocks for the sustainable production of biofuels and other value-added biochemicals. Owing to economic hurdles as well as market pull for green chemicals, it is expected that integrated biorefineries producing biofuels as well as high-value phycochemicals will be the future commercial template. This chapter explores novel biosynthetic pathways and the potential of several high-value platform chemicals already under evaluation as well as current practices and several of the tools available for their production."
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education",The mitogenome of the bed bug Cimex lectularius (Hemiptera: Cimicidae),We report the extraction of a bed bug mitogenome from high-throughput sequencing projects originally focused on the nuclear genome of Cimex lectularius. The assembled mitogenome has a similar AT nucleotide composition bias found in other insects. Phylogenetic analysis of all protein-coding genes indicates that C. lectularius is clearly a member of a paraphyletic Cimicomorpha clade within the Order Hemiptera.
Darryl Reeves,https://scholar.google.com/citations?user=HA_YoR0AAAAJ&hl=en,"computational biology, computer science education","The mitogenome of the bed bug Cimex lectularius (Hemiptera: Cimicidae)(vol 1, pg 425, 2016)",Description not available
Gustavo Sandoval,https://scholar.google.com/citations?user=65_TUrIAAAAJ&hl=en,"Machine Learning, Security",Method and system for generating and displaying a slide show with animations and transitions in a browser,"(54) METHOD AND SYSTEM FOR GENERATING Primary Examiner—Cliff N. V0 AND DISPLAYINGA SLIDE SHOW WITH(74) Attorney, Agent, or Firm—Christensen O’Connor ANIMATIONS AND TRANSITIONS IN A Johnson Kindness PLLC BROWSER"
Gustavo Sandoval,https://scholar.google.com/citations?user=65_TUrIAAAAJ&hl=en,"Machine Learning, Security",Lost at c: A user study on the security implications of large language model code assistants,"Large Language Models (LLMs) such as OpenAI Codex are increasingly being used as AI-based coding assistants. Understanding the impact of these tools on developers’ code is paramount, especially as recent work showed that LLMs may suggest cybersecurity vulnerabilities. We conduct a security-driven user study (N= 58) to assess code written by student programmers when assisted by LLMs. Given the potential severity of low-level bugs as well as their relative frequency in real-world projects, we tasked participants with implementing a singly-linked ‘shopping list’structure in C. Our results indicate that the security impact in this setting (low-level C with pointer and array manipulations) is small: AI-assisted users produce critical security bugs at a rate no greater than 10% more than the control, indicating the use of LLMs does not introduce new security risks."
Gustavo Sandoval,https://scholar.google.com/citations?user=65_TUrIAAAAJ&hl=en,"Machine Learning, Security",Security implications of large language model code assistants: A user study,Description not available
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",The ball-pivoting algorithm for surface reconstruction,Description not available
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Computing and rendering point set surfaces,Description not available
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Point set surfaces,Description not available
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",A survey of surface reconstruction from point clouds,"The area of surface reconstruction has seen substantial progress in the past two decades. The traditional problem addressed by surface reconstruction is to recover the digital representation of a physical shape that has been scanned, where the scanned data contain a wide variety of defects. While much of the earlier work has been focused on reconstructing a piece‐wise smooth representation of the original shape, recent work has taken on more specialized priors to address significantly challenging data imperfections, where the reconstruction can take on different representations—not necessarily the explicit geometry. We survey the field of surface reconstruction, and provide a categorization with respect to priors, data imperfections and reconstruction output. By considering a holistic view of surface reconstruction, we show a detailed characterization of the field, highlight similarities between diverse …"
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Robust moving least-squares fitting with sharp features,"We introduce a robust moving least-squares technique for reconstructing a piecewise smooth surface from a potentially noisy point cloud. We use techniques from robust statistics to guide the creation of the neighborhoods used by the moving least squares (MLS) computation. This leads to a conceptually simple approach that provides a unified framework for not only dealing with noise, but also for enabling the modeling of surfaces with sharp features.Our technique is based on a new robust statistics method for outlier detection: the forward-search paradigm. Using this powerful technique, we locally classify regions of a point-set to multiple outlier-free smooth regions. This classification allows us to project points on a locally smooth region rather than a surface that is smooth everywhere, thus defining a piecewise smooth surface and increasing the numerical stability of the projection operator. Furthermore, by treating …"
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",VisTrails: visualization meets data management,"Scientists are now faced with an incredible volume of data to analyze. To successfully analyze and validate various hypothesis, it is necessary to pose several queries, correlate disparate data, and create insightful visualizations of both the simulated processes and observed phenomena. Often, insight comes from comparing the results of multiple visualizations. Unfortunately, today this process is far from interactive and contains many error-prone and time-consuming tasks. As a result, the generation and maintenance of visualizations is a major bottleneck in the scientific process, hindering both the ability to mine scientific data and the actual use of the data. The VisTrails system represents our initial attempt to improve the scientific discovery process and reduce the time to insight. In VisTrails, we address the problem of visualization from a data management perspective: VisTrails manages the data and metadata of a …"
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Provenance for computational tasks: A survey,Description not available
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Visual exploration of big spatio-temporal urban data: A study of new york city taxi trips,Description not available
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",A survey of visibility for walkthrough applications,Description not available
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",The ALPS project release 2.0: open source software for strongly correlated systems,"We present release 2.0 of the ALPS (Algorithms and Libraries for Physics Simulations) project, an open source software project to develop libraries and application programs for the simulation of strongly correlated quantum lattice models such as quantum magnets, lattice bosons, and strongly correlated fermion systems. The code development is centered on common XML and HDF5 data formats, libraries to simplify and speed up code development, common evaluation and plotting tools, and simulation programs. The programs enable non-experts to start carrying out serial or parallel numerical simulations by providing basic implementations of the important algorithms for quantum lattice models: classical and quantum Monte Carlo (QMC) using non-local updates, extended ensemble simulations, exact and full diagonalization (ED), the density matrix renormalization group (DMRG) both in a static version and a …"
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Vistrails: Enabling interactive multiple-view visualizations,Description not available
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Quad‐mesh generation and processing: A survey,"Triangle meshes have been nearly ubiquitous in computer graphics, and a large body of data structures and geometry processing algorithms based on them has been developed in the literature. At the same time, quadrilateral meshes, especially semi‐regular ones, have advantages for many applications, and significant progress was made in quadrilateral mesh generation and processing during the last several years. In this survey we discuss the advantages and problems of techniques operating on quadrilateral meshes, including surface analysis and mesh quality, simplification, adaptive refinement, alignment with features, parametrisation and remeshing."
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Surface reconstruction based on lower dimensional localized Delaunay triangulation,"We present a fast, memory efficient algorithm that generates a manifold triangular mesh S passing through a set of unorganized points P R 3. Nothing is assumed about the geometry, topology or presence of boundaries in the data set except that P is sampled from a real manifold surface. The speed of our algorithm is derived from a projection‐based approach we use to determine the incident faces on a point. We define our sampling criteria to sample the surface and guarantee a topologically correct mesh after surface reconstruction for such a sampled surface. We also present a new algorithm to find the normal at a vertex, when the surface is sampled according our given criteria. We also present results of our surface reconstruction using our algorithm on unorganized point clouds of various models."
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Managing rapidly-evolving scientific workflows,"We give an overview of VisTrails, a system that provides an infrastructure for systematically capturing detailed provenance and streamlining the data exploration process. A key feature that sets VisTrails apart from previous visualization and scientific workflow systems is a novel action-based mechanism that uniformly captures provenance for data products and workflows used to generate these products. This mechanism not only ensures reproducibility of results, but it also simplifies data exploration by allowing scientists to easily navigate through the space of workflows and parameter settings for an exploration task."
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",A user study of visualization effectiveness using EEG and cognitive load,"Effectively evaluating visualization techniques is a difficult task often assessed through feedback from user studies and expert evaluations. This work presents an alternative approach to visualization evaluation in which brain activity is passively recorded using electroencephalography (EEG). These measurements are used to compare different visualization techniques in terms of the burden they place on a viewer's cognitive resources. In this paper, EEG signals and response times are recorded while users interpret different representations of data distributions. This information is processed to provide insight into the cognitive load imposed on the viewer. This paper describes the design of the user study performed, the extraction of cognitive load measures from EEG data, and how those measures are used to quantitatively evaluate the effectiveness of visualizations."
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics","Sonyc: A system for monitoring, analyzing, and mitigating urban noise pollution","SONYC integrates sensors, machine listening, data analytics, and citizen science to address noise pollution in New York City."
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",The first provenance challenge,"The first Provenance Challenge was set up in order to provide a forum for the community to understand the capabilities of different provenance systems and the expressiveness of their provenance representations. To this end, a functional magnetic resonance imaging workflow was defined, which participants had to either simulate or run in order to produce some provenance representation, from which a set of identified queries had to be implemented and executed. Sixteen teams responded to the challenge, and submitted their inputs. In this paper, we present the challenge workflow and queries, and summarize the participants' contributions. Copyright © 2007 John Wiley & Sons, Ltd."
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",A benchmark for surface reconstruction,"We present a benchmark for the evaluation and comparison of algorithms which reconstruct a surface from point cloud data. Although a substantial amount of effort has been dedicated to the problem of surface reconstruction, a comprehensive means of evaluating this class of algorithms is noticeably absent. We propose a simple pipeline for measuring surface reconstruction algorithms, consisting of three main phases: surface modeling, sampling, and evaluation. We use implicit surfaces for modeling shapes which are capable of representing details of varying size and sharp features. From these implicit surfaces, we produce point clouds by synthetically generating range scans which resemble realistic scan data produced by an optical triangulation scanner. We validate our synthetic sampling scheme by comparing against scan data produced by a commercial optical laser scanner, where we scan a 3D-printed …"
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Deep geometric prior for surface reconstruction,"The reconstruction of a discrete surface from a point cloud is a fundamental geometry processing problem that has been studied for decades, with many methods developed. We propose the use of a deep neural network as a geometric prior for surface reconstruction. Specifically, we overfit a neural network representing a local chart parameterization to part of an input point cloud using the Wasserstein distance as a measure of approximation. By jointly fitting many such networks to overlapping parts of the point cloud, while enforcing a consistency condition, we compute a manifold atlas. By sampling this atlas, we can produce a dense reconstruction of the surface approximating the input cloud. The entire procedure does not require any training data or explicit regularization, yet, we show that it is able to perform remarkably well: not introducing typical overfitting artifacts, and approximating sharp features closely at the same time. We experimentally show that this geometric prior produces good results for both man-made objects containing sharp features and smoother organic objects, as well as noisy inputs. We compare our method with a number of well-known reconstruction methods on a standard surface reconstruction benchmark."
Claudio T. Silva,https://scholar.google.com/citations?user=YIwiAAsAAAAJ&hl=en,"Visualization, Graphics, Urban Computing, Geometry Processing, Sports Analytics",Progressive point set surfaces,"Progressive point set surfaces (PPSS) are a multilevel point-based surface representation. They combine the usability of multilevel scalar displacement maps (e.g., compression, filtering, geometric modeling) with the generality of point-based surface representations (i.e., no fixed homology group or continuity class). The multiscale nature of PPSS fosters the idea of point-based modeling. The basic building block for the construction of PPSS is a projection operator, which maps points in the proximity of the shape onto local polynomial surface approximations. The projection operator allows the computing of displacements from smoother to more detailed levels. Based on the properties of the projection operator we derive an algorithm to construct a base point set. Starting from this base point set, a refinement rule using the projection operator constructs a PPSS from any given manifold surface."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Exploiting diverse knowledge sources via maximum entropy in named entity recognition,"This paper describes a novel statistical namedentity (ie"" proper name"") recognition system built around a maximum entity framework. By working v, ithin the framework of maximum entropy theory and utilizing a flexible object-based architecture, the system is able to make use of an extraordinarily diverse range of knowledge sources in making its tagging decisions. These knowledge sources include capitalization features, lexical features, features indicating the current section of text (ie headline or main body), and dictionaries of single or multi-word terms. The purely statistical system contains no hand-generated patterns and achieves a result comparable with the best statistical systems. However, when combined with other handcoded systems, the system achieves scores that exceed the highest comparable scores thus-far published."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,NYU: Description of the MENE named entity system as used in MUC-7,"This paper describes a new system called Maximum Entropy Named Entity"" or MENE"" pronounced meanie"" which was NYU's entrant in the MUC-7 named entity evaluation. By working within the framework of maximum entropy theory and utilizing a exible object-based architecture, the system is able to make use of an extraordinarily diverse range of knowledge sources in making its tagging decisions. These knowledge sources include capitalization features, lexical features and features indicating the current type of text ie headline or main body. It makes use of a broad array of dictionaries of useful single or multi-word terms such as rst names, company names, and corporate su xes. These dictionaries required no manual editing and were either downloaded from the web or were simply obvious"" lists entered by hand."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Generalizing automatically generated selectional patterns,"Frequency information on co-occurrence patterns can be atttomatically collected from a syntactically analyzed corpus; this information can then serve as the basis for selectional constraints when analyzing new text; from the same domain. Tiffs information, however, is necessarily incomplete. We report on measurements of the degree of selectional coverage obtained with ditt\~ rent sizes of corpora. We then describe a technique for using the corpus to identify selectionally similar terms, and for using tiffs similarity to broaden the seleetional coverage for a tixed corpus size."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Acquisition of selectional patterns,"For most natural language analysis systems, one of the major hurdles in porting the system to a new domain is the development of an appropriate set of semantic patterns. Such patterns are typically needed to guide syntactic analysis (as selectional constraints) and to control the translation into a predicate-argument representation. As systems are ported to more complex domains, the set of patterns grows and the task of accumulating them manually becomes more formidable. There has therefore been increasing interest in acquiring such patterns automatically froin a sample of text in the domain, through an analysis of word co-occurrence patterns either in raw text (word sequences) or in parsed text. We briefly review some of this work later in the article. We have been specificaily concerned about the practicality of using such techniques in place of manual encoding to develop the selectional patterns for new domains. In the experiments reported here, we have therefore been particularly concerned with the evaluation of our automatically generated patterns, in terms of their completehess and accuracy and in terms of their efficacy in performing selection during parsing."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,New York University: Description of the PROTEUS system as used for MUC-3,"The PROTEUS Syntactic Analyzer was developed starting in the fall of 1984 as a common base for all th e applications of the PROTEUS Project. Many aspects of its design reflect its heritage in the Linguistic Strin g Parser, previously developed and still in use at New York University. The current system, including the Restriction Language compiler, the lexical analyzer, and the parser proper, comprise approximately 4500 lines of Common Lisp."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Evaluating parsing strategies using standardized parse files,"The availability of large files of manuallyreviewed parse trees from the University of Pennsylvania"" tree bank"", along with a program for comparing system-generated parses against these"" standard"" parses, provides a new opportunity for evaluating different parsing strategies. We discuss some of the restructuring required to the output of our parser so that it could be meaningfully compared with these standard parses. We then describe several heuristics for improving parsing accuracy and coverage, such as closest attachment of modifiers, statistical grammars, and fitted parses, and present a quantitative evaluation of the improvements obtained with each strategy."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Description of the MENE Named Entity System as used in MUC-7,Description not available
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Smoothing of automatically generated selectional constraints,"Frequency information on co-occurrence patterns can be automatically collected from a syntactically analyzed corpus; this information can then serve as the basis for selectional constraints when analyzing new text from the same domain. Better coverage of the domain can be obtained by appropriate generalization of the specific word patterns which are collected. We report here on an approach to automatically make suitable generalizations: using the co-occurrence data to compute a confusion matrix relating individual words, and then using the confusion matrix to smooth the original frequency data."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Preference semantics for message understanding,"The design of effective natural language processing systems requires a combination of the theoretical and the practical. We want to have a theoretically well-founded design so that we can take advantage of gradual improvements in our knowledge of syntax, semantics, discourse structures, and the subject domain. At the same time we need to adopt a practical approach which recognizes the inevitable shortcomings of our knowledge in these areas. We need to create robust systems which are able to deal appropriately with these shortcomings. We are interested in particular in systems for extracting specified information from a text. Such systems are robust if they are able to extract at least partial information despite the presence of ill-formed or unexpected syntactic, semantic, or discourse structures."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,New York University PROTEUS system: MUC-3 test results and analysis,RESULTS
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Description of the MENE named Entity System,Description not available
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,NYU/BBN 1994 CSR evaluation,"NYU’s research objective is to determine whether non-local, linguistically-based word preferences can be used to enhance speech recognition. We are working jointly with BBN, and our system takes as input the N-best hypotheses generated by BBN (with acoustic and n-gram language model scores for each hypothesis). Our goal is to generate scores based on both intersentential dependencies (related to topic coherence) and intrasentential dependencies (connected by syntactic relations) to complement the usual contiguous-word (n-gram) dependencies."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Analyzing telegraphic messages,"SHIPMENT GOLD BULLION ARRIVING STAGECOACH JAN. 7 3 PM even though lots of material has been omitted which would be required in"" standard English"", such as articles, prepositions, and verbs. Our concern in this paper is how to process such messages by computer. Even though people don't send many telegrams anymore, this problem is still of importance because many military messages are written in this telegraphic style:"
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Information extraction and semantic constraints,"We consider the problem of extracting specified types of information from natural language text. To properly analyze the text, we wish to apply semantic (selectional) constraints whenever possible; however, we cannot expect to have semantic patterns for all the input we may encounter in real texts. We therefore use preference semantics: selecting the analysis which maximizes the number of semantic patterns matched. We describe a specific information extraction task, and report on the benefits of using preference semantics for this task."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,An Equipment Model and its Role in the Interpretation of Noun Phrases.,"For natural language understanding systems designed for domains including relatively complex equipment, it is not sufficient to use general knowledge about this equipment. We show problems which can be solved only if the system has access to a detailed equipment model. We discuss the structure of such models in some detail and, in particular, the mixed static/dynamic nature of the model. As an illustration, we describe parts of a simulation model for an air compressor. Finally, we demonstrate how to find referents in this model for noun phrases."
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,PROTEUS: un sistema multilingüe de extracción de información,Description not available
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,Towards robust natural language analysis,Description not available
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,PROTEUS: Un sistema multilingüe de extracción de información. f,"Resumen El sistema PROTEUS (PROtotype TExt Understanding System) tiene como objetivo analizar e interpretar textos reales y mostrar un resumen de la información contenida en ellos de una forma estructurada (concretamente en forma de registro de base de datos). El sistema utiliza gramáticas del inglés y español de gran cobertura sintáctica, aunque la interpretación de las estructuras analizadas sólo se puede hacer dentro de dominios lingüísticos restringidos. En esta comunicación presentaremos una aplicación práctica de PROTEUS: resumen de documentos periodísticos de información (no de opinión). Nuestro ejemplo está tomado de partes de agencias. Como es habitual en las bases de datos. la estructura ha sido predeﬁnida en función de las necesidades de los usuarios. También se compararán los resultados obtenidos automáticamente por ambas gramáticas con los generados por un …"
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,"Towards robust natural language analysis: Position paper for AAAI symposium on text-based intelligent systems, March 27-29, 1990",Description not available
John Sterling,https://scholar.google.com/citations?user=cS9Fcf4AAAAJ&hl=en,,PRÖTEUS: UN SISTEMA MULTILINGÜE DE EXTRACCIÓN,"El sistema PROTEUS (PROtotypeTExtUnderstanding System) tiene como objetivo analizar e interpretar textos reales y mostrar un resumen de la información contenida en ellos de una forma estructurada (concretamente en forma de registro de base de datos). El sistema utiliza gramáticas del inglésyespañol de grancoberturasintáctica, aunque lainterpretación de lasestructurasanalizadas sólo se puede hacer dentro de dominios lingüísticos restringidos. En esta comunicación presentaremos una aplicación práctica de PROTEUS: resumen de documentos periodísticos de información (no de opinión). Nuestro ejemplo está tomado de partes de agencias. Como es habitual en las bases de datos, la estructura ha sido predefinida en función de las necesidades de los usuarios. También se compararán los resultados obtenidos automáticamente por ambas gramáticas con los generados por un especialista."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Measuring fairness in ranked outputs,"Ranking and scoring are ubiquitous. We consider the setting in which an institution, called a ranker, evaluates a set of individuals based on demographic, behavioral or other characteristics. The final output is a ranking that represents the relative quality of the individuals. While automatic and therefore seemingly objective, rankers can, and often do, discriminate against individuals and systematically disadvantage members of protected groups. This warrants a careful study of the fairness of a ranking scheme, to enable data science for social good applications, among others."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Putting lipstick on pig: Enabling database-style workflow provenance,Description not available
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Designing fair ranking schemes,"Items from a database are often ranked based on a combination of criteria. The weight given to each criterion in the combination can greatly affect the fairness of the produced ranking, for example, preferring men over women. A user may have the flexibility to choose combinations that weigh these criteria differently, within limits. In this paper, we develop a system that helps users choose criterion weights that lead to greater fairness. We consider ranking functions that compute the score of each item as a weighted sum of (numeric) attribute values, and then sort items on their score. Each ranking function can be expressed as a point in a multi-dimensional space. For a broad range of fairness criteria, including proportionality, we show how to efficiently identify regions in this space that satisfy these criteria. Using this identification method, our system is able to tell users whether their proposed ranking function satisfies …"
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Datasynthesizer: Privacy-preserving synthetic datasets,"To facilitate collaboration over sensitive data, we present DataSynthesizer, a tool that takes a sensitive dataset as input and generates a structurally and statistically similar synthetic dataset with strong privacy guarantees. The data owners need not release their data, while potential collaborators can begin developing models and methods with some confidence that their results will work similarly on the real dataset. The distinguishing feature of DataSynthesizer is its usability --- the data owner does not have to specify any parameters to start generating and sharing data safely and effectively."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Diversity in big data: A review,"Big data technology offers unprecedented opportunities to society as a whole and also to its individual members. At the same time, this technology poses significant risks to those it overlooks. In this article, we give an overview of recent technical work on diversity, particularly in selection tasks, discuss connections between diversity and fairness, and identify promising directions for future work that will position diversity as an important component of a data-responsible society. We argue that diversity should come to the forefront of our discourse, for reasons that are both ethical—to mitigate the risks of exclusion—and utilitarian, to enable more powerful, accurate, and engaging data analysis and use."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Efficient network aware search in collaborative tagging sites,"The popularity of collaborative tagging sites presents a unique opportunity to explore keyword search in a context where query results are determined by the opinion of a network of taggers related to a seeker. In this paper, we present the first in-depth study of network-aware search. We investigate efficient top-k processing when the score of an answer is computed as its popularity among members of a seeker's network. We argue that obvious adaptations of top-k algorithms are too space-intensive, due to the dependence of scores on the seeker's network. We therefore develop algorithms based on maintaining score upper-bounds. The global upper-bound approach maintains a single score upper-bound for every pair of item and tag, over the entire collection of users. The resulting bounds are very coarse. We thus investigate clustering seekers based on similar behavior of their networks. We show that finding the …"
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Automatically and adaptively determining execution plans for queries with parameter markers,A method for automatically and adaptively determining query execution plans for parametric queries. A first classifier trained by an initial set of training points is generated using a set of random decision trees (RDTs). A query workload and/or database statistics are dynamically updated. A new set of training points collected off-line is used to modify the first classifier into a second classifier. A database query is received at a runtime Subsequent to the off line phase. The query includes predicates having parameter markers bound to actual values. The predicates are associated with selectivities. The query execution plan is determined by identifying an optimal average of posterior probabilities obtained across a set of RDTs and mapping the selectivities to a plan. The determined query execution plan is included in an augmented set of training points that includes the initial set and the new
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",A nutritional label for rankings,"Algorithmic decisions often result in scoring and ranking individuals to determine credit worthiness, qualifications for college admissions and employment, and compatibility as dating partners. While automatic and seemingly objective, ranking algorithms can discriminate against individuals and protected groups, and exhibit low diversity. Furthermore, ranked results are often unstable -- small changes in the input data or in the ranking methodology may lead to drastic changes in the output, making the result uninformative and easy to manipulate. Similar concerns apply in cases where items other than individuals are ranked, including colleges, academic departments, or products. Despite the ubiquity of rankers, there is, to the best of our knowledge, no technical work that focuses on making rankers transparent."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Responsible data management,Description not available
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",On provenance and privacy,"Provenance in scientific workflows is a double-edged sword. On the one hand, recording information about the module executions used to produce a data item, as well as the parameter settings and intermediate data items passed between module executions, enables transparency and reproducibility of results. On the other hand, a scientific workflow often contains private or confidential data and uses proprietary modules. Hence, providing exact answers to provenance queries over all executions of the workflow may reveal private information. In this paper we discuss privacy concerns in scientific workflows -- data, module, and structural privacy - and frame several natural questions: (i) Can we formally analyze data, module, and structural privacy, giving provable privacy guarantees for an unlimited/bounded number of provenance queries? (ii) How can we answer search and structural queries over repositories of …"
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Fairness in ranking: A survey,Description not available
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Online set selection with fairness and diversity constraints,"Selection algorithms usually score individual items in isolation, and then select the top scoring items. However, often there is an additional diversity objective. Since diversity is a group property, it does not easily jibe with individual item scoring. In this paper, we study set selection queries subject to diversity and group fairness constraints. We develop algorithms for several problem settings with streaming data, where an online decision must be made on each item as it is presented. We show through experiments with real and synthetic data that fairness and diversity can be achieved, usually with modest costs in terms of quality. Our experimental evaluation leads to several important insights in online set selection. We demonstrate that theoretical guarantees on solution quality are conservative in real datasets, and that tuning the length of the score estimation phase leads to an interesting accuracy-efficiency trade-off. Further, we show that if a difference in scores is expected between groups, then these groups must be treated separately during processing. Otherwise, a solution may be derived that meets diversity constraints, but that selects lower-scoring members of disadvantaged groups."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy","Fairness in ranking, part i: Score-based ranking","In the past few years, there has been much work on incorporating fairness requirements into algorithmic rankers, with contributions coming from the data management, algorithms, information retrieval, and recommender systems communities. In this survey, we give a systematic overview of this work, offering a broad perspective that connects formalizations and algorithmic approaches across sub-fields. An important contribution of our work is in developing a common narrative around the value frameworks that motivate specific fairness-enhancing interventions in ranking. This allows us to unify the presentation of mitigation objectives and of algorithmic techniques to help meet those objectives or identify trade-offs."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",It’s just not that simple: an empirical study of the accuracy-explainability trade-off in machine learning for public policy,"To achieve high accuracy in machine learning (ML) systems, practitioners often use complex “black-box” models that are not easily understood by humans. The opacity of such models has resulted in public concerns about their use in high-stakes contexts and given rise to two conflicting arguments about the nature — and even the existence — of the accuracy-explainability trade-off. One side postulates that model accuracy and explainability are inversely related, leading practitioners to use black-box models when high accuracy is important. The other side of this argument holds that the accuracy-explainability trade-off is rarely observed in practice and consequently, that simpler interpretable models should always be preferred. Both sides of the argument operate under the assumption that some types of models, such as low-depth decision trees and linear regression are more explainable, while others such as …"
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Balanced ranking with diversity constraints,Description not available
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy","Fairness in ranking, part ii: Learning-to-rank and recommender systems","In the past few years, there has been much work on incorporating fairness requirements into algorithmic rankers, with contributions coming from the data management, algorithms, information retrieval, and recommender systems communities. In this survey, we give a systematic overview of this work, offering a broad perspective that connects formalizations and algorithmic approaches across subfields. An important contribution of our work is in developing a common narrative around the value frameworks that motivate specific fairness-enhancing interventions in ranking. This allows us to unify the presentation of mitigation objectives and of algorithmic techniques to help meet those objectives or identify trade-offs."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Research directions for principles of data management (dagstuhl perspectives workshop 16151),"The area of Principles of Data Management (PDM) has made crucial contributions to the development of formal frameworks for understanding and managing data and knowledge. This work has involved a rich cross-fertilization between PDM and other disciplines in mathematics and computer science, including logic, complexity theory, and knowledge representation. We anticipate on-going expansion of PDM research as the technology and applications involving data management continue to grow and evolve. In particular, the lifecycle of Big Data Analytics raises a wealth of challenge areas that PDM can help with. In this report we identify some of the most important research directions where the PDM community has the potential to make significant contributions. This is done from three perspectives: potential practical relevance, results already obtained, and research questions that appear surmountable in the short and medium term."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Automatically and adaptively determining execution plans for queries with parameter markers,"Freund et al.; A decision-theoretic generalization of on-line learning and an application to boosting; Journal of Computer and System Sciences, 55 (1): pp. 119-139 (1997). Freund et al. A short introduction to boosting; Journal of Japanese Society for Artificial Intelligence, 14 (5): pp. 771-780 (1999). Hulgeri et al.; Parametric query optimization for linear and piecewise linear cost functions; Proceedings of the 28th VLDB Conference, Hong Kong, China (2002); 12 pages."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Leveraging Tagging to Model User Interests in del. icio. us.,"Social tagging sites such as Flickr, YouTube and del. icio. us are becoming increasingly popular. Users of these sites annotate and endorse content by tagging, and form social ties with other users by including them into their friendship network. The richness of social context raises the users’ expectations with respect to the quality of served content, but also presents a unique opportunity for the design of semantically-enriched recommender systems. This paper presents a variety of methods for producing customized hotlists and evaluates their effectiveness on del. icio. us datasets. We model a user’s interest in terms of the tags he uses to annotate content, and in terms of his explicitly stated and derived social ties, and demonstrate how such interest can be leveraged to produce holistic of very high quality. We also discuss possible research directions and outline strategies for the design of a social tagging recommender system."
Julia Stoyanovich,https://scholar.google.com/citations?user=UhJRkaIAAAAJ,"responsible AI, data management, algorithmic ranking, AI ethics, AI policy",Nutritional labels for data and models,Description not available
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Optimal histograms with quality guarantees,"Histograms are commonly used to capture attribute value distribution statistics for query optimizers. More recently, histograms have also been considered as a way to produce quick approximate answers to decision support queries. This widespread interest in histograms motivates the problem of computing histograms that are good under a given error metric. In particular, we are interested in an e cient algorithm for choosing the bucket boundaries in a way that either minimizes the estimation error for a given amount of space (number of buckets) or, conversely, minimizes the space needed for a given upper bound on the error. Under the assumption that nding optimal bucket boundaries is computationally ine cient, previous research has focused on heuristics with no provable bounds on the quality of the solutions."
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Design and implementation of a high-performance distributed web crawler,Description not available
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",BSPlib: The BSP programming library,Description not available
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Efficient query processing in geographic web search engines,"Geographic web search engines allow users to constrain and order search results in an intuitive manner by focusing a query on a particular geographic region. Geographic search technology, also called local search, has recently received significant interest from major search engine companies. Academic research in this area has focused primarily on techniques for extracting geographic knowledge from the web. In this paper, we study the problem of efficient query processing in scalable geographic search engines. Query processing is a major bottleneck in standard web search engines, and the main reason for the thousands of machines used by the major engines. Geographic search engine query processing is different in that it requires a combination of text and spatial data processing techniques. We propose several algorithms for efficient query processing in geographic search engines, integrate them into an …"
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",The Perron-Frobenius theorem: some of its applications,Description not available
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Inverted index compression and query processing with optimized document ordering,"Web search engines use highly optimized compression schemes to decrease inverted index size and improve query throughput, and many index compression techniques have been studied in the literature. One approach taken by several recent studies first performs a renumbering of the document IDs in the collection that groups similar documents together, and then applies standard compression techniques. It is known that this can significantly improve index compression compared to a random document ordering. We study index compression and query processing techniques for such reordered indexes. Previous work has focused on determining the best possible ordering of documents. In contrast, we assume that such an ordering is already given, and focus on how to optimize compression methods and query processing for this case. We perform an extensive study of compression techniques for document IDs …"
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Scalable sweeping-based spatial join,"In this paper, we examine the spatial join problem. In particular, we focus on the case when neither of the inputs is indexed. We present a new algorithm, Scalable Sweep-based Spatial Join (SSSJ), that is based on the distribution-sweeping technique recently proposed in computational geometry, and that is the first to achieve theoretically optimal bounds on internal computation time as well as I/O transfers. We present experimental results based on an efficient implementation of the SSSJ algorithm, and compare it to an improved implementation of the state-of-the-art Partition-Based Spatial-Merge (PBSM) algorithm of Patel and DeWitt."
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Performance of compressed inverted list caching in search engines,"Due to the rapid growth in the size of the web, web search engines are facing enormous performance challenges. The larger engines in particular have to be able to process tens of thousands of queries per second on tens of billions of documents, making query throughput a critical issue. To satisfy this heavy workload, search engines use a variety of performance optimizations including index compression, caching, and early termination."
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",An efficient distributed algorithm for constructing small dominating sets,"The dominating set problem asks for a small subset D of nodes in a graph such that every node is either in D or adjacent to a node in D. This problem arises in a number of distributed network applications, where it is important to locate a small number of centers in the network such that every node is nearby at least one center. Finding a dominating set of minimum size is NP-complete, and the best known approximation is logarithmic in the maximum degree of the graph and is provided by the same simple greedy approach that gives the well-known logarithmic approximation result for the closely related set cover problem. We describe and analyze new randomized distributed algorithms for the dominating set problem that run in polylogarithmic time, independent of the diameter of the network, and that return a dominating set of size within a logarithmic factor from optimal, with high probability. In particular, our best algorithm …"
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Faster top-k document retrieval using block-max indexes,"Large search engines process thousands of queries per second over billions of documents, making query processing a major performance bottleneck. An important class of optimization techniques called early termination achieves faster query processing by avoiding the scoring of documents that are unlikely to be in the top results. We study new algorithms for early termination that outperform previous methods. In particular, we focus on safe techniques for disjunctive queries, which return the same result as an exhaustive evaluation over the disjunction of the query terms. The current state-of-the-art methods for this case, the WAND algorithm by Broder et al. [11] and the approach of Strohman and Croft [30], achieve great benefits but still leave a large performance gap between disjunctive and (even non-early terminated) conjunctive queries. We propose a new set of algorithms by introducing a simple augmented …"
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems","On rectangular partitionings in two dimensions: Algorithms, complexity and applications","Partitioning a multi-dimensional data set into rectangular partitions subject to certain constraints is an important problem that arises in many database applications, including histogram-based selectivity estimation, load-balancing, and construction of index structures. While provably optimal and efficient algorithms exist for partitioning one-dimensional data, the multi-dimensional problem has received less attention, except for a few special cases. As a result, the heuristic partitioning techniques that are used in practice are not well understood, and come with no guarantees on the quality of the solution. In this paper, we present algorithmic and complexity-theoretic results for the fundamental problem of partitioning a two-dimensional array into rectangular tiles of arbitrary size in a way that minimizes the number of tiles required to satisfy a given constraint. Our main results are approximation algorithms for …"
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",ODISSEA: A Peer-to-Peer Architecture for Scalable Web Search and Information Retrieval.,"We consider the problem of building a P2P-based search engine for massive document collections. We describe a prototype system called ODISSEA (Open DIStributed Search Engine Architecture) that is currently under development in our group. ODISSEA provides a highly distributed global indexing and query execution service that can be used for content residing inside or outside of a P2P network. ODISSEA is different from many other approaches to P2P search in that it assumes a two-tier search engine architecture and a global index structure distributed over the network. We give an overview of the proposed system and discuss the basic design choices. Our main focus is on efficient query execution, and we discuss how recent work on top-k queries in the database community can be applied in a highly distributed environment. We also give preliminary simulation results on a real search engine log and a terabyte web collection that indicate good scalability for our approach."
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Three-level caching for efficient query processing in large web search engines,"Large web search engines have to answer thousands of queries per second with interactive response times. Due to the sizes of the data sets involved, often in the range of multiple terabytes, a single query may require the processing of hundreds of megabytes or more of index data. To keep up with this immense workload, large search engines employ clusters of hundreds or thousands of machines, and a number of techniques such as caching, index compression, and index and query pruning are used to improve scalability. In particular, two-level caching techniques cache results of repeated identical queries at the frontend, while index data for frequently used query terms are cached in each node at a lower level.We propose and evaluate a three-level caching scheme that adds an intermediate level of caching for additional performance gains. This intermediate level attempts to exploit frequently occurring pairs of …"
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Research frontiers in information retrieval: Report from the third strategic workshop on information retrieval in lorne (swirl 2018),"The purpose of the Strategic Workshop in Information Retrieval in Lorne is to explore the long-range issues of the Information Retrieval field, to recognize challenges that are on - or even over - the horizon, to build consensus on some of the key challenges, and to disseminate the resulting information to the research community. The intent is that this description of open problems will help to inspire researchers and graduate students to address the questions, and will provide funding agencies data to focus and coordinate support for information retrieval research."
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Improved techniques for result caching in web search engines,"Query processing is a major cost factor in operating large web search engines. In this paper, we study query result caching, one of the main techniques used to optimize query processing performance. Our first contribution is a study of result caching as a weighted caching problem. Most previous work has focused on optimizing cache hit ratios, but given that processing costs of queries can vary very significantly we argue that total cost savings also need to be considered. We describe and evaluate several algorithms for weighted result caching, and study the impact of Zipf-based query distributions on result caching. Our second and main contribution is a new set of feature-based cache eviction policies that achieve significant improvements over all previous methods, substantially narrowing the existing performance gap to the theoretically optimal (clairvoyant) method. Finally, using the same approach, we also …"
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Compressing the graph structure of the web,Description not available
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Text vs. space: efficient geo-search query processing,"Many web search services allow users to constrain text queries to a geographic location (e.g., yoga classes near Santa Monica). Important examples include local search engines such as Google Local and location-based search services for smart phones. Several research groups have studied the efficient execution of queries mixing text and geography; their approaches usually combine inverted lists with a spatial access method such as an R-tree or space-filling curve. In this paper, we take a fresh look at this problem. We feel that previous work has often focused on the spatial aspect at the expense of performance considerations in text processing, such as inverted index access, compression, and caching. We describe new and existing approaches and discuss their different perspectives. We then compare their performance in extensive experiments on large document collections. Our results indicate that a query …"
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Analysis of geographic queries in a search engine log,"Geography is becoming increasingly important in web search. Search engines can often return better results to users by analyzing features such as user location or geographic terms in web pages and user queries. This is also of great commercial value as it enables location specific advertising and improved search for local businesses. As a result, major search companies have invested significant resources into geographic search technologies, also often called local search."
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Optimized query execution in large search engines with global page ordering,"This chapter discusses the optimized query execution in large search engines with global page ordering. Large web search engines have to answer thousands of queries per second with interactive response times. A major factor in the cost of executing a query is given by the lengths of the inverted lists for the query terms, which increase with the size of the document collection and are often in the range of many megabytes. To address this issue, information retrieval (IR) and database researchers have proposed pruning techniques that compute or approximate term-based ranking functions without scanning over the full inverted lists. This chapter focuses on the question of how such techniques can be efficiently integrated into query processing. It studies pruning techniques for query execution in large engines in the case where one has a global ranking of pages, as provided by Pagerank or any …"
Torsten Suel,https://scholar.google.com/citations?user=eQUn8ugAAAAJ&hl=en,"Web Search and Mining, Databases, Algorithms, Distributed Systems",Optimal peer selection for P2P downloading and streaming,Description not available
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Difftaichi: Differentiable programming for physical simulation,Description not available
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Towards virtual reality infinite walking: dynamic saccadic redirection,"Redirected walking techniques can enhance the immersion and visual-vestibular comfort of virtual reality (VR) navigation, but are often limited by the size, shape, and content of the physical environments."
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Mapping virtual and physical reality,"Real walking offers higher immersive presence for virtual reality (VR) applications than alternative locomotive means such as walking-in-place and external control gadgets, but needs to take into consideration different room sizes, wall shapes, and surrounding objects in the virtual and real worlds. Despite perceptual study of impossible spaces and redirected walking, there are no general methods to match a given pair of virtual and real scenes."
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Fov-nerf: Foveated neural radiance fields for virtual reality,Description not available
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",System and method for generating a progressive representation associated with surjectively mapped virtual and physical reality image data,"A system of generating a progressive representation associated with virtual and physical reality image data is disclosed. The system receives virtual image data associated with a virtual scene map of a virtual scene, and receives physical image data from the image capturing device, associated with a physical environment of a real scene. Perimeter information of the physical environment is determined. Boundary information of an obstacle associated with the physical environment is determined. A real scene map associated with the physical environment including an obstacle and one or more free space areas is generated. A corresponding virtual barrier is generated in the real scene map, the virtual barrier associated with the boundary information of the obstacle in the real scene map. A folding of the virtual scene map into the one or more free space areas of the real scene map is implemented, the free space areas …"
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Learning to reconstruct 3d manhattan wireframes from a single image,"From a single view of an urban environment, we propose a method to effectively exploit the global structural regularities for obtaining a compact, accurate, and intuitive 3D wireframe representation. Our method trains a single convolutional neural network to simultaneously detect salient junctions and straight lines, as well as predict their 3D depth and vanishing points. Compared with state-of-the-art learning-based wireframe detection methods, our network is much simpler and more unified, leading to better 2D wireframe detection. With a global structural prior (such as Manhattan assumption), our method further reconstructs a full 3D wireframe model, a compact vector representation suitable for a variety of high-level vision tasks such as AR and CAD. We conduct extensive evaluations of our method on a large new synthetic dataset of urban scenes as well as real images. Our code and datasets will be published along with the paper."
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Perceptually-guided foveation for light field displays,"A variety of applications such as virtual reality and immersive cinema require high image quality, low rendering latency, and consistent depth cues. 4D light field displays support focus accommodation, but are more costly to render than 2D images, resulting in higher latency."
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Reducing simulator sickness with perceptual camera control,"Virtual-reality provides an immersive environment but can induce cybersickness due to the discrepancy between visual and vestibular cues. To avoid this problem, the movement of the virtual camera needs to match the motion of the user in the real world. Unfortunately, this is usually difficult due to the mismatch between the size of the virtual environments and the space available to the users in the physical domain. The resulting constraints on the camera movement significantly hamper the adoption of virtual-reality headsets in many scenarios and make the design of the virtual environments very challenging. In this work, we study how the characteristics of the virtual camera movement (e.g., translational acceleration and rotational velocity) and the composition of the virtual environment (e.g., scene depth) contribute to perceived discomfort. Based on the results from our user experiments, we devise a computational …"
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Deep multi depth panoramas for view synthesis,"We propose a learning-based approach for novel view synthesis for multi-camera 360 panorama capture rigs. Previous work constructs RGBD panoramas from such data, allowing for view synthesis with small amounts of translation, but cannot handle the disocclusions and view-dependent effects that are caused by large translations. To address this issue, we present a novel scene representation—Multi Depth Panorama (MDP)—that consists of multiple RGBD panoramas that represent both scene geometry and appearance. We demonstrate a deep neural network-based method to reconstruct MDPs from multi-camera 360 images. MDPs are more compact than previous 3D scene representations and enable high-quality, efficient new view rendering. We demonstrate this via experiments on both synthetic and real data and comparisons with previous state-of-the-art methods spanning both learning …"
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Gaze-contingent retinal speckle suppression for perceptually-matched foveated holographic displays,Description not available
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Benefits of 3D immersion for virtual colonoscopy,Description not available
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Color-perception-guided display power reduction for virtual reality,"Battery life is an increasingly urgent challenge for today's untethered VR and AR devices. However, the power efficiency of head-mounted displays is naturally at odds with growing computational requirements driven by better resolution, refresh rate, and dynamic ranges, all of which reduce the sustained usage time of untethered AR/VR devices. For instance, the Oculus Quest 2, under a fully-charged battery, can sustain only 2 to 3 hours of operation time. Prior display power reduction techniques mostly target smartphone displays. Directly applying smartphone display power reduction techniques, however, degrades the visual perception in AR/VR with noticeable artifacts. For instance, the ""power-saving mode"" on smartphones uniformly lowers the pixel luminance across the display and, as a result, presents an overall darkened visual perception to users if directly applied to VR content."
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Path planning for virtual reality locomotion,"(57) ABSTRACT A method, computer readable medium, and system are disclosed for computing a path for a user to move along within a physical space while viewing a virtual environment in a virtual reality system. A path for a user to physically move along through a virtual environment is determined based on waypoints and at least one characteristic of the physical environment within which the user is positioned, position data for the user is received indicating whether and how much a current path taken by the user has deviated from the path, and an updated path is computed through the virtual environment based on the waypoints and the at least one characteristic of the physical environment."
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Force-aware interface via electromyography for natural VR/AR interaction,"While tremendous advances in visual and auditory realism have been made for virtual and augmented reality (VR/AR), introducing a plausible sense of physicality into the virtual world remains challenging. Closing the gap between real-world physicality and immersive virtual experience requires a closed interaction loop: applying user-exerted physical forces to the virtual environment and generating haptic sensations back to the users. However, existing VR/AR solutions either completely ignore the force inputs from the users or rely on obtrusive sensing devices that compromise user experience."
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Eccentricity effects on blur and depth perception,"Foveation and (de)focus are two important visual factors in designing near eye displays. Foveation can reduce computational load by lowering display details towards the visual periphery, while focal cues can reduce vergence-accommodation conflict thereby lessening visual discomfort in using near eye displays. We performed two psychophysical experiments to investigate the relationship between foveation and focus cues. The first study measured blur discrimination sensitivity as a function of visual eccentricity, where we found discrimination thresholds significantly lower than previously reported. The second study measured depth discrimination threshold where we found a clear dependency on visual eccentricity. We discuss the study results and suggest further investigation."
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Instant Reality: Gaze-Contingent Perceptual Optimization for 3D Virtual Reality Streaming,"To address this challenge, we propose a perceptually-optimized progressive 3D streaming method for spatial quality and temporal consistency in immersive interactions. On the …"
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Kinect-based automatic 3D high-resolution face modeling,Description not available
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Tailored reality: Perception-aware scene restructuring for adaptive vr navigation,"In virtual reality (VR), the virtual scenes are pre-designed by creators. Our physical surroundings, however, comprise significantly varied sizes, layouts, and components. To bridge the gap and further enable natural navigation, recent solutions have been proposed to redirect users or recreate the virtual content. However, they suffer from either interrupted experience or distorted appearances. We present a novel VR-oriented algorithm that automatically restructures a given virtual scene for a user’s physical environment. Different from the previous methods, we introduce neither interrupted walking experience nor curved appearances. Instead, a perception-aware function optimizes our retargeting technique to preserve the fidelity of the virtual scene that appears in VR head-mounted displays. Besides geometric and topological properties, it emphasizes the unique first-person view perceptual factors in VR, such as …"
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Image features influence reaction time: a learned probabilistic perceptual model for saccade latency,"We aim to ask and answer an essential question ""how quickly do we react after observing a displayed visual target?"" To this end, we present psychophysical studies that characterize the remarkable disconnect between human saccadic behaviors and spatial visual acuity. Building on the results of our studies, we develop a perceptual model to predict temporal gaze behavior, particularly saccadic latency, as a function of the statistics of a displayed image. Specifically, we implement a neurologically-inspired probabilistic model that mimics the accumulation of confidence that leads to a perceptual decision. We validate our model with a series of objective measurements and user studies using an eye-tracked VR display. The results demonstrate that our model prediction is in statistical alignment with real-world human behavior. Further, we establish that many sub-threshold image modifications commonly introduced in …"
Qi Sun,https://scholar.google.com/citations?hl=en&user=oN7gaqMAAAAJ,"Virtual Reality, Augmented Reality, Computer Graphics, Applied Perception",Dually noted: layout-aware annotations with smartphone augmented reality,"Sharing annotations encourages feedback, discussion, and knowledge passing among readers and can be beneficial for personal and public use. Prior augmented reality (AR) systems have expanded these benefits to both digital and printed documents. However, despite smartphone AR now being widely available, there is a lack of research about how to use AR effectively for interactive document annotation. We propose Dually Noted, a smartphone-based AR annotation system that recognizes the layout of structural elements in a printed document for real-time authoring and viewing of annotations. We conducted experience prototyping with eight users to elicit potential benefits and challenges within smartphone AR, and this informed the resulting Dually Noted system and annotation interactions with the document elements. AR annotation is often unwieldy, but during a 12-user empirical study our novel …"
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Search-based procedural content generation: A taxonomy and survey,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Procedural Content Generation In Games,"Welcome to the Procedural Content Generation in Games book. 1 This is, as far as we know, the first textbook about procedural content generation in games. As far as we know it is also the first book-length overview of the research field. We hope you find it useful, whether you are studying in a course, on your own, or are a researcher. We wrote this book for two reasons. The first reason was that all three of us were doing research on PCG in games, and we wanted a good overview. As we come from somewhat different methodological backgrounds, we realized that many researchers did not know about methods that had been developed in other communities. For example, researchers using logic programming and those using evolutionary computation might not know that the other type of algorithms was applicable to the same problem; and researchers coming from computer graphics might not even know that …"
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Artificial intelligence and games,"Of all the things that wisdom provides for the complete happiness of one’s entire life, by far the greatest is friendship."
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Experience-driven procedural content generation,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Procedural content generation via machine learning (PCGML),Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Towards automatic personalised content creation for racing games,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",An experiment in automatic game design,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Modeling player experience for content creation,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Deep learning for video game playing,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Towards automatic personalized content generation for platform games,"In this paper, we show that personalized levels can be auto-matically generated for platform games. We build on previ-ous work, where models were derived that predicted player experience based on features of level design and on playing styles. These models are constructed using preference learn-ing, based on questionnaires administered to players after playing different levels. The contributions of the current pa-per are (1) more accurate models based on a much larger data set;(2) a mechanism for adapting level design parameters to given players and playing style;(3) evaluation of this adap-tation mechanism using both algorithmic and human players. The results indicate that the adaptation mechanism effectively optimizes level design parameters for particular players."
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Sentient sketchbook: computer-assisted game level authoring,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Alphastar: An evolutionary computation perspective,"In January 2019, DeepMind revealed AlphaStar to the world---the first artificial intelligence (AI) system to beat a professional player at the game of StarCraft II---representing a milestone in the progress of AI. AlphaStar draws on many areas of AI research, including deep learning, reinforcement learning, game theory, and evolutionary computation (EC). In this paper we analyze AlphaStar primarily through the lens of EC, presenting a new look at the system and relating it to many concepts in the field. We highlight some of its most interesting aspects---the use of Lamarckian evolution, competitive co-evolution, and quality diversity. In doing so, we hope to provide a bridge between the wider EC community and one of the most significant AI systems developed in recent times."
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",What is procedural content generation? Mario on the borderline,"We try to clarify the concept of procedural content generation (PCG) through contrasting it to other forms of content generation in games with which it could easily be mistaken, and through discussing some properties of PCG which are sometimes thought of as necessary but are actually not. After drawing up some clear demarcations for what is and what is not PCG, we present two versions of a content generation system for Infinite Mario Bros which is intentionally designed to question these same demarcations. We argue that, according to our own definition, one version of the system is an example of PCG while the other is not, even though they are mostly identical. We hope that this paper answers some questions but raises others, and inspires researchers and developers to thread some less common ground in developing content generation techniques."
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",The 2014 General Video Game Playing Competition,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",A panorama of artificial and computational intelligence in games,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Cellular automata for real-time generation of infinite cave levels,"This paper presents a reliable and efficient approach to procedurally generating level maps based on the self-organization capabilities of cellular automata (CA). A simple CA-based algorithm is evaluated on an infinite cave game, generating playable and well-designed tunnel-based maps. The algorithm has very low computational cost, permitting realtime content generation, and the proposed map representation provides sufficient flexibility with respect to level design."
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",DeepMasterPrints: Generating MasterPrints for Dictionary Attacks via Latent Variable Evolution*,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",The 2009 mario ai competition,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",Modeling player experience in super mario bros,Description not available
Julian Togelius,https://scholar.google.com/citations?user=lr4I9BwAAAAJ&hl=en,"Artificial Intelligence, Games, Evolutionary Computation, Game AI, Procedural Content Generation",The mario ai benchmark and competitions,Description not available
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Geosimulation: Automata-based modeling of urban phenomena,Description not available
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Measuring sprawl,"Suburban sprawl is one of the most avidly followed urban issues in the United States today. However, despite the level of attention that is afforded sprawl, their remains relatively little understanding of its determinants and its constitution. Previous attempts to measure sprawl have focused largely on costing out its impacts rather than quantifying its characteristics. Also, the characterization of sprawl is often confused with general suburbanization and remains, in many cases, without clear empirical foundation. This paucity of understanding casts doubts about the effectiveness of growth management and smart growth policies and inhibits the ability of planners to inform public policy in a reasoned way. This paper contributes to the debate about sprawl by offering a toolkit for characterizing its attributes in a quantifiable manner."
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Cellular automata and urban simulation: where do we go from here?,"For some time now, cellular automata (CA) have been in popular use for urban simulation. Many of the most significant contributions to this new, emerging field have featured in Environment and Planning B, with a special issue devoted to the topic (Batty et al, 1997). The range of applications of cellular automata to urban studies is impressive. CA models have been employed in the exploration of a wide variety of urban phenomena, from traffic simulation and regional-scale urbanization to land-use dynamics, polycentricity, historical urbanization, and urban development. CA models of sprawl, sociospatial dynamics, segregation, and gentrification have been developed, as have simulations of urban form, growth, and location. CA have many advantages for modeling urban phenomena, including their decentralized approach, the link they provide to complexity theory, the connection of form with function and pattern …"
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Modelling and prediction in a complex world,Description not available
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Agent-based models of land-use and land-cover change,Description not available
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Geographic automata systems,"A novel approach to automata‐based modeling for spatial systems is described: geographic automata and Geographic Automata Systems. We detail a framework that takes advantage of the formalism of automata theory and GI Science to unite cellular automata and multi‐agent systems techniques, and provides a spatial approach to bottom‐up modeling of complex geographic systems that are comprised of infrastructure and human objects. The suitability of the framework is also discussed with reference to existing cellular automata and multi‐agent systems models used in urban studies. Practical implementation of the framework is illustrated with reference to an object‐based urban simulation environment and implementation of a popular socio‐spatial segregation model."
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",A toolkit for measuring sprawl,"Debate regarding suburban sprawl in urban studies is contentious. It is fair to say that the phenomenon is not fully understood to satisfaction in the academic, policy, or planning communities and there are a host of reasons why this may be the case. Characterization of sprawl in the literature is often narrative and subjective. Measurement is piecemeal and largely data-driven. Existing studies yield contrary results for the same cities in many cases. The partial appreciation for the intricacies of sprawl is problematic. In practice, city planning agencies and citizen advocacy groups are scrambling to suggest and develop “smart growth” strategies to curb sprawl, without a strong empirical basis for measuring the phenomenon. Yet, sprawl is extremely popular with consumers. In this paper, we develop an innovative approach to diagnosing sprawl, looking across the full range of its characteristic attributes in a …"
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Modelling complexity: the limits to prediction,Description not available
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Simulating sprawl,"Suburban sprawl, a relatively recent phenomenon, is among the most important urban policy issues facing contemporary cities. To date, a well-accepted rationale has not been settled on for explaining and managing the causes of sprawl. Our contention is that consideration of geography is essential—that geographical explanations offer much potential in informing the debate about sprawl. Similarly, spatial simulation could support sprawl-related research, offering what-if experimentation environments for exploring issues relating to the phenomenon. Sprawling cities may be considered as complex adaptive systems, and this warrants use of methodology that can accommodate the space-time dynamics of many interacting entities. Automata tools are well-suited to representation of such systems, but could be better formulated to capture the uniquely geographical traits of phenomena such as sprawl. By means of …"
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Visualizing the city: communicating urban design to planners and decision-makers,Description not available
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Cellular models of urban systems,"Cellular automaton (CA) based models are increasingly used to investigate cities and urban systems. We discuss difficulties with this representation of human systems, and suggest that many modifications to simple CA introduced in modelling cities are responses to these problems. We propose a two-pronged approach to research. First, for operational model-building many variations on the CA theme are required and should be welcomed; and second theoretically motivated variations of the CA formalism are required so that the possible effects on model dynamic behaviour may be more systematically explored."
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Geosimulation: object-based modeling of urban phenomena,"Urban simulation has undergone somewhat of a transformation in recent years. The field has emerged from an ‘‘evolutionary’’phase, which has spanned the last two decades. A ‘‘new wave’’of urban models have begun to take center stage, influenced by technologies such as cellular automata (CA) and multi-agent systems (MAS)(Batty, Couclelis, & Eichen, 1997; O’Sullivan & Torrens, 2000; Torrens, 2000, 2002). The familiar regional models detailing the exchange of population, goods, and jobs between coarsely represented divisions of geographical space have gradually been substituted by simulations of urban systems as collectives of numerous elements acting in the city. These ‘‘new wave’’urban models are more likely to be formulated based on individual-scale urban objects—homeowners, renters, pedestrians, commuters—and detailed descriptions of the rules governing their ‘‘real-time’’behavior in space …"
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Modeling gentrification dynamics: A hybrid approach,Description not available
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",How land-use-transportation models work,Description not available
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Cellular automata and multi-agent systems as planning support tools,"Traditional’ urban simulation models have a number of weaknesses that limit their suitability as planning support tools. However, a new wave of models is currently under development in academic circles, and it is beginning to find application in practical contexts. Based around two simulation techniques that have origins in artificial life and artificial intelligence — cellular automata and multi-agent systems — it offers great potential for planning support tools, with the capacity to simulate individual households and units of the built environment in a truly dynamic, realistic and highly flexible manner. This chapter presents an overview of traditional land use and transport models as planning support tools and examines theirfragilities before reviewing a new wave of urban models. Additionally, it considers the challenges facing the use of new techniques in operational models."
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",How cellular models of urban systems work,Description not available
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",How cellular models of urban systems work (1. Theory),"Cellular automata (CA) models have been applied to urban systems with a recent fervor and have used to explore research questions in applications from location to urban morphology. This paper (part 1 of a two-part series) is intended to serve as an introduction to how cellular models of urban system actually work, on a theoretical level. Part 2 focuses on how to build urban CA models in a practical context."
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Moving agent pedestrians through space and time,"The choreography of pedestrian movement is important to many domains of interest, particularly in the geographical sciences. Agent-based models have become a popular tool for simulating movement, allowing experimentation with scenarios in computer models that might not be amenable to real-world investigation. The fidelity of agent-based movement models is naturally most acute when the models driving their synthetic characters reproduce the geography of their behaviors appropriately: by placing people in the right places, at the right times, doing the right things, in the right contexts. Most simulation environments for moving agent pedestrians, however, rely on simple, abstract physical heuristics to drive synthetic characters and they focus on generating plausible coarse-grained movement patterns, which might not always map to real-world pedestrian behavior. Moreover, existing approaches often produce …"
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Wi-fi geographies,"Wi-Fi marries Internet-based networking and radio broadcasting. Although still nascent, the technology is wildly popular. Geography is a central consideration in the functioning of Wi-Fi technology. Yet, its influence is just beginning to be investigated. Examination of the space of Wi-Fi poses problems as wireless data traffic is invisible to the eye and its underlying apparatus is impromptu and veiled to traditional geographic inquiry. A scheme for detecting Wi-Fi infrastructure and transmissions and analyzing their geographic properties is introduced in this article. The application of the scheme to the study of Wi-Fi geography in Salt Lake City, Utah, is described. A dense network of impromptu Wi-Fi infrastructure is found to permeate the city's built environment and the urban area has been blanketed in a fog of Wi-Fi transmissions without any centralized organization. This Wi-Fi cloud is surprisingly resilient to network …"
Paul Torrens,https://scholar.google.com/citations?user=5w-u8x8AAAAJ&hl=en,"Geosimulation, geocomputation, spatial behavior",Geography and computational social science,"The emergence of computational social science has had a transformative influence on the geographical sciences, integrating diverse themes of scholarship and allying it with the pursuit of grand challenges in the physical, natural, and life sciences. Geography has benefitted from many of these developments and has, in turn, catalyzed significant advances and innovation in computational social science. In this paper, I explore the relationship between geography, computing, and the social sciences by examining the evolution of some central themes in the computational social sciences: complexity, informatics, modeling and simulation, information visualization, cyberspace, socio-technical systems, and semantic computing."
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Molecular topography of an entire nervous system,"We have produced gene expression profiles of all 302 neurons of the C. elegans nervous system that match the single-cell resolution of its anatomy and wiring diagram. Our results suggest that individual neuron classes can be solely identified by combinatorial expression of specific gene families. For example, each neuron class expresses distinct codes of ∼23 neuropeptide genes and ∼36 neuropeptide receptors, delineating a complex and expansive ""wireless"" signaling network. To demonstrate the utility of this comprehensive gene expression catalog, we used computational approaches to (1) identify cis-regulatory elements for neuron-specific gene expression and (2) reveal adhesion proteins with potential roles in process placement and synaptic specificity. Our expression data are available at https://cengen.org and can be interrogated at the web application CengenApp. We expect that this neuron-specific …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Two distinct neuroanatomical subtypes of schizophrenia revealed using machine learning,"Neurobiological heterogeneity in schizophrenia is poorly understood and confounds current analyses. We investigated neuroanatomical subtypes in a multi-institutional multi-ethnic cohort, using novel semi-supervised machine learning methods designed to discover patterns associated with disease rather than normal anatomical variation. Structural MRI and clinical measures in established schizophrenia (n = 307) and healthy controls (n = 364) were analysed across three sites of PHENOM (Psychosis Heterogeneity Evaluated via Dimensional Neuroimaging) consortium. Regional volumetric measures of grey matter, white matter, and CSF were used to identify distinct and reproducible neuroanatomical subtypes of schizophrenia. Two distinct neuroanatomical subtypes were found. Subtype 1 showed widespread lower grey matter volumes, most prominent in thalamus, nucleus accumbens, medial …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience","Heterogeneity of neuroanatomical patterns in prodromal Alzheimer’s disease: links to cognition, progression and biomarkers",See Coulthard and Knight (doi:10.1093/aww335) for a scientific commentary on this article.
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",NeuroPAL: a multicolor atlas for Whole-Brain neuronal identification in C. elegans,"Comprehensively resolving neuronal identities in whole-brain images is a major challenge. We achieve this in C. elegans by engineering a multicolor transgene called NeuroPAL (a neuronal polychromatic atlas of landmarks). NeuroPAL worms share a stereotypical multicolor fluorescence map for the entire hermaphrodite nervous system that resolves all neuronal identities. Neurons labeled with NeuroPAL do not exhibit fluorescence in the green, cyan, or yellow emission channels, allowing the transgene to be used with numerous reporters of gene expression or neuronal dynamics. We showcase three applications that leverage NeuroPAL for nervous-system-wide neuronal identification. First, we determine the brainwide expression patterns of all metabotropic receptors for acetylcholine, GABA, and glutamate, completing a map of this communication network. Second, we uncover changes in cell fate caused by …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",HYDRA: Revealing heterogeneity of imaging and genetic patterns through a multiple max-margin discriminative analysis framework,"Multivariate pattern analysis techniques have been increasingly used over the past decade to derive highly sensitive and specific biomarkers of diseases on an individual basis. The driving assumption behind the vast majority of the existing methodologies is that a single imaging pattern can distinguish between healthy and diseased populations, or between two subgroups of patients (e.g., progressors vs. non-progressors). This assumption effectively ignores the ample evidence for the heterogeneous nature of brain diseases. Neurodegenerative, neuropsychiatric and neurodevelopmental disorders are largely characterized by high clinical heterogeneity, which likely stems in part from underlying neuroanatomical heterogeneity of various pathologies. Detecting and characterizing heterogeneity may deepen our understanding of disease mechanisms and lead to patient-specific treatments. However, few approaches …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Unique homeobox codes delineate all the neuron classes of C. elegans,"It is not known at present whether neuronal cell-type diversity—defined by cell-type-specific anatomical, biophysical, functional and molecular signatures—can be reduced to relatively simple molecular descriptors of neuronal identity. Here we show, through examination of the expression of all of the conserved homeodomain proteins encoded by the Caenorhabditis elegans genome, that the complete set of 118 neuron classes of C. elegans can be described individually by unique combinations of the expression of homeodomain proteins, thereby providing—to our knowledge—the simplest currently known descriptor of neuronal diversity. Computational and genetic loss-of-function analyses corroborate the notion that homeodomain proteins not only provide unique descriptors of neuron type, but also have a critical role in specifying neuronal identity. We speculate that the pervasive use of homeobox genes in …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Crowdsourced estimation of cognitive decline and resilience in Alzheimer's disease,"Identifying accurate biomarkers of cognitive decline is essential for advancing early diagnosis and prevention therapies in Alzheimer's disease. The Alzheimer's disease DREAM Challenge was designed as a computational crowdsourced project to benchmark the current state‐of‐the‐art in predicting cognitive outcomes in Alzheimer's disease based on high dimensional, publicly available genetic and structural imaging data. This meta‐analysis failed to identify a meaningful predictor developed from either data modality, suggesting that alternate approaches should be considered for prediction of cognitive performance."
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience","Characterizing heterogeneity in neuroimaging, cognition, clinical symptoms, and genetics among patients with late-life depression",Late-life depression (LLD) is characterized by considerable heterogeneity in clinical manifestation. Unraveling such heterogeneity might aid in elucidating etiological mechanisms and support precision and individualized medicine.
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Interaction of the Joining Region in Junctophilin-2 With the L-Type Ca2+ Channel Is Pivotal for Cardiac Dyad Assembly and Intracellular Ca2+ Dynamics,"Ca2+-induced Ca2+ release (CICR) in normal hearts requires close approximation of L-type calcium channels (LTCCs) within the transverse tubules (T-tubules) and RyR (ryanodine receptors) within the junctional sarcoplasmic reticulum. CICR is disrupted in cardiac hypertrophy and heart failure, which is associated with loss of T-tubules and disruption of cardiac dyads. In these conditions, LTCCs are redistributed from the T-tubules to disrupt CICR. The molecular mechanism responsible for LTCCs recruitment to and from the T-tubules is not well known. JPH (junctophilin) 2 enables close association between T-tubules and the junctional sarcoplasmic reticulum to ensure efficient CICR. JPH2 has a so-called joining region that is located near domains that interact with T-tubular plasma membrane, where LTCCs are housed. The idea that this joining region directly interacts with LTCCs and contributes to …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Neurostructural heterogeneity in youths with internalizing symptoms,"Internalizing disorders such as anxiety and depression are common psychiatric disorders that frequently begin in youth and exhibit marked heterogeneity in treatment response and clinical course. Given that symptom-based classification approaches do not align with underlying neurobiology, an alternative approach is to identify neurobiologically informed subtypes based on brain imaging data."
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Expression profiling of the mature C. elegans nervous system by single-cell RNA-sequencing,"A single neuron and its synapses define the fundamental structural motif of the brain but the underlying gene expression programs that specify individual neuron types are poorly understood. To address this question in a model organism, we have produced a gene expression profile of >90% of the individual neuron classes in the C. elegans nervous system, an ensemble of neurons for which both the anatomy and connectivity are uniquely defined at single cell resolution. We generated single cell transcriptomes for 52,412 neurons that resolve as clusters corresponding to 109 of the canonical 118 neuron classes in the mature hermaphrodite nervous system. Detailed analysis revealed molecular signatures that further subdivide identified classes into specific neuronal subtypes. Notably, neuropeptide-related genes are often differentially expressed between subtypes of the given neuron class which points to distinct functional characteristics. All of these data are publicly available at our website (http://www.cengen.org) and can be interrogated at the web application SCeNGEA (https://cengen.shinyapps.io/SCeNGEA). We expect that this gene expression catalog will spur the goal of delineating the underlying mechanisms that define the developmental lineage, detailed anatomy, synaptic connectivity and function of each type of C. elegans neuron."
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Feature ranking based nested support vector machine ensemble for medical image classification,Description not available
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Multi-scale semi-supervised clustering of brain images: deriving disease subtypes,"Disease heterogeneity is a significant obstacle to understanding pathological processes and delivering precision diagnostics and treatment. Clustering methods have gained popularity for stratifying patients into subpopulations (i.e., subtypes) of brain diseases using imaging data. However, unsupervised clustering approaches are often confounded by anatomical and functional variations not related to a disease or pathology of interest. Semi-supervised clustering techniques have been proposed to overcome this and, therefore, capture disease-specific patterns more effectively. An additional limitation of both unsupervised and semi-supervised conventional machine learning methods is that they typically model, learn and infer from data using a basis of feature sets pre-defined at a fixed anatomical or functional scale (e.g., atlas-based regions of interest). Herein we propose a novel method, “Multi-scAle …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",NeuroPAL: a neuronal polychromatic atlas of landmarks for whole-brain imaging in C. elegans,"Resolving whole-brain images of neuronal gene expression or neuronal activity patterns, to the level of single-neuron types with defined identities, represents a major challenge. We describe here the development and use of a multicolor Caenorhabditis elegans transgene, called “NeuroPAL” (a Neuronal Polychromatic Atlas of Landmarks), to resolve unique neural identities in whole-brain images. NeuroPAL worms share a stereotypical multicolor map, permitting complete, unambiguous and automated determination of individual neuron identities in conjunction with GCaMP-based neuronal activity reporters and GFP/YFP/CFP gene-expression reporters. To demonstrate the method and its potential, we use NeuroPAL and GFP-based reporters to map expression for the whole family of metabotropic acetylcholine, glutamate, and GABA neurotransmitter receptors encoded in the C. elegans genome, revealing a vast number of potential molecular connections that go far beyond the anatomically-defined connectome. We then expand the technique to whole-brain activity, employing NeuroPAL and a panneuronal neural-activity sensor (GCaMP6s) for functional analysis. Using this tool we delineate extensive nervous system activity patterns in response to several stimuli with single, identified neuron resolution. We find that attractive odors sensed by the same neuron class exhibit dissimilar activity patterns implying that, despite their shared valence and stimulus modality, these odors drive distinct neural circuitry. Our results also indicate that the connectome is a poor predictor of functional activity, emphasizing the need for comprehensive brain-activity …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",A multidimensional neural maturation index reveals reproducible developmental patterns in children and adolescents,"Adolescence is a time of extensive neural restructuring, leaving one susceptible to atypical development. Although neural maturation in humans can be measured using functional and structural MRI, the subtle patterns associated with the initial stages of abnormal change may be difficult to identify, particularly at an individual level. Brain age prediction models may have utility in assessing brain development in an individualized manner, as deviations between chronological age and predicted brain age could reflect one's divergence from typical development. Here, we built a support vector regression model to summarize high-dimensional neuroimaging as an index of brain age in both sexes. Using structural and functional MRI data from two large pediatric datasets and a third clinical dataset, we produced and validated a two-dimensional neural maturation index (NMI) that characterizes typical brain maturation …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",The Prop1-like homeobox gene unc-42 specifies the identity of synaptically connected neurons,"Many neuronal identity regulators are expressed in distinct populations of cells in the nervous system, but their function is often analyzed only in specific isolated cellular contexts, thereby potentially leaving overarching themes in gene function undiscovered. We show here that the Caenorhabditis elegans Prop1-like homeobox gene unc-42 is expressed in 15 distinct sensory, inter- and motor neuron classes throughout the entire C. elegans nervous system. Strikingly, all 15 neuron classes expressing unc-42 are synaptically interconnected, prompting us to investigate whether unc-42 controls the functional properties of this circuit and perhaps also the assembly of these neurons into functional circuitry. We found that unc-42 defines the routes of communication between these interconnected neurons by controlling the expression of neurotransmitter pathway genes, neurotransmitter receptors, neuropeptides, and neuropeptide receptors. Anatomical analysis of unc-42 mutant animals reveals defects in axon pathfinding and synaptic connectivity, paralleled by expression defects of molecules involved in axon pathfinding, cell-cell recognition, and synaptic connectivity. We conclude that unc-42 establishes functional circuitry by acting as a terminal selector of functionally connected neuron types. We identify a number of additional transcription factors that are also expressed in synaptically connected neurons and propose that terminal selectors may also function as ‘circuit organizer transcription factors’ to control the assembly of functional circuitry throughout the nervous system. We hypothesize that such organizational properties of transcription factors …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Disentangling disease heterogeneity with max-margin multiple hyperplane classifier,"There is ample evidence for the heterogeneous nature of diseases. For example, Alzheimer’s Disease, Schizophrenia and Autism Spectrum Disorder are typical disease examples that are characterized by high clinical heterogeneity, and likely by heterogeneity in the underlying brain phenotypes. Parsing this heterogeneity as captured by neuroimaging studies is important both for better understanding of disease mechanisms, and for building subtype-specific classifiers. However, few existing methodologies tackle this problem in a principled machine learning framework. In this work, we developed a novel non-linear learning algorithm for integrated binary classification and subpopulation clustering. Non-linearity is introduced through the use of multiple linear hyperplanes that form a convex polytope that separates healthy controls from pathologic samples. Disease heterogeneity is disentangled by implicitly …"
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience","Schizophrenia imaging signatures and their associations with cognition, psychopathology, and genetics in the general population","The prevalence and significance of schizophrenia-related phenotypes at the population level is debated in the literature. Here, the authors assessed whether two recently reported neuroanatomical signatures of schizophrenia—signature 1, with widespread reduction of gray matter volume, and signature 2, with increased striatal volume—could be replicated in an independent schizophrenia sample, and investigated whether expression of these signatures can be detected at the population level and how they relate to cognition, psychosis spectrum symptoms, and schizophrenia genetic risk."
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Three-dimensional spike localization and improved motion correction for Neuropixels recordings,"Neuropixels (NP) probes are dense linear multi-electrode arrays that have rapidly become essential tools for studying the electrophysiology of large neural populations. Unfortunately, a number of challenges remain in analyzing the large datasets output by these probes. Here we introduce several new methods for extracting useful spiking information from NP probes. First, we use a simple point neuron model, together with a neural-network denoiser, to efficiently map spikes detected on the probe into three-dimensional localizations. Previous methods localized spikes in two dimensions only; we show that the new localization approach is significantly more robust and provides an improved feature set for clustering spikes according to neural identity (``spike sorting""). Next, we apply a Poisson denoising method to the resulting three-dimensional point-cloud representation of the data, and show that the resulting 3D images can be accurately registered over time, leading to improved tracking of time-varying neural activity over the probe, and in turn, crisper estimates of neural clusters over time. The code to reproduce our results and an example neuropixels dataset is provided in the supplementary material."
Erdem Varol,https://scholar.google.com/citations?user=7GlElV0AAAAJ&hl=en,"Statistics, Machine learning, Computer Vision, Neuroscience",Nuquantus: Machine learning software for the characterization and quantification of cell nuclei in complex immunofluorescent tissue images,"Determination of fundamental mechanisms of disease often hinges on histopathology visualization and quantitative image analysis. Currently, the analysis of multi-channel fluorescence tissue images is primarily achieved by manual measurements of tissue cellular content and sub-cellular compartments. Since the current manual methodology for image analysis is a tedious and subjective approach, there is clearly a need for an automated analytical technique to process large-scale image datasets. Here, we introduce Nuquantus (Nuclei quantification utility software) - a novel machine learning-based analytical method, which identifies, quantifies and classifies nuclei based on cells of interest in composite fluorescent tissue images, in which cell borders are not visible. Nuquantus is an adaptive framework that learns the morphological attributes of intact tissue in the presence of anatomical variability and pathological …"
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",3D Deep Shape Descriptor,"Shape descriptor is a concise yet informative representation that provides a 3D object with an identification as a member of some category. This paper developed a concise deep shape descriptor for the first time to address challenging issues from ever-growing 3D datasets in areas as diverse as engineering, medicine, and biology. Specifically, the proposed approach developed novel techniques to extract concise but geometrically informative shape descriptor, new definitions of Eigen-shape descriptor and Fisher-shape descriptor to guide the training strategy for deep neural network, and deep shape descriptor with discriminative capacity of maximizing the inter-class margin while minimizing the intra-class variance. Our approach addressed the challenges for shape analysis techniques posed by the complexity of 3D model and data representation and geometric structural variations and noise present in 3D models. The experimental results on 3D shape retrieval demonstrate that our proposed deep shape descriptor is superior to other state-of-the-art approaches on handling noise, incompleteness and 3D shape structural variations."
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",A new robust algorithm for video text extraction,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Deepshape: Deep learned shape descriptor for 3d shape matching and retrieval,"Complex geometric structural variations of 3D models usually pose great challenges in 3D shape matching and retrieval. In this paper, we propose a high-level shape feature learning scheme to extract deformation-insensitive feature via a novel discriminative deep auto-encoder. First, we developed a multiscale shape distribution to concisely describe the entire shape of a 3D object. Then, by imposing the Fisher discrimination criterion on the neurons in the hidden layer, we developed a novel discriminative deep auto-encoder for shape feature learning. Finally, the neurons in hidden layers from multiple discriminative auto-encoders are concatenated to form a shape descriptor for 3D shape matching and retrieval. The proposed method is evaluated on the representative datasets with large geometric variations, ie, Mcgill, SHREC'10 ShapeGoogle datasets. Experimental results on the benchmark datasets demonstrate the effectiveness of the proposed method on the applications of 3D shape matching and retrieval."
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Attention Mask R-CNN for Ship Detection and Segmentation From Remote Sensing Images,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Integration of multimodal features for video scene classification based on HMM,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Data hiding in binary text documents,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Deepshape: Deep-learned shape descriptor for 3D shape retrieval,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Model matching in robot vision by subgraph isomorphism,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Spatial Image Steganography Based on Generative Adversarial Network,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Random faces guided sparse many-to-one encoder for pose-invariant face recognition,"One of the most challenging task in face recognition is to identify people with varied poses. Namely, the test faces have significantly different poses compared with the registered faces. In this paper, we propose a high-level feature learning scheme to extract pose-invariant identity feature for face recognition. First, we build a single-hiddenlayer neural network with sparse constraint, to extract poseinvariant feature in a supervised fashion. Second, we further enhance the discriminative capability of the proposed feature by using multiple random faces as the target values for multiple encoders. By enforcing the target values to be unique for input faces over different poses, the learned highlevel feature that is represented by the neurons in the hidden layer is pose free and only relevant to the identity information. Finally, we conduct face identification on CMU MultiPIE, and verification on Labeled Faces in the Wild (LFW) databases, where identification rank-1 accuracy and face verification accuracy with ROC curve are reported. These experiments demonstrate that our model is superior to other state-of-the-art approaches on handling pose variations."
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",COMPUTER-AIDED INTELLIGENT RECOGNITION TECHNIQUES AND APPLICATIONS,"Intelligent recognition methods have recently proven to be indispensable in a variety of modern industries, including computer vision, robotics, medical imaging, visualization and the media. Furthermore, they play a critical role in the traditional fields such as character recognition, natural language processing and personal identification."
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Pavement distress analysis using image processing techniques,"We demonstrate the feasibility of applying image processing techniques to the analysis of pavement distress due to cracking. Pavement image samples were obtained using a custom‐designed data acquisition system called the Automatic Crack Monitor (ACM). The image samples conteining pavement cracks are parameters, are extracted using techniquesw described in this paper. The crack parameters are necessary measures used in calculations of the Pavement Serviceability Index (PSI), which is used by highway maintenance engineers to decide whether a certain pavement section needs to be repaired. Experimental results are shown and the potential harware implementation of the developed techniques is also discussed."
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Recent developments in document image watermarking and data hiding,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",A hierarchical orthogonal space approach to three-dimensional path planning,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",JPEG Steganalysis Based on DenseNet,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Cross-Safe: A computer vision-based approach to make all intersection-related pedestrian signals accessible for the visually impaired,"Intersections pose great challenges to blind or visually impaired travelers who aim to cross roads safely and efficiently given unpredictable traffic control. Due to decreases in vision and increasingly difficult odds when planning and negotiating dynamic environments, visually impaired travelers require devices and/or assistance (i.e. cane, talking signals) to successfully execute intersection navigation. The proposed research project is to develop a novel computer vision-based approach, named Cross-Safe, that provides accurate and accessible guidance to the visually impaired as one crosses intersections, as part of a larger unified smart wearable device. As a first step, we focused on the red-light-green-light, go-no-go problem, as accessible pedestrian signals are drastically missing from urban infrastructure in New York City. Cross-Safe leverages state-of-the-art deep learning techniques for real-time …"
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Augmented image histogram for image and video similarity search,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",A robust algorithm for text extraction in color video,Description not available
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Dual many-to-one-encoder-based transfer learning for cross-dataset human action recognition,"The emergence of large-scale human action datasets poses a challenge to efficient action labeling. Hand labeling large-scale datasets is tedious and time consuming; thus a more efficient labeling method would be beneficial. One possible solution is to make use of the knowledge of a known dataset to aid the labeling of a new dataset. To this end, we propose a new transfer learning method for cross-dataset human action recognition. Our method aims at learning generalized feature representation for effective cross-dataset classification. We propose a novel dual many-to-one encoder architecture to extract generalized features by mapping raw features from source and target datasets to the same feature space. Benefiting from the favorable property of the proposed many-to-one encoder, cross-dataset action data are encouraged to possess identical encoded features if the actions share the same class labels …"
Edward K Wong,https://scholar.google.com/citations?user=f7laURkAAAAJ&hl=en,"Computer Vision, Multimedia Computing, Machine Learning",Steganalysis Based on Awareness of Selection-Channel and Deep Learning,"Recently, deep learning has been used in steganalysis based on convolutional neural networks (CNN). In this work, we propose a CNN architecture (the so-called maxCNN) to use the selection channel. It is the first time that the knowledge of the selection channel has been incorporated into CNN for steganalysis. The proposed method assigns large weights to features learned from complex texture regions while assigns small weights to features learned from smooth regions. Experimental results on the well-known dataset BOSSbase have demonstrated that the proposed scheme is able to improve detection performance, especially for low embedding payloads. The results have shown that with the ensemble of maxCNN and maxSRMd2+EC, the proposed method can obtain better performance compared with the reported state-of-the-art on detecting WOW embedding algorithm."
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems","Scalability, fidelity, and containment in the potemkin virtual honeyfarm","The rapid evolution of large-scale worms, viruses and bot-nets have made Internet malware a pressing concern. Such infections are at the root of modern scourges including DDoS extortion, on-line identity theft, SPAM, phishing, and piracy. However, the most widely used tools for gathering intelligence on new malware -- network honeypots -- have forced investigators to choose between monitoring activity at a large scale or capturing behavior with high fidelity. In this paper, we describe an approach to minimize this tension and improve honeypot scalability by up to six orders of magnitude while still closely emulating the execution behavior of individual Internet hosts. We have built a prototype honeyfarm system, called Potemkin, that exploits virtual machines, aggressive memory sharing, and late binding of resources to achieve this goal. While still an immature implementation, Potemkin has emulated over 64,000 …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Adaptive congestion control for unpredictable cellular networks,"Legacy congestion controls including TCP and its variants are known to perform poorly over cellular networks due to highly variable capacities over short time scales, self-inflicted packet delays, and packet losses unrelated to congestion. To cope with these challenges, we present Verus, an end-to-end congestion control protocol that uses delay measurements to react quickly to the capacity changes in cellular networks without explicitly attempting to predict the cellular channel dynamics. The key idea of Verus is to continuously learn a delay profile that captures the relationship between end-to-end packet delay and outstanding window size over short epochs and uses this relationship to increment or decrement the window size based on the observed short-term packet delay variations. While the delay-based control is primarily for congestion avoidance, Verus uses standard TCP features including multiplicative …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Digital privacy challenges with shared mobile phone use in Bangladesh,"Prior research on technology use in the Global South suggests that people in marginalized communities frequently share a single device among multiple individuals. However, the data privacy challenges and tensions that arise when people share devices have not been studied in depth. This paper presents a qualitative study with 72 participants that analyzes how families in Bangladesh currently share mobile phones, their usage patterns, and the tensions and challenges that arise as individuals seek to protect the privacy of their personal data. We show how people share devices out of economic need, but also because sharing is a social and cultural practice that is deeply embedded in Bangladeshi society. We also discuss how prevalent power relationships affect sharing practices and reveal gender dynamics that impact the privacy of women's data. Finally, we highlight strategies that participants adopted to …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Computing within limits,The future of computing research relies on addressing an array of limitations on a planetary scale.
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Cultural and psychological factors in cyber-security,"Increasing cyber-security presents an ongoing challenge to security professionals. Research continuously suggests that online users are a weak link in information security. This research explores the relationship between cyber-security and cultural, personality and demographic variables."
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Hermes: data transmission over unknown voice channels,"While the cellular revolution has made voice connectivity ubiquitous in the developing world, data services are largely absent or are prohibitively expensive. In this paper, we present Hermes1, a point-to-point data connectivity solution that works by modulating data onto acoustic signals that are sent over a cellular voice call. The main challenge is that most voice codecs greatly distort signals that are not voice-like; furthermore, the backhaul can be highly heterogeneous and of low quality, thereby introducing unpredictable distortions. Hermes modulates data over the extremely narrow-band approximately 3kHz bandwidth) acoustic carrier, while being severely constrained by the requirement that the resulting sound signals are voice-like, as far as the voice codecs are concerned. Hermes uses a robust data transcoding and modulation scheme to detect and correct errors in the face of bit flips, insertions and deletions …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems","Infrastructure as creative action: Online buying, selling, and delivery in Phnom Penh","This paper describes a complex global sales and logistics network based in Phnom Penh, Cambodia, which utilizes Internet tools (particularly Facebook) as well as a suite of offline tools such as feature phones, paper receipts, and motorcycles to facilitate the buying and selling of clothes and other commodities. Against the gap or import models that sometimes limit HCI understandings of computational change in non-Western environments, we argue that the consumers, business owners, delivery drivers, and call center staff play active and formative roles in producing this infrastructure, integrating new tools into older cultural practices and determining how they work within the limits and conventions of the environment. We argue that resourceful and imaginative activities such as these constitute a form of creative infrastructural action and are central to the ways that new tools circulate in the world, though they often …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",SMS-based web search for low-end mobile devices,"Short Messaging Service (SMS) based mobile information services have become increasingly common around the world, especially in emerging regions among users with low-end mobile devices. This paper presents the design and implementation of SMSFind, an SMS-based search system that enables users to obtain extremely concise (one SMS) message of 140 bytes) and appropriate search responses for queries across arbitrary topics in one round of interaction. SMSFind is designed to complement existing SMS-based search services that are either limited in the topics they recognize or involve a human in the loop."
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",""" Everyone Has Some Personal Stuff"" Designing to Support Digital Privacy with Shared Mobile Phone Use in Bangladesh","People in South Asia frequently share a single device among multiple individuals, resulting in digital privacy challenges. This paper explores a design concept that aims to mitigate some of these challenges through a 'tiered' privacy model. Using this model, a person creates a 'shared' account that contains data they are willing to share and that is assigned a password that will be shared. Simultaneously, they create a separate 'secret' account that contains data they prefer to keep secret and that uses a password they do not share with anyone. When a friend or family member asks to check their device, the user can tell them the password for their shared account, with their private data secure in the secret account that the other person is unaware of. We explore the benefits and trade-offs of our design through a three-week deployment with 21 participants in Bangladesh, presenting findings that show how our work aids …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Dissecting web latency in ghana,"Web access is prohibitively slow in many developing regions despite substantial effort to increase bandwidth and network penetration. In this paper, we explore the fundamental bottlenecks that cause poor web performance from a client's perspective by carefully dissecting webpage load latency contributors in Ghana. Based on our measurements from 2012 to 2014, we find several interesting issues that arise due to the increasing complexity of web pages and number of server redirections required to completely render the assets of a page. We observe that, rather than bandwidth, the primary bottleneck of web performance in Ghana is the lack of good DNS servers and caching infrastructure. The main bottlenecks are: (a) Recursive DNS query resolutions; (b) HTTP redirections; (c) TLS/SSL handshakes. We experiment with a range of well-known end-to-end latency optimizations and find that simple DNS caching …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Exploring internet security perceptions and practices in urban ghana,"Security is predicated, in part, upon the clear understanding of threats and the use of strategies to mitigate these threats. Internet landscapes and the use of the Internet in developing countries are vastly different compared to those in rich countries where technology is more pervasive. In this work, we explore the use of Internet technology throughout urban and peri-urban Ghana and examine attitudes toward security to gauge the extent to which this new population of technology users may be vulnerable to attacks. We find that, like in North America and Europe, the prevalent mental threat model indicates a lack of understanding of how Internet technologies operate. As a result, people rely heavily upon passwords for security online and those who augment their security do so with a variety of ad hoc practices learned by word of mouth. We relate and contrast our findings to previous works and make several recommendations for improving security in these contexts."
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",RuralCafe: web search in the rural developing world,"The majority of people in rural developing regions do not have access to the World Wide Web. Traditional network connectivity technologies have proven to be prohibitively expensive in these areas. The emergence of new long-range wireless technologies provide hope for connecting these rural regions to the Internet. However, the network connectivity provided by these new solutions are by nature intermittent due to high network usage rates, frequent power-cuts and the use of delay tolerant links. Typical applications, especially interactive applications like web search, do not tolerate intermittent connectivity. In this paper, we present the design and implementation of RuralCafe, a system intended to support efficient web search over intermittent networks. RuralCafe enables users to perform web search asynchronously and find what they are looking for in one round of intermittency as opposed to multiple rounds of …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems","Money, God, and SMS: Explorations in supporting social action through a Bangladeshi mosque","Religious institutions hold a significant place in daily life for the vast majority of people in the world, especially in developing countries. Yet despite their social prominence, and despite HCI's emphasis on the social context of technology, organized religion is neglected in both the HCI and ICTD literature. This paper explores the relationship that mosques in Bangladesh have with their constituencies and with technology, with an eye toward the integration of technology with existing religious institutions as a way to achieve positive social ends. We first describe a qualitative exploration of several mosque communities in Bangladesh, where we find that skepticism and pragmatism about modern technology interact in a complex way that nevertheless leaves room for technical interventions. We then describe a randomized controlled trial to study the relative value of SMS messages infused with overtly religious or …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Computing within limits and ICTD,"Computing research today is fixated on high performance and large scale, but computing can be tremendously powerful even at low power and small scale. In this article we present a perspective on promising directions for research on computing within limits, where concerns about limits overshadow performance and scale. Despite coming from different motivations, computing within limits has very similar considerations as Information Communication Technology for Development (ICTD). We discuss where the two research areas intersect and where they may diverge. We draw parallels between computing within limits and ICTD in terms of technical constraints, designing for context, and goals. We hope to help stimulate computing within limits with ideas from ICTD and highlight research synergies."
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Computing security in the developing world: A case for multidisciplinary research,"Technology users in the developing world face a varied and complex set of computer security concerns. These challenges are deeply tied to a range of contextual factors including poor infrastructure, non-traditional usage patterns, and different attitudes towards security, which make simply importing security solutions from industrialized nations inadequate. Recognizing this, we describe some of the specific security risks in developing regions and their relationships with technical, political, social, and economic factors. We present concrete examples of how these factors affect the security of individuals, groups, and key applications such as mobile banking. Our analysis highlights the urgency of the concerns that need attention and presents an important intellectual challenge for the research community."
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",The persistence of paper: a case study in microfinance from Ghana,"Paper as a medium persists as the de facto standard for information collection, storage, and transfer in many low-resource developing contexts. Of these contexts, the microfinance industry continues to be fascinating in the ongoing ICTD conversation due, in part, to its elimination of paper by digitizing money transfers using mobile banking. This success invites scholars, designers, and industry practitioners to design technology solutions to eliminate the perceived inefficiencies of paper in microfinance and other industries. In this work, we take a step back to assess the role and value of paper in order to give designers pause when considering a blanket digitization of existing processes, norms, and transactions. Specifically, we study a microfinance ecosystem in the city of Tema in Ghana and find that paper passbooks are able to deliver valuable context-specific information to its owners that derive from the specific …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",The increasing sophistication of mobile media sharing in lower-middle-class Bangalore,"During the first decade of the 21st century, the rise of mobile feature phones in India saw the development of both an economy of informal media exchange and a culture of active media sharing for entertainment. Mobile phone owners paid for pirated movies and music on the grey market, and they traded them with one another, even using poorly designed mechanisms such as Bluetooth file exchange."
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",Routing in an Internet-scale network emulator,Description not available
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",One LED is Enough: Catalyzing Face-to-face Interactions at Conferences with a Gentle Nudge,"Face-to-face social interactions among strangers today are becoming increasingly rare as people turn towards computer-mediated networking tools. Today's tools, however, are based on the following assumptions: increased information encourages interaction, profiles are good representations of users to other users, and computer-mediated communications prior to face-to-face meetings lead to better outcomes. This paper describes CommonTies, a gentle technological in the form of a wearable accessory, that encourages immediate, face-to-face, organic social interactions among strangers at conferences. By not exposing any profile information, CommonTies preserves an element of mystery and enables self-disclosure of information through conversation. We evaluate our system through a field study at a three-day research conference - CSCW 2014. We find that despite our information-scarce design, users were …"
Jay Chen,https://scholar.google.com/citations?user=JWHaRbIAAAAJ&hl=en,"ICTD, HCI, Networked Systems",A strategy for limits-aware computing,"Research on computing within limits explores the design of computing technologies that will be appropriate for a future where availability of resources is drastically reduced. In an effort to define the scope and goals of limits-aware computing, early papers discussed how such a future may come about, what challenges this future may present, and the kinds of technologies we should design given these scenarios. In this paper, we posit that these future challenges already exist today in their incipient forms. We propose that limits-aware computing research should focus on these problems to make a difference today while preparing for further future collapse."
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Multi-scale Analysis Strategies in PRNU-based Tampering Localization,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Digital image integrity – a survey of protection and verification techniques,"We are currently on a verge of a revolution in digital photography. Developments in computational imaging and adoption of artificial intelligence have spawned new editing techniques that give impressive results in astonishingly short time-frames. The advent of multi-sensor and multi-lens cameras will further challenge many existing integrity verification techniques. As a result, it will be necessary to re-evaluate our notion of image authenticity and look for new techniques that could work efficiently in this new reality. The goal of this paper is to thoroughly review existing techniques for protection and verification of digital image integrity. In contrast to other recent surveys, the discussion covers the most important developments both in active protection and in passive forensic analysis techniques. Existing approaches are analyzed with respect to their capabilities, fundamental limitations, and prospective attack vectors …"
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Efficient Method for Content Reconstruction with Self-Embedding,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Multi-scale fusion for improved localization of malicious tampering in digital images,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Evaluation of Random Field Models in Multi-modal Unsupervised Tampering Localization,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Band Energy Difference for Source Attribution in Audio Forensics,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",FiFTy: large-scale file fragment type identification using convolutional neural networks,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Towards Practical Self-Embedding for JPEG-compressed Digital Images,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Hard-attention for scalable image classification,"Can we leverage high-resolution information without the unsustainable quadratic complexity to input scale? We propose Traversal Network (TNet), a novel multi-scale hard-attention architecture, which traverses image scale-space in a top-down fashion, visiting only the most informative image regions along the way. TNet offers an adjustable trade-off between accuracy and complexity, by changing the number of attended image locations. We compare our model against hard-attention baselines on ImageNet, achieving higher accuracy with less resources (FLOPs, processing time and memory). We further test our model on fMoW dataset, where we process satellite images of size up to px, getting up to x faster processing compared to baselines operating on the same resolution, while achieving higher accuracy as well. TNet is modular, meaning that most classification models could be adopted as its backbone for feature extraction, making the reported performance gains orthogonal to benefits offered by existing optimized deep models. Finally, hard-attention guarantees a degree of interpretability to our model's predictions, without any extra cost beyond inference."
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Adaptive Self-Embedding Scheme with Controlled Reconstruction Performance,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Adversarial Optimization for Dictionary Attacks on Speaker Verification.,"In this paper, we assess vulnerability of speaker verification systems to dictionary attacks. We seek master voices, ie, adversarial utterances optimized to match against a large number of users by pure chance. First, we perform menagerie analysis to identify utterances which intrinsically hold this property. Then, we propose an adversarial optimization approach for generating master voices synthetically. Our experiments show that, even in the most secure configuration, on average, a master voice can match approx. 20% of females and 10% of males without any knowledge about the population. We demonstrate that dictionary attacks should be considered as a feasible threat model for sensitive and high-stakes deployments of speaker verification."
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Improved tampering localization in digital image forensics based on maximal entropy random walk,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Content authentication for neural imaging pipelines: End-to-end optimization of photo provenance in complex distribution channels,"Forensic analysis of digital photo provenance relies on intrinsic traces left in the photograph at the time of its acquisition. Such analysis becomes unreliable after heavy post-processing, such as down-sampling and re-compression applied upon distribution in the Web. This paper explores end-to-end optimization of the entire image acquisition and distribution workflow to facilitate reliable forensic analysis at the end of the distribution channel. We demonstrate that neural imaging pipelines can be trained to replace the internals of digital cameras, and jointly optimized for high-fidelity photo development and reliable provenance analysis. In our experiments, the proposed approach increased image manipulation detection accuracy from 45% to over 90%. The findings encourage further research towards building more reliable imaging pipelines with explicit provenance-guaranteeing properties."
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",A new approach to high-capacity annotation watermarking based on digital fountain codes,"Annotation watermarking is a technique that allows to associate content descriptions with digital images in a persistent and format independent manner. It is commonly used in medical applications and, hence, existing schemes have been designed to meet rigorous watermark transparency requirements. As a result, the effective capacity of such schemes is severely limited. In this paper, we present a new approach to annotation watermarking. We adopt the fountain coding paradigm and design a convenient watermark communication architecture which resembles a traditional packet network. Our approach allows for straightforward incorporation of content adaptivity, robustness against cropping and support for multiple data streams. In our study, we focus on high-capacity annotations and we assume different requirements with respect to the fidelity of the watermarked images. Our scheme is robust against …"
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",A scheme for censorship of sensitive image content with high-quality reconstruction ability,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Every shred helps: Assembling evidence from orphaned JPEG fragments,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",A novel approach to adaptive image authentication,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Image-like 2d barcodes using generalizations of the Kuznetsov–Tsybakov problem,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Overview of recent advances in CCTV processing chain in the INDECT and INSIGMA projects,Description not available
Paweł Korus,https://scholar.google.com/citations?user=UDEEvd0AAAAJ&hl=fil,"computer vision, signal processing, media forensics, watermarking, security",Dictionary attacks on speaker verification,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Pettingzoo: Gym for multi-agent reinforcement learning,"This paper introduces the PettingZoo library and the accompanying Agent Environment Cycle ("" AEC"") games model. PettingZoo is a library of diverse sets of multi-agent environments with a universal, elegant Python API. PettingZoo was developed with the goal of accelerating research in Multi-Agent Reinforcement Learning ("" MARL""), by making work more interchangeable, accessible and reproducible akin to what OpenAI's Gym library did for single-agent reinforcement learning. PettingZoo's API, while inheriting many features of Gym, is unique amongst MARL APIs in that it's based around the novel AEC games model. We argue, in part through case studies on major problems in popular MARL environments, that the popular game models are poor conceptual models of the games commonly used with MARL, that they promote severe bugs that are hard to detect, and that the AEC games model addresses these problems."
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics","Estimation of rotation gain thresholds considering fov, gender, and distractors",Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",ARC: Alignment-based Redirection Controller for Redirected Walking in Complex Environments,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Redirected walking in static and dynamic scenes using visibility polygons,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Generating emotive gaits for virtual agents using affect-based autoregression,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Eni: Quantifying environment compatibility for natural walking in virtual reality,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Augmenting physics education with haptic and visual feedback,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Pettingzoo: Gym for multi-agent reinforcement learning (2020),Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Estimation of rotation gain thresholds for redirected walking considering FOV and gender,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",PettingZoo: A Standard API for Multi-Agent Reinforcement Learning,"This paper introduces the PettingZoo library and the accompanying Agent Environment Cycle (“AEC”) games model. PettingZoo is a library of diverse sets of multi-agent environments with a universal, elegant Python API. PettingZoo was developed with the goal of accelerating research in Multi-Agent Reinforcement Learning (“MARL”), by making work more interchangeable, accessible and reproducible akin to what OpenAI’s Gym library did for single-agent reinforcement learning. PettingZoo’s API, while inheriting many features of Gym, is unique amongst MARL APIs in that it’s based around the novel AEC games model. We argue, in part through case studies on major problems in popular MARL environments, that the popular game models are poor conceptual models of games commonly used in MARL and accordingly can promote confusing bugs that are hard to detect, and that the AEC games model addresses these problems."
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",A framework for active haptic guidance using robotic haptic proxies,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",The impact of haptic and visual feedback on teaching,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Robust redirected walking in the wild,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Redirection Using Alignment,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Who you lookin'at? Perception of gaze direction in group settings depends on naturalness of gaze behavior and clutter,"Moving to online meetings inherently impairs our ability to perceive social cues such as the gaze direction of meeting participants. Much of the previous work on human gaze estimation has examined gaze near the forward direction, ie toward the camera. However, in-person group interactions include gaze directions over a much wider range. Here we examine the accuracy of estimating the gaze of human-like avatars looking at each other around a table. Gaze direction in this scene varies in magnitude from 22.5 to 157.5 degrees relative to the camera, and from 0 to 67.5 degrees relative to the avatar body. In the realistic condition, each avatar rotated its torso, head, and eyes according to previous work on human gaze behavior. In the simple turn condition, each avatar moved only its head and eyes, by the same angle. We also varied scene richness; richer scenes may provide stronger cues to depth and body angle …"
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Perceptual Thresholds for Radial Optic Flow Distortion in Near-Eye Stereoscopic Displays,Description not available
Niall L. Williams,https://scholar.google.com/citations?user=KIUsT1cAAAAJ&hl=en,"Virtual Reality, Applied Perception, Navigation, Computer Graphics",Natural Walking Interfaces to Improve Immersive Training in Virtual Reality,"Virtual reality (VR) allows users to be placed in a computer-generated environment and provides realistic visual feedback through motion tracking, high refresh rates, and a stereoscopic display [16]. VR presents a new opportunity to provide immersive experiences with applications to job training, entertainment, social interactions, and therapy and rehabilitation. One important aspect of providing users with a comfortable, immersive virtual experience is granting users the ability to freely explore the virtual environment (VE)[5, 6, 30]. Due to the importance of exploration for virtual experiences, it is crucial that we develop locomotion interfaces that provide the best user experience."
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Can Physical Tools that Adapt their Shape based on a Learner’s Performance Help in Motor Skill Training?,"Adaptive tools that can change their shape to support users with motor tasks have been used in a variety of applications, such as to improve ergonomics and support muscle memory. In this paper, we investigate whether shape-adapting tools can also help in motor skill training. In contrast to static training tools that maintain task difficulty at a fixed level during training, shape-adapting tools can vary task difficulty and thus keep learners’ training at the optimal challenge point, where the task is neither too easy, nor too difficult."
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Adapt2Learn: A Toolkit for Configuring the Learning Algorithm for Adaptive Physical Tools for Motor-Skill Learning,"A recent study on motor-skill training showed that adaptive training tools that use shape-change to adapt the training difficulty based on learners’ performance can lead to higher learning gains. However, to date, no support tools exist to help designers create adaptive learning tools. Our formative study shows that developing the adaptive learning algorithm poses a particular challenge. To address this, we built Adapt2Learn, a toolkit that auto-generates the learning algorithm for adaptive tools. Designers choose their tool’s sensors and actuators, Adapt2Learn then configures the learning algorithm and generates a microcontroller script that designers can deploy on the tool. Once uploaded, the script assesses the learner’s performance via the sensors, computes the training difficulty, and actuates the tool to adapt the difficulty. Adapt2Learn’s visualization tool then lets designers visualize their tool’s adaptation and …"
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Fabo: Integrating fabrication with a player’s gameplay in existing digital games,"Fabricating objects from a player’s gameplay, for example, collectibles of valuable game items, or custom game controllers shaped from game objects, expands ways to engage with digital games. Researchers currently create such integrated fabrication games from scratch, which is time-consuming and misses the potential of integrating fabrication with the myriad existing games. Integrating fabrication with the real-time gameplay of existing games, however, is challenging without access to the source files."
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Identifying game mechanics for integrating fabrication activities within existing digital games,"Integrating fabrication activities into existing video games provides opportunities for players to construct objects from their gameplay and bring the digital content into the physical world. In our prior work, we outlined a framework and developed a toolkit for integrating fabrication activities within existing digital games. Insights from our prior study highlighted the challenge of aligning fabrication mechanics with the existing game mechanics in order to strengthen the player aesthetics."
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",The reflective maker: Using reflection to support skill-learning in makerspaces,"In recent years, while HCI researchers have developed several systems that leverage the use of reflection for skill learning, the use of reflection-based learning of maker skills remains unexplored. We present ReflectiveMaker - a toolkit for experts and educators to design reflection exercises for novice learners in makerspaces. We describe the three components of our toolkit: (a) a designer interface to author the reflection prompts during fabrication activities, (b) a set of fabrication tools to sense the user’s activities and (c) a reflection diary interface to record the user’s reflections and analyze data on their learning progress. We then outline future work and envision a range of application scenarios."
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Understanding the educators’ practices in makerspaces for the design of education tools,"Makerspaces persist as formal and informal spaces of learning for youth, promoting continued interest in studying how design can support the variety of learning opportunities within these spaces. However, much of the current research examining learning in makerspaces neglects the perspectives of educators. This not only hinders our understanding of educators’ goals and how educators navigate makerspaces but also constrains how we frame the design space of the learning experiences and environments. To address this, we engaged in a set of semi-structured interviews to examine the contexts, goals, values, and practices of seven educators across five makerspaces. A thematic analysis of the data identified six key categories of competencies that these educators prioritize including a range of skills, practices, and knowledge, such as technical proficiency, communication, and contextual reflection. The …"
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Reimagining Systems for Learning Hands-on Creative and Maker Skills,"In the last decade, HCI researchers have designed and engineered several systems to lower the entry barrier for beginners and support novices in learning hands-on creative maker skills. These skills range from building electronics to fabricating physical artifacts. While much of the design and engineering of current learning systems is driven by the advances in technology, we can reimagine these systems by reorienting the design goals around constructivist and sociocultural theories of learning to support learning progression, engagement across artistic disciplines, and designing for inclusivity and accessibility. This one-day workshop aims to bring together the HCI researchers in systems engineering and learning sciences, challenge them to reimagine the future design of systems of learning creative maker skills, form connections across disciplines, and promote collaborative research in the systems of learning …"
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",What Can We Learn From Educators About Teaching in Makerspaces?,"Current research examining learning in makerspaces is primarily centered around the learners’ experiences and not the educators, thus presenting a gap not only in our understanding of educators’ perspectives but also in how we design educational technologies for learning in makerspaces. In our work, we address this gap through an interview study investigating seven educators’ experiences of teaching maker skills across five diverse makerspaces. Our thematic analysis of the educators’ practices resulted in an outline of the competencies that the educators centralize in their teaching, the strategies they integrate into their teaching practices, and the challenges they encounter while teaching in makerspaces. We discuss how this analysis can give insights into the educators’ values and perspectives of makerspace learning and inform the design of learning tools and experiences within the makerspaces."
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",SensorViz: Visualizing Sensor Data Across Different Stages of Prototyping Interactive Objects,"In this paper, we propose SensorViz, a visualization tool that supports novice makers during different stages of prototyping with sensors. SensorViz provides three modes of visualization: (1) visualizing datasheet specifications before buying sensors, (2) visualizing sensor interaction with the environment via AR before building the physical prototype, and (3) visualizing live/recorded sensor data to test the assembled prototype. SensorViz includes a library of visualization primitives for different types of sensor data and a sensor database builder, which once a new sensor is added automatically creates a matching visualization by composing visualization primitives. Our user study with 12 makers shows that users are more effective in selecting sensors and configuring sensor layouts using SensorViz compared to traditional prototyping utilizing datasheets and manual testing on the prototype. Our post hoc interviews …"
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Designing Adaptive Tools for Motor Skill Training,"We demonstrate the design of adaptive tools for motor skill training that use shape change to automatically vary task difficulty based on a learner’s performance. Studies [1] have shown that automatically-adaptive tools lead to significantly higher learning gains when compared to non-adaptive and manually-adaptive tools. We demonstrate the use of Adapt2Learn [2] - a toolkit that supports designers in building adaptive training tools. Adapt2Learn auto-generates an algorithm that converts a learner’s performance data into adaptation states during motor skill training. This algorithm, that maintains the training difficulty at the ’optimal challenge point’, can be uploaded to the micro-controller to convert several shape-changing tools into adaptive tools for motor skill training. We demonstrate 7 prototypes of adaptive tools for motor-skill learning to show applications in sports, music, rehabilitation, and accessibility."
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",An Open-ended System in Virtual Reality for Training Machining Skills,"With the rise in exploring Virtual Reality (VR) to enhance the training of psychomotor skills, several systems have been designed within the manufacturing sector to train for machining skills. However, existing industry training programs often lack the flexibility to accommodate human error and the adaptability to allow multiple paths to achieving the end task goal. We address this limitation through our VR training system by adopting an open-ended approach to system design. In this interactivity demo, we present our VR training simulation which is specifically tailored for practicing drilling skills using a 3-axis milling machine. This simulation offers an open-ended learning experience, guiding users through safety protocols, setup procedures, drilling tutorials, and open-ended practice sessions. It provides real-time feedback on mistakes and failures and an evaluation of the drilled geometries. For the demo, participants …"
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Training for Open-Ended Drilling through a Virtual Reality Simulation,Description not available
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",The reflective make-ar in-action: Using augmented reality for reflection-based learning of makerskills,"Recent work on reflective learning supports self-paced learning of skills like breadboarding and using power tools in makerspaces through a reflection exercise toolkit. This toolkit monitors the learners’ performances in real-time and prompts them to reflect both in-action and on-action i.e., during and after their maker activities. In this paper, we build on this prior work and use an augmented reality system to monitor, prompt, and record in-action reflections, i.e., while the maker activity is in progress. In particular, we propose a framework to design multi-modal reflective prompts for self-learning exercises using augmented reality with three specific goals - (1) adding real-world contextualization, (2) overlaying personalized multimodal contextual information for supporting in-action reflections, and (3) maintaining an immersive experience during the reflection exercises. We conclude with a discussion of three application …"
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Designing Tools for Autodidactic Learning of Skills,"In the last decade, HCI researchers have designed and engineered several systems to lower the entry barrier for beginners and support novices in learning hands-on creative skills, such as motor skills, fabrication, circuit prototyping, and design."
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Dynamic Tensegrity Systems—Investigating a case in reconfigurable habitable structures,Description not available
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Dynamic Tensegrity Systems,"Irregular tensegrity structures, due to their non-linear behavior, possess the potential ability to configure in multiple stable states. The kinematics and inherent properties of the compressive and tensile components govern the final static configuration of the system. The primary objective of the research is to study the non-linear behavior of irregular tensegrity structures and formulate a computational generative, evaluative and algorithmic method to design a structurally dynamic tensegrity system, with inherent potential to adapt to the varying contexts and its respective demands, requirements and spatial needs."
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Generating Reflection Prompts in Self-Directed Learning Activities with Generative AI,Description not available
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Designing Learner-centric Tools for Physical Skill-learning,Description not available
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Thirteen ways of looking: a theoretical inquiry in computational creative thinking,Description not available
Dishita G Turakhia,https://scholar.google.com/citations?user=43okw2AAAAAJ&hl=en,"Human Computer Interaction, Learning Systems, AR/VR, Computational Design, Architecture Design",Shape Modeling International 2013,Description not available
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Efficient construction of directed hopsets and parallel approximate shortest paths,"The approximate single-source shortest-path problem is as follows: given a graph with nonnegative edge weights and a designated source vertex s, return estimates of the distances from s to each other vertex such that the estimate falls between the true distance and (1+є) times the distance. This paper provides the first nearly work-efficient parallel algorithm with sublinear span (also called depth) for the approximate shortest-path problem on directed graphs. Specifically, for constant є and polynomially-bounded edge weights, our algorithm has work Õ(m) and span n 1/2+o(1). Several algorithms were previously known for the case of undirected graphs, but none of the techniques seem to translate to the directed setting."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Brief announcement: An improved distributed approximate single source shortest paths algorithm,"This brief announcement presents an algorithm for (1+ε) approximate single-source shortest paths for directed graphs with non-negative real edge weights in the CONGEST model that runs in Õ ((n^1/2 +D+n^2/5+o(1) D^2/5 )log W / ε^2) rounds, where W is the ratio between the largest and smallest non-zero edge weights."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Improved work span tradeoff for single source reachability and approximate shortest paths,"This brief announcement presents parallel algorithms with a tradeoff between work and span for single source reachability and approximate shortest paths on directed graphs. Both algorithms have ~O(mρ2 + nρ4) work and achieve n1/2+ o(1)/ρ span for all ρ ∈ [1,√n]."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Parallel exact shortest paths in almost linear work and square root depth,"This paper presents a randomized parallel single-source shortest paths (SSSP) algorithm for directed graphs with non-negative integer edge weights that solves the problem exactly in O(m) work and n1/2+o(1) span, with high probability. All previous exact SSSP algorithms with nearly linear work have linear span, even for undirected unweighted graphs. Our main technical contribution is to show a reduction from the exact SSSP to directed hopsets [6] using the iterative gradual rounding technique [9]. An (h, ε)-hopset is a set of weighted edges (sometimes called shortcuts) that when added to the graph admit h-hop paths with weights no more than (1 + ε) times the true shortest path distances."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Toward RSA-OAEP without random oracles,"We show new partial and full instantiation results under chosen-ciphertext security for the widely implemented and standardized RSA-OAEP encryption scheme of Bellare and Rogaway (EUROCRYPT 1994) and two variants. Prior work on such instantiations either showed negative results or settled for “passive” security notions like IND-CPA. More precisely, recall that RSA-OAEP adds redundancy and randomness to a message before composing two rounds of an underlying Feistel transform, whose round functions are modeled as random oracles (ROs), with RSA. Our main results are:
Either of the two oracles (while still modeling the other as a RO) can be instantiated in RSA-OAEP under IND-CCA2 using mild standard-model assumptions on the round functions and generalizations of algebraic properties of RSA shown by Barthe, Pointcheval, and Báguelin (CCS 2012). The algebraic properties are only shown to …"
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Understanding the Cluster Linear Program for Correlation Clustering,"In the classic Correlation Clustering problem introduced by Bansal, Blum, and Chawla ‍(FOCS 2002), the input is a complete graph where edges are labeled either + or −, and the goal is to find a partition of the vertices that minimizes the sum of the +edges across parts plus the sum of the -edges within parts. In recent years, Chawla, Makarychev, Schramm and Yaroslavtsev ‍(STOC 2015) gave a 2.06-approximation by providing a near-optimal rounding of the standard LP, and Cohen-Addad, Lee, Li, and Newman ‍(FOCS 2022, 2023) finally bypassed the integrality gap of 2 for this LP giving a 1.73-approximation for the problem. While introducing new ideas for Correlation Clustering, their algorithm is more complicated than typical approximation algorithms in the following two aspects: (1) It is based on two different relaxations with separate rounding algorithms connected by the round-or-cut procedure. (2) Each of …"
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Parallel shortest paths with negative edge weights,"This paper presents a parallel version of Goldberg's algorithm for the problem of single-source shortest paths with integer (including negatives) edge weights. Given an input graph with n vertices, m edges, and integer weights ≥-N, our algorithms solves the problem with Õ(m √n log N) work and n5/4+o(1) log N span, both with high probability. Our algorithm thus has work similar to Goldberg's algorithm while also achieving at least m1/4-o(1) parallelism. To generate our parallel version of Goldberg's algorithm, we solve two specific distance-limited shortest-path problems, both with work Õ(m) and span √L · n1/2+o(1), where L is the distance limit."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Breaking 3-factor approximation for correlation clustering in polylogarithmic rounds,"In this paper, we study parallel algorithms for the correlation clustering problem, where every pair of two different entities is labeled with similar or dissimilar. The goal is to partition the entities into clusters to minimize the number of disagreements with the labels. Currently, all efficient parallel algorithms have an approximation ratio of at least 3. In comparison with the 1.994 + ɛ ratio achieved by polynomial-time sequential algorithms [25], a significant gap exists."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Nearly optimal parallel algorithms for longest increasing subsequence,"The paper presents parallel algorithms for multiplying implicit simple unit-Monge matrices (Krusche and Tiskin, PPAM 2009) of size n x n in the EREW PRAM model. We show implicit simple unit-Monge matrices multiplication of size n x n can be achieved by a deterministic EREW PRAM algorithm with O(n log n log log n) total work and O(log3 n) span. This implies that there is a deterministic EREW PRAM algorithm solving the longest increasing subsequence (LIS) problem in O(n log2 n log log n) work and O(log 4 n) span. Furthermore, with randomization and bitwise operations, implicitly multiplying two simple unit-Monge matrices can be improved to O(n log n) work and O(log3n) span, which leads to a randomized EREW PRAM algorithm obtaining LIS in O(nlog2n) work and O(log4n) span with high probability. In the regime where the LIS has length k = Ψ(log3n), our results improve the span from Õ(n2/3) (Krusche …"
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Self-supervised Representation Learning on Electronic Health Records with Graph Kernel Infomax,"Learning Electronic Health Records (EHRs) representation is a preeminent yet under-discovered research topic. It benefits various clinical decision support applications, e.g., medication outcome prediction or patient similarity search. Current approaches focus on task-specific label supervision on vectorized sequential EHR, which is not applicable to large-scale unsupervised scenarios. Recently, contrastive learning has shown great success in self-supervised representation learning problems. However, complex temporality often degrades the performance. We propose Graph Kernel Infomax, a self-supervised graph kernel learning approach on the graphical representation of EHR, to overcome the previous problems. Unlike the state-of-the-art, we do not change the graph structure to construct augmented views. Instead, we use Kernel Subspace Augmentation to embed nodes into two geometrically different …"
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",I/O-efficient algorithms for topological sort and related problems,"This article presents I/O-efficient algorithms for topologically sorting a directed acyclic graph and for the more general problem identifying and topologically sorting the strongly connected components of a directed graph G = (V, E). Both algorithms are randomized and have I/O-costs O(sort(E) · poly(log V)), with high probability, where sort(E) = O(E/B log M/B(E/B)) is the I/O cost of sorting an |E|-element array on a machine with size-B blocks and size-M cache/internal memory. These are the first algorithms for these problems that do not incur at least one I/O per vertex, and as such these are the first I/O-efficient algorithms for sparse graphs. By applying the technique of time-forward processing, these algorithms also imply I/O-efficient algorithms for most problems on directed acyclic graphs, such as shortest paths, as well as the single-source reachability problem on arbitrary directed graphs."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Parallel and distributed exact single-source shortest paths with negative edge weights,Description not available
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Simultaneously Approximating All Norms for Massively Parallel Correlation Clustering,Description not available
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms","Parallel, Distributed, and Quantum Exact Single-Source Shortest Paths with Negative Edge Weights",Description not available
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Efficient Construction of Directed Hopsets and Parallel Single-source Shortest Paths,"The single-source shortest-path problem is as follows: given a graph with nonnegative edge weights and a designated source vertex s, return the distances from~s to each other vertex such. This paper presents a randomized parallel single-source shortest paths (SSSP) algorithm for directed graphs with non-negative integer edge weights that solves the exact SSSP problem in O (m) work and n^1/2+o(1) span, with high probability. All previous exact SSSP algorithms with nearly linear work have linear span, even for undirected unweighted graphs."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Nested Active-Time Scheduling,Description not available
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Brief Announcement: Nested Active-Time Scheduling,"The active-time scheduling problem considers the problem of scheduling preemptible jobs with windows (release times and deadlines) on a parallel machine that can schedule up to g jobs during each timestep. The goal in the active-time problem is to minimize the number of active steps, i.e., timesteps in which at least one job is scheduled."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",Single-Source Shortest Paths for Directed Graphs,"The single-source shortest path (SSSP) problem is as follows: Given a graph with nonnegative edge weights and a designated source vertex s, return the true distances from~ s to each other vertex. The approximate version of SSSP allows estimates of distance such that the estimate falls between the true distance and (1+ epsilon) times the ture distance. This dissertation mainly studies the SSSP problem for directed graphs in parallel and distributed models. This dissertation presents a series of efficient randomized algorithms with theoretical guarantees."
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",LRCRYPT: Leakage-Resilient Cryptographic System (Design and Implementation),"Due to the advancement of side-channel attacks, leakage-resilient cryptography has attracted a lot of attention in recent years. Many fruitful results have been proposed by researchers. Most, if not all, of these results are theoretical in nature. Not much has been done to realize these schemes for practical use. In this work, we design and provide a leakage-resilient cryptographic system with programming interfaces for users to build leakage-resilient cryptographic applications. consists of a few fundamental building blocks that perform leakage-resilient public-key encryption, leakage-resilient signature, and leakage-resilient secret-key encryption, which can also be extended to many existing leakage resilience cryptographic primitives. We have conducted both a security analysis and a performance evaluation on . To our knowledge, is the first to work in this …"
Nairen Cao,https://scholar.google.com/citations?user=OiiBPDwAAAAJ&hl=en,"Graph algorithms, Parallel algorithms",An ORAM Scheme with Improved Worst-Case Computational Overhead,"We construct a statistically secure ORAM with computational overhead of . Moreover, when accessing continuous blocks, our scheme can achieve an amortized complexity , which almost matches the theoretical lower bound of the ORAM problem. Our construction is based on a tree-based construction [16]. The technical novelty comes from the idea of combining blocks into a big block together with a more aggressive and efficient “flush” operation, which is the bottleneck of existing ORAM schemes. All in all, we can achieve better amortized overhead in our new scheme."
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",The surprising effectiveness of ppo in cooperative multi-agent games,"Proximal Policy Optimization (PPO) is a ubiquitous on-policy reinforcement learning algorithm but is significantly less utilized than off-policy learning algorithms in multi-agent settings. This is often due to the belief that PPO is significantly less sample efficient than off-policy methods in multi-agent systems. In this work, we carefully study the performance of PPO in cooperative multi-agent settings. We show that PPO-based multi-agent algorithms achieve surprisingly strong performance in four popular multi-agent testbeds: the particle-world environments, the StarCraft multi-agent challenge, the Hanabi challenge, and Google Research Football, with minimal hyperparameter tuning and without any domain-specific algorithmic modifications or architectures. Importantly, compared to competitive off-policy methods, PPO often achieves competitive or superior results in both final returns and sample efficiency. Finally, through ablation studies, we analyze implementation and hyperparameter factors that are critical to PPO's empirical performance, and give concrete practical suggestions regarding these factors. Our results show that when using these practices, simple PPO-based methods are a strong baseline in cooperative multi-agent reinforcement learning. Source code is released at https://github. com/marlbenchmark/on-policy."
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Flow: Architecture and benchmarking for reinforcement learning in traffic control,"Flow is a new computational framework, built to support a key need triggered by the rapid growth of autonomy in ground traffic: controllers for autonomous vehicles in the presence of complex nonlinear dynamics in traffic. Leveraging recent advances in deep Reinforcement Learning (RL), Flow enables the use of RL methods such as policy gradient for traffic control and enables benchmarking the performance of classical (including hand-designed) controllers with learned policies (control laws). Flow integrates traffic microsimulator SUMO with deep reinforcement learning library rllab and enables the easy design of traffic tasks, including different networks configurations and vehicle dynamics. We use Flow to develop reliable controllers for complex problems, such as controlling mixed-autonomy traffic (involving both autonomous and human-driven vehicles) in a ring road. For this, we first show that state-of-the-art hand-designed controllers excel when in-distribution, but fail to generalize; then, we show that even simple neural network policies can solve the stabilization task across density settings and generalize to outof-distribution settings."
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Emergent complexity and zero-shot transfer via unsupervised environment design,"A wide range of reinforcement learning (RL) problems---including robustness, transfer learning, unsupervised RL, and emergent complexity---require specifying a distribution of tasks or environments in which a policy will be trained. However, creating a useful distribution of environments is error prone, and takes a significant amount of developer time and effort. We propose Unsupervised Environment Design (UED) as an alternative paradigm, where developers provide environments with unknown parameters, and these parameters are used to automatically produce a distribution over valid, solvable environments. Existing approaches to automatically generating environments suffer from common failure modes: domain randomization cannot generate structure or adapt the difficulty of the environment to the agent's learning progress, and minimax adversarial training leads to worst-case environments that are often unsolvable. To generate structured, solvable environments for our protagonist agent, we introduce a second, antagonist agent that is allied with the environment-generating adversary. The adversary is motivated to generate environments which maximize regret, defined as the difference between the protagonist and antagonist agent's return. We call our technique Protagonist Antagonist Induced Regret Environment Design (PAIRED). Our experiments demonstrate that PAIRED produces a natural curriculum of increasingly complex environments, and PAIRED agents achieve higher zero-shot transfer performance when tested in highly novel environments."
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Benchmarks for reinforcement learning in mixed-autonomy traffic,"We release new benchmarks in the use of deep reinforcement learning (RL) to create controllers for mixed-autonomy traffic, where connected and autonomous vehicles (CAVs) interact with human drivers and infrastructure. Benchmarks, such as Mujoco or the Arcade Learning Environment, have spurred new research by enabling researchers to effectively compare their results so that they can focus on algorithmic improvements and control techniques rather than system design. To promote similar advances in traffic control via RL, we propose four benchmarks, based on three new traffic scenarios, illustrating distinct reinforcement learning problems with applications to mixed-autonomy traffic. We provide an introduction to each control problem, an overview of their MDP structures, and preliminary performance results from commonly used RL algorithms. For the purpose of reproducibility, the benchmarks, reference implementations, and tutorials are available at https://github. com/flow-project/flow."
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Flow: A modular learning framework for mixed autonomy traffic,Description not available
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Emergent behaviors in mixed-autonomy traffic,"Traffic dynamics are often modeled by complex dynamical systems for which classical analysis tools can struggle to provide tractable policies used by transportation agencies and planners. In light of the introduction of automated vehicles into transportation systems, there is a new need for understanding the impacts of automation on transportation networks. The present article formulates and approaches the mixed-autonomy traffic control problem (where both automated and human-driven vehicles are present) using the powerful framework of deep reinforcement learning (RL). The resulting policies and emergent behaviors in mixed-autonomy traffic settings provide insight for the potential for automation of traffic through mixed fleets of automated and manned vehicles. Model-free learning methods are shown to naturally select policies and behaviors previously designed by model-driven approaches, such as stabilization and platooning, known to improve ring road efficiency and to even exceed a theoretical velocity limit. Remarkably, RL succeeds at maximizing velocity by effectively leveraging the structure of the human driving behavior to form an efficient vehicle spacing for an intersection network. We describe our results in the context of existing control theoretic results for stability analysis and mixed-autonomy analysis. This article additionally introduces state equivalence classes to improve the sample complexity for the learning methods."
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Lagrangian control through deep-rl: Applications to bottleneck decongestion,Description not available
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Simulation to scaled city: zero-shot policy transfer for traffic control via autonomous vehicles,"Using deep reinforcement learning, we successfully train a set of two autonomous vehicles to lead a fleet of vehicles onto a round-about and then transfer this policy from simulation to a scaled city without fine-tuning. We use Flow, a library for deep reinforcement learning in microsimulators, to train two policies, (1) a policy with noise injected into the state and action space and (2) a policy without any injected noise. In simulation, the autonomous vehicles learn an emergent metering behavior for both policies which allows smooth merging. We then directly transfer this policy without any tuning to the University of Delaware's Scaled Smart City (UDSSC), a 1:25 scale testbed for connected and automated vehicles. We characterize the performance of the transferred policy based on how thoroughly the ramp metering behavior is captured in UDSSC. We show that the noise-free policy results in severe slowdowns and …"
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Robust reinforcement learning using adversarial populations,Description not available
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Metallization and Superconductivity in the Hydrogen-Rich Ionic Salt BaReH9,"BaReH9 is an exceedingly high-hydrogen-content metal hydride that is predicted to exhibit interesting behavior under pressure. The high-pressure electronic properties of this material were investigated using diamond-anvil-cell electrical conductivity techniques to megabar (100 GPa) pressures. The measurements show that BeReH9 transforms into a metal and then a superconductor above 100 GPa with a maximum transition temperature (Tc) near 7 K. The occurrence of superconductivity was confirmed by the suppression of the resistance drop upon application of magnetic fields. The transition to the metallic phase is sluggish, but it is accelerated by laser irradiation. Raman scattering and X-ray diffraction measurements, used to supplement the electrical measurements, indicate that the Ba–Re sublattice is largely preserved upon compression under the conditions explored, but there is a possibility that hydrogen …"
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Flow: Deep reinforcement learning for control in sumo,"We detail the motivation and design decisions underpinning Flow, a computational framework integrating SUMO with the deep reinforcement learning libraries rllab and RLlib, allowing researchers to apply deep reinforcement learning (RL) methods to traffic scenarios, and permitting vehicle and infrastructure control in highly varied traffic environments. Users of Flow can rapidly design a wide variety of traffic scenarios in SUMO, enabling the development of controllers for autonomous vehicles and intelligent infrastructure across a broad range of settings."
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Framework for control and deep reinforcement learning in traffic,Description not available
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Zero-shot autonomous vehicle policy transfer: From simulation to real-world via adversarial learning,Description not available
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Flow: A modular learning framework for autonomy in traffic,"The rapid development of autonomous vehicles (AVs) holds vast potential for transportation systems through improved safety, efficiency, and access to mobility. However, new methodologies are needed for the design of vehicles and transportation systems to enable these positive outcomes, due to numerous technical, political, and human factors challenges. This article focuses on tackling important technical challenges arising from the partial adoption of autonomy (hence termed mixed autonomy, to involve both AVs and human-driven vehicles): partial control and partial observation, complex dynamics of multi-vehicle interactions, and the sheer variety of traffic settings represented by real-world networks. To enable the study of the full diversity of traffic settings, we first propose decomposing traffic control tasks into components called modules, which may be configured and composed to create new control tasks of interest. These modules include salient aspects of traffic control tasks: networks, actors, control laws, metrics, initialization, and additional dynamics. Second, we study the potential of modelfree deep Reinforcement Learning (RL) methods to address the complexity of traffic dynamics. The resulting modular learning framework is called Flow. Using Flow, we create and study a variety of mixed-autonomy settings, including single-lane, multilane, and intersection traffic In all cases, the learned control law exceeds human driving performance (measured by system-level average velocity) by at least 40% with only 5-10% adoption of AVs. In the case of partially-observed single-lane traffic, we show that a low-parameter neural network control law …"
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",A learning agent that acquires social norms from public sanctions in decentralized multi-agent settings,"Society is characterized by the presence of a variety of social norms: collective patterns of sanctioning that can prevent miscoordination and free-riding. Inspired by this, we aim to construct learning dynamics where potentially beneficial social norms can emerge. Since social norms are underpinned by sanctioning, we introduce a training regime where agents can access all sanctioning events but learning is otherwise decentralized. This setting is technologically interesting because sanctioning events may be the only available public signal in decentralized multi-agent systems where reward or policy-sharing is infeasible or undesirable. To achieve collective action in this setting, we construct an agent architecture containing a classifier module that categorizes observed behaviors as approved or disapproved, and a motivation to punish in accord with the group. We show that social norms emerge in multi-agent …"
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Nocturne: a scalable driving benchmark for bringing multi-agent learning one step closer to the real world,"We introduce\textit {Nocturne}, a new 2D driving simulator for investigating multi-agent coordination under partial observability. The focus of Nocturne is to enable research into inference and theory of mind in real-world multi-agent settings without the computational overhead of computer vision and feature extraction from images. Agents in this simulator only observe an obstructed view of the scene, mimicking human visual sensing constraints. Unlike existing benchmarks that are bottlenecked by rendering human-like observations directly using a camera input, Nocturne uses efficient intersection methods to compute a vectorized set of visible features in a C++ back-end, allowing the simulator to run at steps-per-second. Using open-source trajectory and map data, we construct a simulator to load and replay arbitrary trajectories and scenes from real-world driving data. Using this environment, we benchmark reinforcement-learning and imitation-learning agents and demonstrate that the agents are quite far from human-level coordination ability and deviate significantly from the expert trajectories."
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Deploying traffic smoothing cruise controllers learned from trajectory data,Description not available
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Unified automatic control of vehicular systems with reinforcement learning,Description not available
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control",Particle dynamics in damped nonlinear quadrupole ion traps,"We examine the motions of particles in quadrupole ion traps as a function of damping and trapping forces, including cases where nonlinear damping or nonlinearities in the electric field geometry play significant roles. In the absence of nonlinearities, particles are either damped to the trap center or ejected, while their addition brings about a rich spectrum of stable closed particle trajectories. In three-dimensional (3D) quadrupole traps, the extended orbits are typically confined to the trap axis, and for this case we present a 1D analysis of the relevant equation of motion. We follow this with an analysis of 2D quadrupole traps that frequently show diamond-shaped closed orbits. For both the 1D and 2D cases, we present experimental observations of the calculated trajectories in microparticle ion traps. We also report the discovery of a new collective behavior in damped 2D microparticle ion traps, where particles …"
Eugene Vinitsky,https://scholar.google.com/citations?user=6dr5fLEAAAAJ&hl=en&oi=ao,"Reinforcement Learning, Autonomous Vehicles, Multi-agent Systems, Control","Integrated framework of vehicle dynamics, instabilities, energy models, and sparse flow smoothing controllers","This work presents an integrated framework of: vehicle dynamics models, with a particular attention to instabilities and traffic waves; vehicle energy models, with particular attention to accurate energy values for strongly unsteady driving profiles; and sparse Lagrangian controls via automated vehicles, with a focus on controls that can be executed via existing technology such as adaptive cruise control systems. This framework serves as a key building block in developing control strategies for human-in-the-loop traffic flow smoothing on real highways. In this contribution, we outline the fundamental merits of integrating vehicle dynamics and energy modeling into a single framework, and we demonstrate the energy impact of sparse flow smoothing controllers via simulation results."
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI","Minerva: Enabling Low-Power, Highly-Accurate Deep Neural Network Accelerators","The continued success of Deep Neural Networks (DNNs) in classification tasks has sparked a trend of accelerating their execution with specialized hardware. While published designs easily give an order of magnitude improvement over general-purpose hardware, few look beyond an initial implementation. This paper presents Minerva, a highly automated co-design approach across the algorithm, architecture, and circuit levels to optimize DNN hardware accelerators. Compared to an established fixed-point accelerator baseline, we show that fine-grained, heterogeneous datatype optimization reduces power by 1.5×; aggressive, inline predication and pruning of small activity values further reduces power by 2.0×; and active hardware fault detection coupled with domain-aware error mitigation eliminates an additional 2.7× through lowering SRAM voltages. Across five datasets, these optimizations provide a collective …"
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Machine learning at facebook: Understanding inference at the edge,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI","Aladdin: A pre-rtl, power-performance accelerator simulator enabling large design space exploration of customized architectures","Hardware specialization, in the form of accelerators that provide custom datapath and control for specific algorithms and applications, promises impressive performance and energy advantages compared to traditional architectures. Current research in accelerator analysis relies on RTL-based synthesis flows to produce accurate timing, power, and area estimates. Such techniques not only require significant effort and expertise but are also slow and tedious to use, making large design space exploration infeasible. To overcome this problem, we present Aladdin, a pre-RTL, power-performance accelerator modeling framework and demonstrate its application to system-on-chip (SoC) simulation. Aladdin estimates performance, power, and area of accelerators within 0.9%, 4.9%, and 6.6% with respect to RTL implementations. Integrated with architecture-level core and memory hierarchy simulators, Aladdin provides …"
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Ares: A framework for quantifying the resilience of deep neural networks,"As the use of deep neural networks continues to grow, so does the fraction of compute cycles devoted to their execution. This has led the CAD and architecture communities to devote considerable attention to building DNN hardware. Despite these efforts, the fault tolerance of DNNs has generally been overlooked. This paper is the first to conduct a large-scale, empirical study of DNN resilience. Motivated by the inherent algorithmic resilience of DNNs, we are interested in understanding the relationship between fault rate and model accuracy. To do so, we present Ares: a light-weight, DNN-specific fault injection framework validated within 12% of real hardware. We find that DNN fault tolerance varies by orders of magnitude with respect to model, layer type, and structure."
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",MachSuite: Benchmarks for Accelerator Design and Customized Architectures,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",The architectural implications of facebook's dnn-based personalized recommendation,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Recnmp: Accelerating personalized recommendation with near-memory processing,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Fathom: Reference workloads for modern deep learning methods,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Deeprecsys: A system for optimizing end-to-end at-scale neural recommendation inference,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Cheetah: Optimizing and accelerating homomorphic encryption for private inference,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",A case for efficient accelerator design space exploration via bayesian optimization,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Deepreduce: Relu reduction for fast private inference,"The recent rise of privacy concerns has led researchers to devise methods for private neural inference—where inferences are made directly on encrypted data, never seeing inputs. The primary challenge facing private inference is that computing on encrypted data levies an impractically-high latency penalty, stemming mostly from non-linear operators like ReLU. Enabling practical and private inference requires new optimization methods that minimize network ReLU counts while preserving accuracy. This paper proposes DeepReDuce: a set of optimizations for the judicious removal of ReLUs to reduce private inference latency. The key insight is that not all ReLUs contribute equally to accuracy. We leverage this insight to drop, or remove, ReLUs from classic networks to significantly reduce inference latency and maintain high accuracy. Given a network architecture, DeepReDuce outputs a Pareto frontier of networks that tradeoff the number of ReLUs and accuracy. Compared to the state-of-the-art for private inference DeepReDuce improves accuracy and reduces ReLU count by up to 3.5%(iso-ReLU count) and 3.5 x (iso-accuracy), respectively."
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Cryptonas: Private inference on a relu budget,"Machine learning as a service has given raise to privacy concerns surrounding clients' data and providers' models and has catalyzed research in private inference (PI): methods to process inferences without disclosing inputs. Recently, researchers have adapted cryptographic techniques to show PI is possible, however all solutions increase inference latency beyond practical limits. This paper makes the observation that existing models are ill-suited for PI and proposes a novel NAS method, named CryptoNAS, for finding and tailoring models to the needs of PI. The key insight is that in PI operator latency cost are inverted: non-linear operations (eg, ReLU) dominate latency, while linear layers become effectively free. We develop the idea of a ReLU budget as a proxy for inference latency and use CryptoNAS to build models that maximize accuracy within a given budget. CryptoNAS improves accuracy by 3.4% and latency by 2.4 x over the state-of-the-art."
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Masr: A modular accelerator for sparse rnns,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",The aladdin approach to accelerator design and modeling,Description not available
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Weightless: Lossy weight encoding for deep neural network compression,"The large memory requirements of deep neural networks limit their deployment and adoption on many devices. Model compression methods effectively reduce the memory requirements of these models, usually through applying transformations such as weight pruning or quantization. In this paper, we present a novel scheme for lossy weight encoding co-designed with weight simplification techniques. The encoding is based on the Bloomier filter, a probabilistic data structure that can save space at the cost of introducing random errors. Leveraging the ability of neural networks to tolerate these imperfections and by re-training around the errors, the proposed technique, named Weightless, can compress weights by up to 496x without loss of model accuracy. This results in up to a 1.51 x improvement over the state-of-the-art."
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Deep learning for computer architects,"Machine learning, and specifically deep learning, has been hugely disruptive in many fields of computer science. The success of deep learning techniques in solving notoriously difficult classification and regression problems has resulted in their rapid adoption in solving real-world problems. The emergence of deep learning is widely attributed to a virtuous cycle whereby fundamental advancements in training deeper models were enabled by the availability of massive datasets and high-performance computer hardware."
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Maxnvm: Maximizing dnn storage density and inference efficiency with sparse encoding and error mitigation,"Deeply embedded applications require low-power, low-cost hardware that fits within stringent area constraints. Deep learning has many potential uses in these domains, but introduces significant inefficiencies stemming from off-chip DRAM accesses of model weights. Ideally, models would fit entirely on-chip. However, even with compression, memory requirements for state-of-the-art models make on-chip inference impractical. Due to increased density, emerging eNVMs are one promising solution."
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",Porcupine: A synthesizing compiler for vectorized homomorphic encryption,"Homomorphic encryption (HE) is a privacy-preserving technique that enables computation directly on encrypted data. Despite its promise, HE has seen limited use due to performance overheads and compilation challenges. Recent work has made significant advances to address the performance overheads but automatic compilation of efficient HE kernels remains relatively unexplored."
Brandon Reagen,https://scholar.google.com/citations?user=cO2uYoAAAAAJ&hl=en,"Computer Architecture, Machine Learning, Privacy, VLSI",On-chip deep neural network storage with multi-level eNVM,"One of the biggest performance bottlenecks of today's neural network (NN) accelerators is off-chip memory accesses [11]. In this paper, we propose a method to use multi-level, embedded nonvolatile memory (eNVM) to eliminate all off-chip weight accesses. The use of multi-level memory cells increases the probability of faults. Therefore, we co-design the weights and memories such that their properties complement each other and the faults result in no noticeable NN accuracy loss. In the extreme case, the weights in fully connected layers can be stored using a single transistor. With weight pruning and clustering, we show our technique reduces the memory area by over an order of magnitude compared to an SRAM baseline. In the case of VGG16 (130M weights), we are able to store all the weights in 4.9 mm2, well within the area allocated to SRAM in modern NN accelerators [6]."
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",COVID-19 Transforms Healthcare Through Telemedicine: Evidence from the Field,"This study provides data on the feasibility and impact of video-enabled telemedicine use among patients and providers and its impact on urgent and nonurgent healthcare delivery from one large health system (NYU Langone Health) at the epicenter of the coronavirus disease 2019 (COVID-19) outbreak in the United States. Between March 2nd and April 14th 2020, telemedicine visits increased from 102.4 daily to 801.6 daily. (683% increase) in urgent care after the system-wide expansion of virtual urgent care staff in response to COVID-19. Of all virtual visits post expansion, 56.2% and 17.6% urgent and nonurgent visits, respectively, were COVID-19–related. Telemedicine usage was highest by patients 20 to 44 years of age, particularly for urgent care. The COVID-19 pandemic has driven rapid expansion of telemedicine use for urgent care and nonurgent care visits beyond baseline periods. This reflects an …"
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",What Motivates Wikipedians?,"In order to increase and enhance user-generated content contributions, it is important to understand the factors that lead people to freely share their time and knowledge with others."
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Analysis of participation in an online photo‐sharing community: A multidimensional perspective,"In recent years we have witnessed a significant growth of social‐computing communities—online services in which users share information in various forms. As content contributions from participants are critical to the viability of these communities, it is important to understand what drives users to participate and share information with others in such settings. We extend previous literature on user contribution by studying the factors that are associated with various forms of participation in a large online photo‐sharing community. Using survey and system data, we examine four different forms of participation and consider the differences between these forms. We build on theories of motivation to examine the relationship between users' participation and their motivations with respect to their tenure in the community. Amongst our findings, we identify individual motivations (both extrinsic and intrinsic) that underpin user …"
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Exploring motivations for contributing to open source initiatives: The roles of contribution context and personal values,Description not available
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW","SONYC: A System for the Monitoring, Analysis and Mitigation of Urban Noise Pollution","SONYC integrates sensors, machine listening, data analytics, and citizen science to address noise pollution in New York City."
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Scientists@ Home: what drives the quantity and quality of online citizen science participation?,"Online citizen science offers a low-cost way to strengthen the infrastructure for scientific research and engage members of the public in science. As the sustainability of online citizen science projects depends on volunteers who contribute their skills, time, and energy, the objective of this study is to investigate effects of motivational factors on the quantity and quality of citizen scientists' contribution. Building on the social movement participation model, findings from a longitudinal empirical study in three different citizen science projects reveal that quantity of contribution is determined by collective motives, norm-oriented motives, reputation, and intrinsic motives. Contribution quality, on the other hand, is positively affected only by collective motives and reputation. We discuss implications for research on the motivation for participation in technology-mediated social participation and for the practice of citizen science."
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Information Quality in Wikipedia: The Effects of Group Composition and Task Conflict,"The success of Wikipedia demonstrates that self-organizing production communities can produce high-quality information-based products. Research on Wikipedia has proceeded largely atheoretically, focusing on (1) the diversity in members' knowledge bases as a determinant of Wikipedia's content quality, (2) the task-related conflicts that occur during the collaborative authoring process, and (3) the different roles members play in Wikipedia. We develop a theoretical model that explains how these three factors interact to determine the quality of Wikipedia articles. The results from the empirical study of 96 Wikipedia articles suggest that (1) diversity should be encouraged, as the creative abrasion that is generated when cognitively diverse members engage in task-related conflict leads to higher-quality articles, (2) task conflict should be managed, as conflict—notwithstanding its contribution to creative abrasion—can …"
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Telemedicine and Healthcare Disparities: A Cohort Study in a Large Healthcare System in New York City During COVID-19,"Through the coronavirus disease 2019 (COVID-19) pandemic, telemedicine became a necessary entry point into the process of diagnosis, triage, and treatment. Racial and ethnic disparities in healthcare have been well documented in COVID-19 with respect to risk of infection and in-hospital outcomes once admitted, and here we assess disparities in those who access healthcare via telemedicine for COVID-19."
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Users' personality and perceived ease of use of digital libraries: The case for resistance to change,"The use of digital libraries has seen steady growth in the past two decades. However, as with other new technologies, effective use of digital libraries depends on user acceptance, which in turn is affected by users' perception of the system's ease of use. Since the introduction of new technologies often involves some form of change for users, the recent identification of the resistance to change (RTC) personality trait, and the development of a scale to measure it, provides an opportunity to assess the impact of RTC on new users of a digital library system. Drawing on prior research focused on personal differences and system characteristics as determinants of perceived ease of use, in the present study we explore the relationship between RTC and perceived ease of use of a university digital library. The results of a survey of 170 new users of the library system suggest that RTC is a significant determinant of perceived …"
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Sources of Volunteer Motivation: Transformational Leadership and Personal Motives Influence Volunteer Outcomes,"We examined the separate influences of volunteers' personal motives and their team leaders' behaviors on volunteer satisfaction and contributions, along with mediating processes suggested by self‐determination theory. Participants were 302 volunteers who worked in teams at various sites through a central agency. As predicted, both personal motives for volunteering and transformational leadership influenced volunteer satisfaction through enhanced work meaningfulness and higher‐quality team relationships. However, motives that predicted volunteer contribution were different from those that predicted satisfaction. Whereas satisfaction was positively associated with motives concerning esteem enhancement and value expression, contribution was positively associated with motives to gain understanding and negatively related to motives pertaining to esteem enhancement and social concerns. Transformational …"
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",The persuasive power of data visualization,Description not available
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Dusting for science: motivation and participation of digital citizen science volunteers,"Digital citizen science offers a low-cost way to strengthen the scientific infrastructure, and engage members of the public in science. It is based on two pillars:(1)a technological pillar, which involves developing computer systems to manage large amounts of distributed resources, and (2) a motivational pillar, which involves attracting and retaining volunteers who would contribute their skills, time, and effort to a scientific cause. While the technological dimension has been widely studied, the motivational dimension received little attention to date. To address this gap, we surveyed volunteers at Stardust@home a digital citizen science project, in which volunteers classify online images from NASA's Stardust spacecraft. We found that collective and intrinsic motivations are the most salient motivational factors, whereas reward motives seem to be less relevant. We also found that intrinsic and norm-oriented motives are most …"
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",What drives content tagging: the case of photos on Flickr,"We examine tagging behavior on Flickr, a public photo-sharing website. We build on previous qualitative research that exposed a taxonomy of tagging motivations, as well as on social presence research. The motivation taxonomy suggests that motivations for tagging are tied to the intended target audience of the tags --- the users themselves, family and friends, or the general public. Using multiple data sources, including a survey and independent system data, we examine which motivations are associated with tagging level, and estimate the magnitude of their contribution. We find that the levels of the Self and Public motivations, together with social presence indicators, are positively correlated with tagging level; Family & Friends motivations are not significantly correlated with tagging. The findings and the use of survey method carry implications for designers of tagging and other social systems on the web."
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",How Deceptive are Deceptive Visualizations?: An Empirical Analysis of Common Distortion Techniques,"In this paper, we present an empirical analysis of deceptive visualizations. We start with an in-depth analysis of what deception means in the context of data visualization, and categorize deceptive visualizations based on the type of deception they lead to. We identify popular distortion techniques and the type of visualizations those distortions can be applied to, and formalize why deception occurs with those distortions. We create four deceptive visualizations using the selected distortion techniques, and run a crowdsourced user study to identify the deceptiveness of those visualizations. We then present the findings of our study and show how deceptive each of these visual distortion techniques are, and for what kind of questions the misinterpretation occurs. We also analyze individual differences among participants and present the effect of some of those variables on participants' responses. This paper presents a first …"
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW","Personality and technology acceptance: Personal innovativeness in IT, openness and resistance to change",Description not available
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Technology-Mediated Citizen Science Participation: A Motivational Model,"We propose and test a framework of the antecedents of contribution in two technology-mediated citizen science projects, with different degrees of task granularity. Comparing earlier findings on the motivations of volunteers in a web-based image analysis project (high granularity), with new findings on the motivations of volunteers in a volunteer computing project (low granularity), we found that participation task granularity is correlated with motivation levels. Further, we found that collective and intrinsic motives are the most salient motivational factors, whereas reward motives are less important for volunteers. Intrinsic, norm-oriented and reputation-seeking motives were most strongly associated with participation intentions, which were, in turn, associated with participation. Finally, comparing the relationship between motives and participation among the two volunteer populations, we found that active-participation volunteers are characterized by significantly stronger association between collective motives and contribution intention, whereas passive-participation volunteers are characterized by significantly stronger association between identification with the community and contribution intention. Implications for research and practice are discussed."
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW","Spear-Phishing in the Wild: A Real-World Study of Personality, Phishing Self-Efficacy and Vulnerability to Spear-Phishing Attacks","Recent research has begun to focus on the factors that cause people to respond to phishing attacks. In this study a real-world spear-phishing attack was performed on employees in organizational settings in order to examine how users’ personality, attitudinal and perceived efficacy factors affect their tendency to expose themselves to such an attack. Spear-phishing attacks are more sophisticated than regular phishing attacks as they use personal information about their intended victim and present a stronger challenge for detection by both the potential victims as well as email phishing filters."
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Resistance to change and the adoption of digital libraries: An integrative model,"In this paper we extend earlier work on the role of the personality trait of resistance to change (RTC) in the adoption of digital libraries. We present an integrative study, drawing on a number of research streams, including IT adoption, social psychology, and digital‐library acceptance. Using structural equation modeling, we confirm RTC as a direct antecedent of effort expectancy. In addition, we also find that by affecting computer anxiety and result demonstrability, RTC acts as an indirect antecedent to both effort expectancy and performance expectancy, which in turn determine user intention to adopt digital library technology. Implications for research and practice are discussed."
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Gender differences in Wikipedia editing,"As Wikipedia has become an indispensable source of online information, concerns about who writes, edits, and maintains it have come to the forefront. In particular, the 2010 UNU-MERIT survey found evidence of a significant gender skew: fewer than 13% of Wikipedia contributors are women. However, the number of contributors is just one way to examine gender differences in contribution. In this paper we take a more fine-grained perspective by examining how much and what types of Wiki-work men and women tend to do. First, we find that the so-called ""Gender Gap"" in number of editors may not be as wide as prior studies have suggested. Second, although more than 80% of editors in our sample were men, among the bottom 75% of editors by activity-level, we find that men and women made similar numbers of revisions. However, among the most active Wikipedians men tended to make many more revisions …"
Oded Nov,https://scholar.google.com/citations?user=G0rV_dcAAAAJ&hl=en&oi=ao,"Human Computer Interaction, Human-AI Interaction, Digital Health, Algorithmic Advice, CSCW",Putting ChatGPT’s Medical Advice to the (Turing) Test: Survey Study,"Chatbots are being piloted to draft responses to patient questions, but patients’ ability to distinguish between provider and chatbot responses and patients’ trust in chatbots’ functions are not well established."
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Youth violence: What we know and what we need to know.,"School shootings tear the fabric of society. In the wake of a school shooting, parents, pediatricians, policymakers, politicians, and the public search for “the” cause of the shooting. But there is no single cause. The causes of school shootings are extremely complex. After the Sandy Hook Elementary School rampage shooting in Newtown, Connecticut, we wrote a report for the National Science Foundation on what is known and not known about youth violence. This article summarizes and updates that report. After distinguishing violent behavior from aggressive behavior, we describe the prevalence of gun violence in the United States and age-related risks for violence. We delineate important differences between violence in the context of rare rampage school shootings, and much more common urban street violence. Acts of violence are influenced by multiple factors, often acting together. We summarize evidence on …"
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Fast subset scan for spatial pattern detection,"We propose a new ‘fast subset scan’ approach for accurate and computationally efficient event detection in massive data sets. We treat event detection as a search over subsets of data records, finding the subset which maximizes some score function. We prove that many commonly used functions (e.g. Kulldorff’s spatial scan statistic and extensions) satisfy the ‘linear time subset scanning’ property, enabling exact and efficient optimization over subsets. In the spatial setting, we demonstrate that proximity-constrained subset scans substantially improve the timeliness and accuracy of event detection, detecting emerging outbreaks of disease 2 days faster than existing methods."
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Rapid Detection of Significant Spatial Clusters,"Given an N x N grid of squares, where each square has a count cij and an underlying population pij, our goal is to find the rectangular region with the highest density, and to calculate its significance by randomization. An arbitrary density function D, dependent on a region's total count C and total population P, can be used. For example, if each count represents the number of disease cases occurring in that square, we can use Kulldorff's spatial scan statistic DK to find the most significant spatial disease cluster. A naive approach to finding the maximum density region requires O(N4) time, and is generally computationally infeasible. We present a multiresolution algorithm which partitions the grid into overlapping regions using a novel overlap-kd tree data structure, bounds the maximum score of subregions contained in each region, and prunes regions which cannot contain the maximum density region. For sufficiently …"
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Non-parametric scan statistics for event detection and forecasting in heterogeneous social media graphs,"Event detection in social media is an important but challenging problem. Most existing approaches are based on burst detection, topic modeling, or clustering techniques, which cannot naturally model the implicit heterogeneous network structure in social media. As a result, only limited information, such as terms and geographic locations, can be used. This paper presents Non-Parametric Heterogeneous Graph Scan (NPHGS), a new approach that considers the entire heterogeneous network for event detection: we first model the network as a ""sensor"" network, in which each node senses its ""neighborhood environment"" and reports an empirical p-value measuring its current level of anomalousness for each time interval (e.g., hour or day). Then, we efficiently maximize a nonparametric scan statistic over connected subgraphs to identify the most anomalous network clusters. Finally, the event represented by each …"
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Using artificial intelligence to improve hospital inpatient care,Description not available
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Detection of emerging space-time clusters,"We propose a new class of spatio-temporal cluster detection methods designed for the rapid detection of emerging space-time clusters. We focus on the motivating application of prospective disease surveillance: detecting space-time clusters of disease cases resulting from an emerging disease outbreak. Automatic, real-time detection of outbreaks can enable rapid epidemiological response, potentially reducing rates of morbidity and mortality. Building on the prior work on spatial and space-time scan statistics, our methods combine time series analysis (to determine how many cases we expect to observe for a given spatial region in a given time interval) with new ""emerging cluster"" space-time scan statistics (to decide whether an observed increase in cases in a region is significant), enabling fast and accurate detection of emerging outbreaks. We evaluate these methods on two types of simulated outbreaks: aerosol …"
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",A Bayesian spatial scan statistic,"We propose a new Bayesian method for spatial cluster detection, the “Bayesian spatial scan statistic,” and compare this method to the standard (frequentist) scan statistic approach. We demonstrate that the Bayesian statistic has several advantages over the frequentist approach, including increased power to detect clusters and (since randomization testing is unnecessary) much faster runtime. We evaluate the Bayesian and fre-quentist methods on the task of prospective disease surveillance: detect-ing spatial clusters of disease cases resulting from emerging disease out-breaks. We demonstrate that our Bayesian methods are successful in rapidly detecting outbreaks while keeping number of false positives low."
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Anomaly pattern detection in categorical datasets,"We propose a new method for detecting patterns of anomalies in categorical datasets. We assume that anomalies are generated by some underlying process which affects only a particular subset of the data. Our method consists of two steps: we first use a ""local anomaly detector"" to identify individual records with anomalous attribute values, and then detect patterns where the number of anomalous records is higher than expected. Given the set of anomalies flagged by the local anomaly detector, we search over all subsets of the data defined by any set of fixed values of a subset of the attributes, in order to detect self-similar patterns of anomalies. We wish to detect any such subset of the test data which displays a significant increase in anomalous activity as compared to the normal behavior of the system (as indicated by the training data). We perform significance testing to determine if the number of anomalies in any …"
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Artificial intelligence–enabled public health surveillance—from local detection to global epidemic monitoring and control,"Artificial intelligence (AI) techniques have been widely applied to infectious disease outbreak detection and early warning, trend prediction, and public health response modeling and assessment. Such public health surveillance and response tasks of major importance pose unique technical challenges such as data sparsity, lack of positive training samples, difficulty in developing baselines and quantifying the control measures, and interwoven dependencies between spatiotemporal elements and finer-grained risk analyses through contact and social networks. Traditional public health surveillance relies heavily on statistical techniques. Recent years have seen tremendous growth of AI-enabled methods, including but not limited to deep learning–based models, complementing statistical approaches. This chapter aims to provide a systematic review of these recent advances applying AI techniques to address public …"
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Fast generalized subset scan for anomalous pattern detection,"We propose Fast Generalized Subset Scan (FGSS), a new method for detecting anomalous patterns in general categorical data sets. We frame the pattern detection problem as a search over subsets of data records and attributes, maximizing a nonparametric scan statistic over all such subsets. We prove that the nonparametric scan statistics possess a novel property that allows for efficient optimization over the exponentially many subsets of the data without an exhaustive search, enabling FGSS to scale to massive and high-dimensional data sets. We evaluate the performance of FGSS in three real-world application domains (customs monitoring, disease surveillance, and network intrusion detection), and demonstrate that FGSS can successfully detect and characterize relevant patterns in each domain. As compared to three other recently proposed detection algorithms, FGSS substantially decreased run time and improved detection power for massive multivariate data sets."
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Guggulsterone enhances head and neck cancer therapies via inhibition of signal transducer and activator of transcription-3,"Treatment of human head and neck squamous cell carcinoma (HNSCC) cell lines with guggulsterone, a widely available, well-tolerated nutraceutical, demonstrated dose-dependent decreases in cell viability with EC 50 s ranging from 5 to 8 μM. Guggulsterone induced apoptosis and cell cycle arrest, inhibited invasion and enhanced the efficacy of erlotinib, cetuximab and cisplatin in HNSCC cell lines. Guggulsterone induced decreased expression of both phosphotyrosine and total signal transducer and activator of transcription (STAT)-3, which contributed to guggulsterone's growth inhibitory effect. Hypoxia-inducible factor (HIF)-1α was also decreased in response to guggulsterone treatment. In a xenograft model of HNSCC, guggulsterone treatment resulted in increased apoptosis and decreased expression of STAT3. In vivo treatment with a guggulsterone-containing natural …"
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Fast Kronecker inference in Gaussian processes with non-Gaussian likelihoods,"Gaussian processes (GPs) are a flexible class of methods with state of the art performance on spatial statistics applications. However, GPs require O (n^ 3) computations and O (n^ 2) storage, and popular GP kernels are typically limited to smoothing and interpolation. To address these difficulties, Kronecker methods have been used to exploit structure in the GP covariance matrix for scalability, while allowing for expressive kernel learning (Wilson et al., 2014). However, fast Kronecker methods have been confined to Gaussian likelihoods. We propose new scalable Kronecker methods for Gaussian processes with non-Gaussian likelihoods, using a Laplace approximation which involves linear conjugate gradients for inference, and a lower bound on the GP marginal likelihood for kernel learning. Our approach has near linear scaling, requiring O (D n^(D+ 1)/D) operations and O (D n^ 2/D) storage, for n training data-points on a dense D> 1 dimensional grid. Moreover, we introduce a log Gaussian Cox process, with highly expressive kernels, for modelling spatiotemporal count processes, and apply it to a point pattern (n= 233,088) of a decade of crime events in Chicago. Using our model, we discover spatially varying multiscale seasonal trends and produce highly accurate long-range local area forecasts."
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Expectation-based scan statistics for monitoring spatial time series data,Description not available
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Honokiol inhibits epidermal growth factor receptor signaling and enhances the antitumor effects of epidermal growth factor receptor inhibitors,"Purpose: This study aimed to investigate the utility of honokiol, a naturally occurring compound, in the treatment of head and neck squamous cell carcinoma (HNSCC) as well as its ability to target the epidermal growth factor receptor (EGFR), a critical therapeutic target in HNSCC, and to enhance the effects of other EGFR-targeting therapies."
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Detection of spatial and spatio-temporal clusters,"This thesis develops a general and powerful statistical framework for the automatic detection of spatial and space-time clusters. Our"" generalized spatial scan"" framework is a flexible, model-based framework for accurate and computationally efficient cluster detection in diverse application domains. Through the development of the"" fast spatial scan"" algorithm and new Bayesian cluster detection methods, we can now detect clusters hundreds or thousands of times faster than previous approaches. More timely detection of emerging clusters (with high detection power and low false positive rates) was made possible by development of"" expectation-based"" scan statistics, which learn baseline models from past data then detect regions that are anomalous given these expectations. These cluster detection methods were applied to two real-world problem domains: the early detection of emerging disease epidemics, and …"
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",A multivariate Bayesian scan statistic for early event detection and characterization,"We present the multivariate Bayesian scan statistic (MBSS), a general framework for event detection and characterization in multivariate spatial time series data. MBSS integrates prior information and observations from multiple data streams in a principled Bayesian framework, computing the posterior probability of each type of event in each space-time region. MBSS learns a multivariate Gamma-Poisson model from historical data, and models the effects of each event type on each stream using expert knowledge or labeled training examples. We evaluate MBSS on various disease surveillance tasks, detecting and characterizing outbreaks injected into three streams of Pennsylvania medication sales data. We demonstrate that MBSS can be used both as a “general” event detector, with high detection power across a variety of event types, and a “specific” detector that incorporates prior knowledge of an event …"
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Identifying significant predictive bias in classifiers,Description not available
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",An empirical comparison of spatial scan statistics for outbreak detection,Description not available
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Detecting significant multidimensional spatial clusters,"Assume a uniform, multidimensional grid of bivariate data, where each cell of the grid has a count ci and a baseline bi. Our goal is to find spatial regions (d-dimensional rectangles) where the ci are significantly higher than expected given bi. We focus on two applications: detection of clusters of disease cases from epidemiological data (emergency depart-ment visits, over-the-counter drug sales), and discovery of regions of in-creased brain activity corresponding to given cognitive tasks (from fMRI data). Each of these problems can be solved using a spatial scan statistic (Kulldorff, 1997), where we compute the maximum of a likelihood ratio statistic over all spatial regions, and find the significance of this region by randomization. However, computing the scan statistic for all spatial regions is generally computationally infeasible, so we introduce a novel fast spatial scan algorithm, generalizing the 2D scan algorithm of (Neill and Moore, 2004) to arbitrary dimensions. Our new multidimensional multiresolution algorithm allows us to find spatial clusters up to 1400x faster than the naive spatial scan, without any loss of accuracy."
Daniel B. Neill,https://scholar.google.com/citations?user=zSqlq00AAAAJ,"machine learning for good, event and pattern detection, public health and safety, spatial and subset scanning, urban systems",Inhibition of EGFR-STAT3 signaling with erlotinib prevents carcinogenesis in a chemically-induced mouse model of oral squamous cell carcinoma,"Chemoprevention of head and neck squamous cell carcinoma (HNSCC), a disease associated with high mortality rates and frequent occurrence of second primary tumor (SPT), is an important clinical goal. The epidermal growth factor receptor (EGFR)-signal transducer and activator of transcription (STAT)-3 signaling pathway is known to play a key role in HNSCC growth, survival, and prognosis, thereby serving as a potential therapeutic target in the treatment of HNSCC. In the current study, the 4-nitroquinoline-1-oxide (4-NQO)–induced murine model of oral carcinogenesis was utilized to investigate the chemopreventive activities of compounds that target the EGFR-STAT3 signaling pathway. This model mimics the process of oral carcinogenesis in humans. The drugs under investigation included erlotinib, a small molecule inhibitor of the EGFR, and guggulipid, the extract of an Ayurvedic medicinal plant, which …"
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security","A primer on hardware security: Models, methods, and metrics",Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Trustworthy hardware: Identifying and classifying hardware trojans,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Security analysis of logic obfuscation,"Due to globalization of Integrated Circuit (IC) design flow, rogue elements in the supply chain can pirate ICs, overbuild ICs, and insert hardware trojans. EPIC [1] obfuscates the design by randomly inserting additional gates; only a correct key makes the design to produce correct outputs. We demonstrate that an attacker can decipher the obfuscated netlist, in a time linear to the number of keys, by sensitizing the key values to the output. We then develop techniques to fix this vulnerability and make obfuscation truly exponential in the number of inserted keys."
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Hardware trojans: Lessons learned after one decade of research,"Given the increasing complexity of modern electronics and the cost of fabrication, entities from around the globe have become more heavily involved in all phases of the electronics supply chain. In this environment, hardware Trojans (i.e., malicious modifications or inclusions made by untrusted third parties) pose major security concerns, especially for those integrated circuits (ICs) and systems used in critical applications and cyber infrastructure. While hardware Trojans have been explored significantly in academia over the last decade, there remains room for improvement. In this article, we examine the research on hardware Trojans from the last decade and attempt to capture the lessons learned. A comprehensive adversarial model taxonomy is introduced and used to examine the current state of the art. Then the past countermeasures and publication trends are categorized based on the adversarial model and …"
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Fault analysis-based logic encryption,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Security analysis of integrated circuit camouflaging,"Camouflaging is a layout-level technique that hampers an attacker from reverse engineering by introducing, in one embodiment, dummy contacts into the layout. By using a mix of real and dummy contacts, one can camouflage a standard cell whose functionality can be one of many. If an attacker cannot resolve the functionality of a camouflaged gate, he/she will extract an incorrect netlist. In this paper, we analyze the feasibility of identifying the functionality of camouflaged gates. We also propose techniques to make the dummy contact-based IC camouflaging technique resilient to reverse engineering. Furthermore, we judiciously select gates to camouflage by using techniques which ensure that the outputs of the extracted netlist are controllably corrupted. The techniques leverage IC testing principles such as justification and sensitization. The proposed techniques are evaluated using ISCAS benchmark circuits and …"
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Scan based side channel attack on dedicated hardware implementations of data encryption standard,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",The cybersecurity landscape in industrial control systems,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",On improving the security of logic locking,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Secure scan: A design-for-test architecture for crypto chips,"Scan-based Design-for-Test (DFT) is a powerful testing scheme, but it can be used to retrieve the secrets stored in a crypto chip thus compromising its security. On one hand, sacrificing security for testability by using traditional scan-based DFT restricts its use in privacy sensitive applications. On the other hand, sacrificing testability for security by abandoning scan-based DFT hurts product quality. The security of a crypto chip comes from the small secret key stored in a few registers and the testability of a crypto chip comes from the data path and control path implementing the crypto algorithm. Based on this key observation, we propose a novel scan DFT architecture called secure scan that maintains the high test quality of traditional scan DFT without compromising the security. We used a hardware implementation of the Advanced Encryption Standard (AES) to show that the traditional Scan DFT scheme can …"
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Asleep at the keyboard? assessing the security of github copilot’s code contributions,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",On design vulnerability analysis and trust benchmarks development,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Manufacturing and security challenges in 3D printing,"As the manufacturing time, quality, and cost associated with additive manufacturing (AM) continue to improve, more and more businesses and consumers are adopting this technology. Some of the key benefits of AM include customizing products, localizing production and reducing logistics. Due to these and numerous other benefits, AM is enabling a globally distributed manufacturing process and supply chain spanning multiple parties, and hence raises concerns about the reliability of the manufactured product. In this work, we first present a brief overview of the potential risks that exist in the cyber-physical environment of additive manufacturing. We then evaluate the risks posed by two different classes of modifications to the AM process which are representative of the challenges that are unique to AM. The risks posed are examined through mechanical testing of objects with altered printing orientation and fine …"
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",The robust QCA adder designs using composable QCA building blocks,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Is split manufacturing secure?,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Examining zero-shot vulnerability repair with large language models,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Concurrent error detection schemes for fault-based side-channel cryptanalysis of symmetric block ciphers,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Attacks and defenses for JTAG,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Logic encryption: A fault analysis perspective,Description not available
Ramesh Karri కర్రి రమేష్,https://scholar.google.com/citations?user=o60TaTEAAAAJ&hl=en,"Hardware Security and Trust, Embedded Security, CPS Security, Additive Manufacturing Security",Hardware security: Threat models and metrics,Description not available
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Tracking ransomware end-to-end,Description not available
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",IoT inspector: Crowdsourcing labeled network traffic from smart home devices at scale,"The proliferation of smart home devices has created new opportunities for empirical research in ubiquitous computing, ranging from security and privacy to personal health. Yet, data from smart home deployments are hard to come by, and existing empirical studies of smart home devices typically involve only a small number of devices in lab settings. To contribute to data-driven smart home research, we crowdsource the largest known dataset of labeled network traffic from smart home devices from within real-world home networks. To do so, we developed and released IoT Inspector, an open-source tool that allows users to observe the traffic from smart home devices on their own home networks. Between April 10, 2019 and January 21, 2020, 5,404 users have installed IoT Inspector, allowing us to collect labeled network traffic from 54,094 smart home devices. At the time of publication, IoT Inspector is still gaining …"
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Keeping the smart home private with smart (er) iot traffic shaping,Description not available
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",High-fidelity switch models for software-defined network emulation,"Software defined networks (SDNs) depart from traditional network architectures by explicitly allowing third-party software access to the network's control plane. Thus, SDN protocols such as OpenFlow give network operators the ability to innovate by authoring or buying network controller software independent of the hardware. However, this split design can make planning and designing large SDNs even more challenging than traditional networks. While existing network emulators allow operators to ascertain the behavior of traditional networks when subjected to a given workload, we find that current approaches fail to account for significant vendor-specific artifacts in the SDN switch control path. We benchmark OpenFlow-enabled switches from three vendors and illustrate how differences in their implementation dramatically impact latency and throughput. We present a measurement methodology and emulator …"
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Framing dependencies introduced by underground commoditization,"Internet crime has become increasingly dependent on the underground economy: a loose federation of specialists selling capabilities, services, and resources explicitly tailored to the abuse ecosystem. Through these emerging markets, modern criminal entrepreneurs piece together dozens of à la carte components into entirely new criminal endeavors. From an abuse fighting perspective, criminal reliance on this black market introduces fragile dependencies that, if disrupted, undermine entire operations that as a composite appear intractable to protect against. However, without a clear framework for examining the costs and infrastructure behind Internet crime, it becomes impossible to evaluate the effectiveness of novel intervention strategies."
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Botcoin: Monetizing Stolen Cycles,"At the current stratospheric value of Bitcoin, miners with access to significant computational horsepower are literally printing money. For example, the first operator of a USD $1,500 custom ASIC mining platform claims to have recouped his investment in less than three weeks in early February 2013, and the value of a bitcoin has more than tripled since then. Not surprisingly, cybercriminals have also been drawn to this potentially lucrative endeavor, but instead are leveraging the resources available to them: stolen CPU hours in the form of botnets. We conduct the first comprehensive study of Bitcoin mining malware, and describe the infrastructure and mechanism deployed by several major players. By carefully reconstructing the Bitcoin transaction records, we are able to deduce the amount of money a number of mining botnets have made."
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Watching you watch: The tracking ecosystem of over-the-top tv streaming devices,"The number of Internet-connected TV devices has grown significantly in recent years, especially Over-the-Top (""OTT"") streaming devices, such as Roku TV and Amazon Fire TV. OTT devices offer an alternative to multi-channel television subscription services, and are often monetized through behavioral advertising. To shed light on the privacy practices of such platforms, we developed a system that can automatically download OTT apps (also known as channels), and interact with them while intercepting the network traffic and performing best-effort TLS interception. We used this smart crawler to visit more than 2,000 channels on two popular OTT platforms, namely Roku and Amazon Fire TV. Our results show that tracking is pervasive on both OTT platforms, with traffic to known trackers present on 69% of Roku channels and 89% of Amazon Fire TV channels. We also discover widespread practice of collecting and …"
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Backpage and bitcoin: Uncovering human traffickers,"Sites for online classified ads selling sex are widely used by human traffickers to support their pernicious business. The sheer quantity of ads makes manual exploration and analysis unscalable. In addition, discerning whether an ad is advertising a trafficked victim or an independent sex worker is a very difficult task. Very little concrete ground truth (i.e., ads definitively known to be posted by a trafficker) exists in this space. In this work, we develop tools and techniques that can be used separately and in conjunction to group sex ads by their true owner (and not the claimed author in the ad). Specifically, we develop a machine learning classifier that uses stylometry to distinguish between ads posted by the same vs. different authors with 90% TPR and 1% FPR. We also design a linking technique that takes advantage of leakages from the Bitcoin mempool, blockchain and sex ad site, to link a subset of sex ads to Bitcoin …"
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Stressing out: Bitcoin “stress testing”,"In this paper, we present an empirical study of a recent spam campaign (a “stress test”) that resulted in a DoS attack on Bitcoin. The goal of our investigation being to understand the methods spammers used and impact on Bitcoin users. To this end, we used a clustering based method to detect spam transactions. We then validate the clustering results and generate a conservative estimate that 385,256 (23.41 %) out of 1,645,667 total transactions were spam during the 10 day period at the peak of the campaign. We show the impact of increasing non-spam transaction fees from 45 to 68 Satoshis/byte (from $0.11 to $0.17 USD per kilobyte of transaction) on average, and increasing delays in processing non-spam transactions from 0.33 to 2.67 h on average, as well as estimate the cost of this spam attack at 201 BTC (or $49,000 USD). We conclude by pointing out changes that could be made to Bitcoin …"
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Web-based attacks to discover and control local IoT devices,"In this paper, we present two web-based attacks against local IoT devices that any malicious web page or third-party script can perform, even when the devices are behind NATs. In our attack scenario, a victim visits the attacker's website, which contains a malicious script that communicates with IoT devices on the local network that have open HTTP servers. We show how the malicious script can circumvent the same-origin policy by exploiting error messages on the HTML5 MediaError interface or by carrying out DNS rebinding attacks. We demonstrate that the attacker can gather sensitive information from the devices (e.g., unique device identifiers and precise geolocation), track and profile the owners to serve ads, or control the devices by playing arbitrary videos and rebooting. We propose potential countermeasures to our attacks that users, browsers, DNS providers, and IoT vendors can implement."
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",“It would probably turn into a social faux-pas”: Users’ and Bystanders’ Preferences of Privacy Awareness Mechanisms in Smart Homes,"The opaque data practices in smart home devices have raised significant privacy concerns for smart home users and bystanders. One way to learn about the data practices is through privacy-related notifications. However, how to deliver these notifications to users and bystanders and increase their awareness of data practices is not clear. We surveyed 136 users and 123 bystanders to understand their preferences of receiving privacy-related notifications in smart homes. We further collected their responses to four mechanisms that improve privacy awareness (e.g., Data Dashboard) as well as their selections of mechanisms in four different scenarios (e.g., friend visiting). Our results showed the pros and cons of each privacy awareness mechanism, e.g., Data Dashboard can help reduce bystanders’ dependence on users. We also found some unique benefits of each mechanism (e.g., Ambient Light could provide …"
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health","Alexa, who am I speaking to?: Understanding users’ ability to identify third-party apps on Amazon Alexa","Many Internet of Things devices have voice user interfaces. One of the most popular voice user interfaces is Amazon’s Alexa, which supports more than 50,000 third-party applications (“skills”). We study how Alexa’s integration of these skills may confuse users. Our survey of 237 participants found that users do not understand that skills are often operated by third parties, that they often confuse third-party skills with native Alexa functions, and that they are unaware of the functions that the native Alexa system supports. Surprisingly, users who interact with Alexa more frequently are more likely to conclude that a third-party skill is a native Alexa function. The potential for misunderstanding creates new security and privacy risks: attackers can develop third-party skills that operate without users’ knowledge or masquerade as native Alexa functions. To mitigate this threat, we make design recommendations to help users …"
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Skillbot: Identifying risky content for children in alexa skills,"Many households include children who use voice personal assistants (VPA) such as Amazon Alexa. Children benefit from the rich functionalities of VPAs and third-party apps but are also exposed to new risks in the VPA ecosystem. In this article, we first investigate “risky” child-directed voice apps that contain inappropriate content or ask for personal information through voice interactions. We build SkillBot—a natural language processing-based system to automatically interact with VPA apps and analyze the resulting conversations. We find 28 risky child-directed apps and maintain a growing dataset of 31,966 non-overlapping app behaviors collected from 3,434 Alexa apps. Our findings suggest that although child-directed VPA apps are subject to stricter policy requirements and more intensive vetting, children remain vulnerable to inappropriate content and privacy violations. We then conduct a user study showing …"
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Managing distributed applications using gush,"Deploying and controlling experiments running on a distributed set of resources is a challenging task. Software developers often spend a significant amount of time dealing with the complexities associated with resource configuration and management in these environments. Experiment control systems are designed to automate the process, and to ultimately help developers cope with the common problems that arise during the design, implementation, and evaluation of distributed systems. However, many of the existing control systems were designed with specific computing environments in mind, and thus do not provide support for heterogeneous resources in different testbeds. In this paper, we explore the functionality of Gush, an experiment control system, and discuss how it supports execution on three of the four GENI control frameworks."
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Pinning down abuse on google maps,"In this paper, we investigate a new form of blackhat search engine optimization that targets local listing services like Google Maps. Miscreants register abusive business listings in an attempt to siphon search traffic away from legitimate businesses and funnel it to deceptive service industries---such as unaccredited locksmiths---or to traffic-referral scams, often for the restaurant and hotel industry. In order to understand the prevalence and scope of this threat, we obtain access to over a hundred-thousand business listings on Google Maps that were suspended for abuse. We categorize the types of abuse affecting Google Maps; analyze how miscreants circumvented the protections against fraudulent business registration such as postcard mail verification; identify the volume of search queries affected; and ultimately explore how miscreants generated a profit from traffic that necessitates physical proximity to the victim …"
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Abuse Vectors: A Framework for Conceptualizing {IoT-Enabled} Interpersonal Abuse,"Tech-enabled interpersonal abuse (IPA) is a pervasive problem. Abusers, often intimate partners, use tools such as spyware to surveil and harass victim-survivors. Unfortunately, anecdotal evidence suggests that smart, Internet-connected devices such as home thermostats, cameras, and Bluetooth item finders may similarly be used against victim-survivors of IPA. To tackle abuse involving smart devices, it is vital that we understand the ecosystem of smart devices that enable IPA. Thus, in this work, we conduct a large-scale qualitative analysis of the smart devices used in IPA. We systematically crawl Google Search results to uncover web pages discussing how abusers use smart devices to enact IPA. By analyzing these web pages, we identify 32 devices used for IPA and detail the varied strategies abusers use for spying and harassment via these devices. Then, we design a simple, yet powerful framework—abuse vectors—which conceptualizes IoT-enabled IPA as four overarching patterns: Covert Spying, Unauthorized Access, Repurposing, and Intended Use. Using this lens, we pinpoint the necessary solutions required to address each vector of IoT abuse and encourage the security community to take action."
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Profit-driven abuses of virtual currencies,"This paper traces the rise of virtual currencies and surveys their more popular incarnations, such Liberty Reserve and Bitcoin. Using cash and conventional electronic payment networks (eg Visa and PayPal) as a reference point, we delineate the evolution of financial abuses in the face of virtual currencies. In particular, we describe the properties of virtual currencies that make them susceptible to abuses. We also discuss how criminals can exploit virtual currencies for profit, and how these malicious activities can be countered. We find that the very benefits which have made virtual currencies popular are also facilitating crimes."
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Estimating Profitability of Alternative Crypto-currencies,Description not available
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",Exploring tenants' preferences of privacy negotiation in airbnb,"Literature suggests the unmatched or conflicting privacy needs between users and bystanders in smart homes due to their different privacy concerns and priorities. A promising approach to mitigate such conflicts is through negotiation. Yet, it is not clear whether bystanders have privacy negotiation needs and if so, what factors may influence their negotiation intention and how to better support the negotiation to achieve their privacy goals. To answer these questions, we conducted a vignette study that varied across three categorical factors, including device types, device location, and duration of stay with 867 participants in the context of Airbnb. We further examined our participants' preferences regarding with whom, when, how, and why they would like to negotiate their privacy. Our findings showed that device type remained the only factor that significantly influenced our participants' negotiation intention. Additionally, we found our participants' other preferences, such as they preferred to contact Airbnb hosts first to convey their privacy needs through asynchronous channels (eg, messages and emails). We summarized design implications to fulfill tenants' privacy negotiation needs."
Danny Yuxing Huang,https://scholar.google.com/citations?user=B-Zb3joAAAAJ&hl=en,"IoT, security, privacy, health",In the room where it happens: Characterizing local communication and threats in smart homes,"The network communication between Internet of Things (IoT) devices on the same local network has significant implications for platform and device interoperability, security, privacy, and correctness. Yet, the analysis of local home Wi-Fi network traffic and its associated security and privacy threats have been largely ignored by prior literature, which typically focuses on studying the communication between IoT devices and cloud end-points, or detecting vulnerable IoT devices exposed to the Internet. In this paper, we present a comprehensive and empirical measurement study to shed light on the local communication within a smart home deployment and its threats. We use a unique combination of passive network traffic captures, protocol honeypots, dynamic mobile app analysis, and crowdsourced IoT data from participants to identify and analyze a wide range of device activities on the local network. We then analyze …"
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Badnets: Identifying vulnerabilities in the machine learning model supply chain,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Fine-pruning: Defending against backdooring attacks on deep neural networks,"Deep neural networks (DNNs) provide excellent performance across a wide range of classification tasks, but their training requires high computational resources and is often outsourced to third parties. Recent work has shown that outsourced training introduces the risk that a malicious trainer will return a backdoored DNN that behaves normally on most inputs but causes targeted misclassifications or degrades the accuracy of the network when a trigger known only to the attacker is present. In this paper, we provide the first effective defenses against backdoor attacks on DNNs. We implement three backdoor attacks from prior work and use them to investigate two promising defenses, pruning and fine-tuning. We show that neither, by itself, is sufficient to defend against sophisticated attackers. We then evaluate fine-pruning, a combination of pruning and fine-tuning, and show that it successfully weakens or even …"
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Badnets: Evaluating backdooring attacks on deep neural networks,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Securing computer hardware using 3d integrated circuit ({IC}) technology and split manufacturing for obfuscation,"The fabrication of digital Integrated Circuits (ICs) is increasingly outsourced. Given this trend, security is recognized as an important issue. The threat agent is an attacker at the IC foundry that has information about the circuit and inserts covert, malicious circuitry. The use of 3D IC technology has been suggested as a possible technique to counter this threat. However, to our knowledge, there is no prior work on how such technology can be used effectively. We propose a way to use 3D IC technology for security in this context. Specifically, we obfuscate the circuit by lifting wires to a trusted tier, which is fabricated separately. This is referred to as split manufacturing. For this setting, we provide a precise notion of security, that we call k-security, and a characterization of the underlying computational problems and their complexity. We further propose a concrete approach for identifying sets of wires to be lifted, and the corresponding security they provide. We conclude with a comprehensive empirical assessment with benchmark circuits that highlights the security versus cost trade-offs introduced by 3D IC based circuit obfuscation."
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware","The EDA challenges in the dark silicon era: Temperature, reliability, and variability perspectives","Technology scaling has resulted in smaller and faster transistors in successive technology generations. However, transistor power consumption no longer scales commensurately with integration density and, consequently, it is projected that in future technology nodes it will only be possible to simultaneously power on a fraction of cores on a multi-core chip in order to stay within the power budget. The part of the chip that is powered off is referred to as dark silicon and brings new challenges as well as opportunities for the design community, particularly in the context of the interaction of dark silicon with thermal, reliability and variability concerns. In this perspectives paper we describe these new challenges and opportunities, and provide preliminary experimental evidence in their support."
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Integrated circuit (IC) decamouflaging: Reverse engineering camouflaged ICs within minutes.,"Circuit camouflaging is a recently proposed defense mechanism to protect digital integrated circuits (ICs) from reverse engineering attacks by using camouflaged gates, ie, logic gates whose functionality cannot be precisely determined by the attacker. Recent work appears to establish that an attacker requires time that is exponential in the number of camouflaged gates to reverse engineer a circuit, if the gates that are camouflaged are chosen using a procedure proposed in that work. Consequently, it appears to be the case that even by camouflaging a relatively small number of gates in the circuit, the attacker is forced to undertake several thousands of years of work. In this paper, we refute such claims. With an underlying complexity-theoretic mindset, we show that the same benchmark circuits with the camouflaged gates chosen the same way as prior work, we can decamouflage the circuit in minutes, and not years. As part of constructing our attack, we provide a precise characterization of two problems that the attacker seeks to solve to carry out his attack, and their computational complexity. A composition of solvers for the two problems is our attack procedure. We show that the two problems are co-NP-complete and NP-complete respectively, and our reduction to boolean satisfiability (SAT) and the use of off-the-shelf SAT solvers results in a highly effective attack. We also propose a new notion that we call a discriminating set of input patterns, that soundly captures the attacker’s difficulty. Our extensive empirical studies reveal that the discriminating sets of inputs for realistic circuits are surprising small, thereby providing an explanation for the …"
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Safetynets: Verifiable execution of deep neural networks on an untrusted cloud,"Inference using deep neural networks is often outsourced to the cloud since it is a computationally demanding task. However, this raises a fundamental issue of trust. How can a client be sure that the cloud has performed inference correctly? A lazy cloud provider might use a simpler but less accurate model to reduce its own computational load, or worse, maliciously modify the inference results sent to the client. We propose SafetyNets, a framework that enables an untrusted server (the cloud) to provide a client with a short mathematical proof of the correctness of inference tasks that they perform on behalf of the client. Specifically, SafetyNets develops and implements a specialized interactive proof (IP) protocol for verifiable execution of a class of deep neural networks, ie, those that can be represented as arithmetic circuits. Our empirical results on three-and four-layer deep neural networks demonstrate the run-time costs of SafetyNets for both the client and server are low. SafetyNets detects any incorrect computations of the neural network by the untrusted server with high probability, while achieving state-of-the-art accuracy on the MNIST digit recognition (99.4%) and TIMIT speech recognition tasks (75.22%)."
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Thundervolt: enabling aggressive voltage underscaling and timing error resilience for energy efficient deep learning accelerators,"Hardware accelerators are being increasingly deployed to boost the performance and energy efficiency of deep neural network (DNN) inference. In this paper we propose Thundervolt, a new framework that enables aggressive voltage underscaling of high-performance DNN accelerators without compromising classification accuracy even in the presence of high timing error rates. Using post-synthesis timing simulations of a DNN accelerator modeled on the Google TPU, we show that Thundervolt enables between 34%-57% energy savings on state-of-the-art speech and image recognition benchmarks with less than 1% loss in classification accuracy and no performance loss. Further, we show that Thundervolt is synergistic with and can further increase the energy efficiency of commonly used run-time DNN pruning techniques like Zero-Skip."
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Analyzing and mitigating the impact of permanent faults on a systolic array based neural network accelerator,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Benchmarking large language models for automated verilog rtl code generation,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Cherry-picking: Exploiting process variations in dark-silicon homogeneous chip multi-processors,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Lost at c: A user study on the security implications of large language model code assistants,"Large Language Models (LLMs) such as OpenAI Codex are increasingly being used as AI-based coding assistants. Understanding the impact of these tools on developers’ code is paramount, especially as recent work showed that LLMs may suggest cybersecurity vulnerabilities. We conduct a security-driven user study (N= 58) to assess code written by student programmers when assisted by LLMs. Given the potential severity of low-level bugs as well as their relative frequency in real-world projects, we tasked participants with implementing a singly-linked ‘shopping list’structure in C. Our results indicate that the security impact in this setting (low-level C with pointer and array manipulations) is small: AI-assisted users produce critical security bugs at a rate no greater than 10% more than the control, indicating the use of LLMs does not introduce new security risks."
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Reverse engineering camouflaged sequential circuits without scan access,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Securing hardware accelerators: A new challenge for high-level synthesis,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Chip-chat: Challenges and opportunities in conversational hardware design,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Deepreduce: Relu reduction for fast private inference,"The recent rise of privacy concerns has led researchers to devise methods for private neural inference—where inferences are made directly on encrypted data, never seeing inputs. The primary challenge facing private inference is that computing on encrypted data levies an impractically-high latency penalty, stemming mostly from non-linear operators like ReLU. Enabling practical and private inference requires new optimization methods that minimize network ReLU counts while preserving accuracy. This paper proposes DeepReDuce: a set of optimizations for the judicious removal of ReLUs to reduce private inference latency. The key insight is that not all ReLUs contribute equally to accuracy. We leverage this insight to drop, or remove, ReLUs from classic networks to significantly reduce inference latency and maintain high accuracy. Given a network architecture, DeepReDuce outputs a Pareto frontier of networks that tradeoff the number of ReLUs and accuracy. Compared to the state-of-the-art for private inference DeepReDuce improves accuracy and reduces ReLU count by up to 3.5%(iso-ReLU count) and 3.5 x (iso-accuracy), respectively."
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Verifiable asics,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Cryptonas: Private inference on a relu budget,"Machine learning as a service has given raise to privacy concerns surrounding clients' data and providers' models and has catalyzed research in private inference (PI): methods to process inferences without disclosing inputs. Recently, researchers have adapted cryptographic techniques to show PI is possible, however all solutions increase inference latency beyond practical limits. This paper makes the observation that existing models are ill-suited for PI and proposes a novel NAS method, named CryptoNAS, for finding and tailoring models to the needs of PI. The key insight is that in PI operator latency cost are inverted: non-linear operations (eg, ReLU) dominate latency, while linear layers become effectively free. We develop the idea of a ReLU budget as a proxy for inference latency and use CryptoNAS to build models that maximize accuracy within a given budget. CryptoNAS improves accuracy by 3.4% and latency by 2.4 x over the state-of-the-art."
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",Fault-tolerant systolic array based accelerators for deep neural network execution,Description not available
Siddharth Garg,https://scholar.google.com/citations?user=Yf8OqQQAAAAJ&hl=en&oi=ao,"ML, computer security, computer hardware",HaDeS: architectural synthesis for heterogeneous dark silicon chip multi-processors,"In this paper, we propose an efficient iterative optimization based approach for architectural synthesis of dark silicon heterogeneous chip multi-processors (CMPs). The goal is to determine the optimal number of cores of each type to provision the CMP with, such that the area and power budgets are met and the application performance is maximized. We consider general-purpose multi-threaded applications with a varying degree of parallelism (DOP) that can be set at run-time, and propose an accurate analytical model to predict the execution time of such applications on heterogeneous CMPs. Our experimental results illustrate that the synthesized heterogeneous dark silicon CMPs provide between 19% to 60% performance improvements over conventional homogeneous designs for variable and fixed DOP scenarios, respectively."
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",FoldingNet: Point cloud auto-encoder via deep grid deformation,"Recent deep networks that directly handle points in a point set, eg, PointNet, have been state-of-the-art for supervised learning tasks on point clouds such as classification and segmentation. In this work, a novel end-to-end deep auto-encoder is proposed to address unsupervised learning challenges on point clouds. On the encoder side, a graph-based enhancement is enforced to promote local structures on top of PointNet. Then, a novel folding-based decoder deforms a canonical 2D grid onto the underlying 3D object surface of a point cloud, achieving low reconstruction errors even for objects with delicate structures. The proposed decoder only uses about 7% parameters of a decoder with fully-connected neural networks, yet leads to a more discriminative representation that achieves higher linear SVM classification accuracy than the benchmark. In addition, the proposed decoder structure is shown, in theory, to be a generic architecture that is able to reconstruct an arbitrary point cloud from a 2D grid. Our code is available at http://www. merl. com/research/license# FoldingNet"
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Mining Point Cloud Local Structures by Kernel Correlation and Graph Pooling,"Unlike on images, semantic learning on 3D point clouds using a deep network is challenging due to the naturally unordered data structure. Among existing works, PointNet has achieved promising results by directly learning on point sets. However, it does not take full advantage of a point's local neighborhood that contains fine-grained structural information which turns out to be helpful towards better semantic learning. In this regard, we present two new operations to improve PointNet with a more efficient exploitation of local structures. The first one focuses on local 3D geometric structures. In analogy to a convolution kernel for images, we define a point-set kernel as a set of learnable 3D points that jointly respond to a set of neighboring data points according to their geometric affinities measured by kernel correlation, adapted from a similar technique for point cloud registration. The second one exploits local high-dimensional feature structures by recursive feature aggregation on a nearest-neighbor-graph computed from 3D positions. Experiments show that our network can efficiently capture local information and robustly achieve better performances on major datasets. Our code is available at http://www. merl. com/research/license# KCNet"
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Geometric distortion metrics for point cloud compression,Description not available
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",CASENet: Deep Category-Aware Semantic Edge Detection,"Boundary and edge cues are highly beneficial in improving a wide variety of vision tasks such as semantic segmentation, object recognition, stereo, and object proposal generation. Recently, the problem of edge detection has been revisited and significant progress has been made with deep learning. While classical edge detection is a challenging binary problem in itself, the category-aware semantic edge detection by nature is an even more challenging multi-label problem. We model the problem such that each edge pixel can be associated with more than one class as they appear in contours or junctions belonging to two or more semantic classes. To this end, we propose a novel end-to-end deep semantic edge learning architecture based on ResNet and a new skip-layer architecture where category-wise edge activations at the top convolution layer share and are fused with the same set of bottom layer features. We then propose a multi-label loss function to supervise the fused activations. We show that our proposed architecture benefits this problem with better performance, and we outperform the current state-of-the-art semantic edge detection methods by a large margin on standard data sets such as SBD and Cityscapes."
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Point-Plane SLAM for Hand-Held 3D Sensors,Description not available
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Fast plane extraction in organized point clouds using agglomerative hierarchical clustering,Description not available
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Fast resampling of three-dimensional point clouds via graphs,Description not available
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality","3D Point Cloud Processing and Learning for Autonomous Driving: Impacting Map Creation, Localization, and Perception",Description not available
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",V2X-Sim: Multi-Agent Collaborative Perception Dataset and Benchmark for Autonomous Driving,Description not available
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Deep Active Learning for Civil Infrastructure Defect Detection and Classification,"Automatic detection and classification of defects in infrastructure surface images can largely boost its maintenance efficiency. Given enough labeled images, various supervised learning methods have been investigated for this task, including decision trees and support vector machines in previous studies, and deep neural networks more recently. However, in real world applications, labels are harder to obtain than images, due to the limited labeling resources (i.e., experts). Thus we propose a deep active learning system to maximize the performance. A deep residual network is firstly designed for defect detection and classification in an image. Following our active learning strategy, this network is trained as soon as an initial batch of labeled images becomes available. It is then used to select a most informative subset of new images and query labels from experts to retrain the network. Experiments demonstrate more …"
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Learning distilled collaboration graph for multi-agent perception,"To promote better performance-bandwidth trade-off for multi-agent perception, we propose a novel distilled collaboration graph (DiscoGraph) to model trainable, pose-aware, and adaptive collaboration among agents. Our key novelties lie in two aspects. First, we propose a teacher-student framework to train DiscoGraph via knowledge distillation. The teacher model employs an early collaboration with holistic-view inputs; the student model is based on intermediate collaboration with single-view inputs. Our framework trains DiscoGraph by constraining post-collaboration feature maps in the student model to match the correspondences in the teacher model. Second, we propose a matrix-valued edge weight in DiscoGraph. In such a matrix, each element reflects the inter-agent attention at a specific spatial region, allowing an agent to adaptively highlight the informative regions. During inference, we only need to use the student model named as the distilled collaboration network (DiscoNet). Attributed to the teacher-student framework, multiple agents with the shared DiscoNet could collaboratively approach the performance of a hypothetical teacher model with a holistic view. Our approach is validated on V2X-Sim 1.0, a large-scale multi-agent perception dataset that we synthesized using CARLA and SUMO co-simulation. Our quantitative and qualitative experiments in multi-agent 3D object detection show that DiscoNet could not only achieve a better performance-bandwidth trade-off than the state-of-the-art collaborative perception methods, but also bring more straightforward design rationale. Our code is available on https://github. com/ai4ce/DiscoNet."
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality","LUVLi Face Alignment: Estimating Landmarks' Location, Uncertainty, and Visibility Likelihood","Modern face alignment methods have become quite accurate at predicting the locations of facial landmarks, but they do not typically estimate the uncertainty of their predicted locations nor predict whether landmarks are visible. In this paper, we present a novel framework for jointly predicting landmark locations, associated uncertainties of these predicted locations, and landmark visibilities. We model these as mixed random variables and estimate them using a deep network trained using our proposed Location, Uncertainty, and Visibility Likelihood (LUVLi) loss. In addition, we release an entirely new labeling of a large face alignment dataset with over 19,000 face images in a full range of head poses. Each face is manually labeled with the ground-truth locations of 68 landmarks, with the additional information of whether each landmarks is visible, self-occluded (due to extreme head poses), or externally occluded. Not only does our joint estimation yield accurate estimates of the uncertainty of predicted landmark locations, but it also yields state-of-the-art estimates for the landmark locations themselves on mulitple standard face alignment datasets. Our method's estimates of the uncertainty of predicted landmark locations could be used to automatically identify input images on which face alignment fails, which can be critical for downstream tasks."
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Vision guided autonomous robotic assembly and as-built scanning on unstructured construction sites,"Unlike robotics in the manufacturing industry, on-site construction robotics has to consider and address two unique challenges: 1) the rugged, evolving, and unstructured environment of typical work sites; and 2) the reversed spatial relationship between the product and the manipulator, i.e., the manipulator has to travel to and localize itself at the work face, rather than a partially complete product arriving at an anchored manipulator. The presented research designed and implemented algorithms that address these challenges and enable autonomous robotic assembly of freeform modular structures on construction sites. Building on the authors' previous work in computer-vision-based pose estimation, the designed algorithms enable a mobile robotic manipulator to: 1) autonomously identify and grasp prismatic building components (e.g., bricks, blocks) that are typically non-unique and arbitrarily stored on-site; and 2 …"
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Voxformer: Sparse voxel transformer for camera-based 3d semantic scene completion,"Humans can easily imagine the complete 3D geometry of occluded objects and scenes. This appealing ability is vital for recognition and understanding. To enable such capability in AI systems, we propose VoxFormer, a Transformer-based semantic scene completion framework that can output complete 3D volumetric semantics from only 2D images. Our framework adopts a two-stage design where we start from a sparse set of visible and occupied voxel queries from depth estimation, followed by a densification stage that generates dense 3D voxels from the sparse ones. A key idea of this design is that the visual features on 2D images correspond only to the visible scene structures rather than the occluded or empty spaces. Therefore, starting with the featurization and prediction of the visible structures is more reliable. Once we obtain the set of sparse queries, we apply a masked autoencoder design to propagate the information to all the voxels by self-attention. Experiments on SemanticKITTI show that VoxFormer outperforms the state of the art with a relative improvement of 20.0% in geometry and 18.1% in semantics and reduces GPU memory during training to less than 16GB. Our code is available on https://github. com/NVlabs/VoxFormer."
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Collaborative visualization of engineering processes using tabletop augmented reality,Description not available
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Method for extracting planes from 3D point cloud sensor data,"(74) Attorney, Agent, or Firm—Gene Vinokur, Hironori Tsukamoto; James McAleenan (57) ABSTRACT A method extracts planes from three-dimensional (3D) points by first partitioning the 3D points into disjoint regions. A graph of nodes and edges is then constructed, wherein the nodes represent the regions and the edges represent neighbor hood relationships of the regions. Finally, agglomerative hier archical clustering is applied to the graph to merge regions belonging to the same plane."
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Simultaneous Edge Alignment and Learning,"Edge detection is among the most fundamental vision problems for its role in perceptual grouping and its wide applications. Recent advances in representation learning have led to considerable improvements in this area. Many state of the art edge detection models are learned with fully convolutional networks (FCNs). However, FCN-based edge learning tends to be vulnerable to misaligned labels due to the delicate structure of edges. While such problem was considered in evaluation benchmarks, similar issue has not been explicitly addressed in general edge learning. In this paper, we show that label misalignment can cause considerably degraded edge learning quality, and address this issue by proposing a simultaneous edge alignment and learning framework. To this end, we formulate a probabilistic model where edge alignment is treated as latent variable optimization, and is learned end-to-end during network training. Experiments show several applications of this work, including improved edge detection with state of the art performance, and automatic refinement of noisy annotations."
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",An Occupancy Grid Mapping enhanced visual SLAM for real-time locating applications in indoor GPS-denied environments,"Current Real-Time Locating Systems (RTLS) typically deployed in indoor built environments are generally based on wireless technologies, fixed cameras, or Lidar-based Simultaneous Localization and Mapping (SLAM), which generally suffer from the drawbacks of low accuracy, reliance on existing infrastructures that may be not available in the deployed environments, labor-intensive environment instrumentation, or economic infeasibility for wide deployment. By improving an ORB RGB-D SLAM with Occupancy Grid Mapping, this paper proposes a new indoor RTLS that can be readily adapted and deployed for a broad range of indoor locating applications while overcoming the limitations faced by current solutions. In addition to the sparse feature map that is maintained by ORB SLAM itself, a new 2D mapping module is developed to build and maintain an additional 2D Occupancy Grid Map (OGM). The 2D OGM is …"
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",Deep unsupervised learning of 3D point clouds via graph topology inference and filtering,Description not available
Chen Feng (冯晨),https://scholar.google.com/citations?user=YeG8ZM0AAAAJ&hl=en,"Computer Vision, Robotics, Construction Automation, Machine Learning, Augmented Reality",DeepMapping: Unsupervised map estimation from multiple point clouds,"We propose DeepMapping, a novel registration framework using deep neural networks (DNNs) as auxiliary functions to align multiple point clouds from scratch to a globally consistent frame. We use DNNs to model the highly non-convex mapping process that traditionally involves hand-crafted data association, sensor pose initialization, and global refinement. Our key novelty is that"" training"" these DNNs with properly defined unsupervised losses is equivalent to solving the underlying registration problem, but less sensitive to good initialization than ICP. Our framework contains two DNNs: a localization network that estimates the poses for input point clouds, and a map network that models the scene structure by estimating the occupancy status of global coordinates. This allows us to convert the registration problem to a binary occupancy classification, which can be solved efficiently using gradient-based optimization. We further show that DeepMapping can be readily extended to address the problem of Lidar SLAM by imposing geometric constraints between consecutive point clouds. Experiments are conducted on both simulated and real datasets. Qualitative and quantitative comparisons demonstrate that DeepMapping often enables more robust and accurate global registration of multiple point clouds than existing techniques. Our code is available at https://ai4ce. github. io/DeepMapping/."
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Analysis of modeling effort and impact of different levels of detail in building information models,Description not available
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Strategic use of quality function deployment (QFD) in construction industry,Description not available
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Quantifying human experience in architectural spaces with integrated virtual reality and body sensor networks,"People spend more than 90% of their time indoors, making it essential to understand how the built environment can influence human experience and assess how the changes in architectural design features can impact this experience. Human experience in an architectural space is defined as the state of mind that is reflected on our physiological, emotional, and cognitive statuses. Previous studies attempted to explain the relation between architectural design features (e.g., the existence of daylight and connectivity to nature) and human experience. However, the extent of how different design features influence human experience has not been fully quantified yet. This study provides an integrated method that fuses virtual reality and noninvasive body area sensor networks (BSNs) to quantify human experience in architectural spaces. Using a set of biometric sensors, several physiological metrics such as skin …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Towards optimal control of air handling units using deep reinforcement learning and recurrent neural network,"Optimal control of heating, ventilation and air conditioning systems (HVACs) aims to minimize the energy consumption of equipment while maintaining the thermal comfort of occupants. Traditional rule-based control methods are not optimized for HVAC systems with continuous sensor readings and actuator controls. Recent developments in deep reinforcement learning (DRL) enabled control of HVACs with continuous sensor inputs and actions, while eliminating the need of building complex thermodynamic models. DRL control includes an environment, which approximates real-world HVAC operations; and an agent, that aims to achieve optimal control over the HVAC. Existing DRL control frameworks use simulation tools (e.g., EnergyPlus) to build DRL training environments with HVAC systems information, but oversimplify building geometrics. This study proposes a framework aiming to achieve optimal control over …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Technological assessment and process implications of field data capture technologies for construction and facility/infrastructure management,"Collection of accurate, complete and reliable field data is not only essential for active management of construction projects involving many tasks, such as material tracking, progress monitoring and quality assurance tasks; but also for facility/infrastructure management during the service life of facilities and infrastructure systems. Limitations of current manual data collection approaches in terms of speed, completeness and accuracy, and implications of these limitations for construction management practice are discussed by many researchers. Advancements in field data capture technologies (such as smart tags, laser scanners, and embedded sensors) enable collecting, storing and reusing field data accurately, completely and reliably. We show that while these technologies are capable of streamlining the associated processes, their performances differ from the manufacturers’ specifications when utilized on construction sites due to issues, such as interference, data reading range, data accuracy, interoperability of hardware and software, and memory limitations. In addition, while these technologies eliminate some non-value adding tasks associated with corresponding project management processes, they can also add new tasks that need to be performed prior to, during, or after the utilization of a technology at the field. Hence, a thorough understanding of both the technological capabilities and process implications of these technologies is needed to be able to utilize them effectively during construction and service life of facilities."
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Prediction of organizational effectiveness in construction companies,"Investigation of literature on organizational effectiveness (OE) reveals that the researchers have been in consensus for the difficulty of defining, modeling, and measuring OE, which is important for attaining high performance. Major focuses of this paper are, therefore, to construct a conceptual framework to model OE, to derive major determinants of OE from this framework, and to measure OE by constructing prediction models based on artificial neural network (ANN) and multiple regression (MR) techniques. Based on the proposed framework that investigates OE from the perspectives of organization and its subsystems, business, and macroenvironments, the most significant variables that determine OE have been collected and used as inputs for the two prediction models, which have been constructed by using the information associated with 116 Turkish construction companies obtained from a designed survey …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Modeling and analyzing the impact of technology on data capture and transfer processes at construction sites: a case study,"A detailed case study conducted at a highway construction project demonstrated that missing and inaccurate data items result in nonvalue adding (NVA) communication loops among the construction personnel. The implications (in terms of time and cost) of extra work associated with deficiencies in manual data collection and transfer are not well quantified. In this paper, a simulation-based framework is used to model information flow processes from a job site to a field office to measure and highlight existing deficiencies, and to model and demonstrate the effect of using automated reality capture technologies (laser scanners and radio frequency identification), in streamlining the data collection process for the same project. The simulation results showed that the NVA times of each agent involved in the information flow can be reduced by utilizing data collection technologies. This framework can be used by …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Towards quantifying human experience in the built environment: A crowdsourcing based experiment to identify influential architectural design features,"One of the main challenges in the quantification of the influence of architectural design features on human experience is to define the set of architectural design features that people notice immediately in a space as well as to define the type of influence these design features can have on people. Through a crowdsourced experiment, this study provides evidences on the architectural design features that people notice immediately in a space, preferences of people on the spaces configured with these features, and the influence level of these features on overall experience in spaces. Statistical analysis on around 400 subjects’ data show that certain features such as the openness of space, presence of windows and daylighting, flexibility in isolation/socialization, level of artificial lighting, density of spaces, and color of surfaces are easy to notice by people and are also powerful to change the human experience. The …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",A data-driven approach to extract operational signatures of HVAC systems and analyze impact on electricity consumption,"The electricity consumption of Heating Ventilating and Air Conditioning (HVAC) systems has a significant share in the energy consumption of buildings, which account for 75% of total electricity produced in the US. Therefore, improving the energy efficiency in HVAC systems is an essential goal in facility management (FM) industry. Building Automation Systems (BASs) deployed in buildings provide an enormous amount of data on HVAC operations, which can be leveraged to extract hidden knowledge and insights about operational signatures of these systems (i.e., parameter-value pairs set for running the equipment) and their relationship to energy profiles. This study aims to identify critical parameters of HVAC systems that drive the changes in the building energy-use profiles and develop an automated approach for identifying HVAC operational signatures and their energy profiles in buildings. The approach relies …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",An approach to combine progressively captured point clouds for BIM update,"Building information models (BIMs) provide opportunities to serve as an information repository to store and deliver as-built information. Since a building is not always constructed exactly as the design information specifies, there will be discrepancies between a BIM created in the design phase (called as-designed BIM) and the as-built conditions. Point clouds captured by laser scans can be used as a reference to update an as-designed BIM into an as-built BIM (i.e., the BIM that captures the as-built information). Occlusions and construction progress prevent a laser scan performed at a single point in time to capture a complete view of building components. Progressively scanning a building during the construction phase and combining the progressively captured point cloud data together can provide the geometric information missing in the point cloud data captured previously. However, combining all point cloud data …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",BIM for FM: Information requirements to support HVAC-related corrective maintenance,"Troubleshooting HVAC-related problems is one of the significant activities of facilities management (FM), in which the services directly affect occupants’ satisfaction, health, and productivity. Because of the complexity of modern HVAC systems and the lack of apparent causes when HVAC-related problems occur, HVAC mechanics need to collect various facility-specific information items to identify the real cause. The current practice lacks systematic approaches for identifying what specific facility information HVAC mechanics should check for in a given work order. Building information models (BIMs) have been used to exchange facilities’ lifecycle information, and automated approaches can be developed to retrieve required information for facility maintenance. The first step toward developing such an approach is to understand what information needs to be included in the BIMs that are used during the facility …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Design and Evaluation of an Integrated Visualization Platform to Support Corrective Maintenance of HVAC Problem–Related Work Orders,"HVAC mechanics need to know various information items about a facility and its building systems to troubleshoot HVAC-related problems. Whether HVAC mechanics can comprehend the situation and pinpoint the problem source in an efficient way is affected by how the required information is provided to them. This research study builds on the hypothesis that the visualization of the required information for HVAC mechanics can improve the time efficiency of the decision making for the troubleshooting process, and there is research needed to understand how much time efficiency can be achieved by visualization. Hence, this study utilizes a user-centered and iterative process to design and implement a visualization platform to support troubleshooting of HVAC-related problems. The final visualization platform is evaluated through user studies with quantitative metrics. The findings show that using the developed …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Leveraging BIM to Provide Automated Support for Efficient Troubleshooting of HVAC-Related Problems,"Prompt response and troubleshooting of HVAC-related problems in facilities are vital to ensure a comfortable indoor environment for occupants. Two main challenges in the current practice result in an ad hoc troubleshooting process and waste of resources: the lack of access to the required facility and system information in a timely manner and the large search space of possible causes for a given HVAC-related problem. This paper presents a formalized approach to bring solutions to these problems. The approach reasons with a facility-specific model-based information repository in order to identify an accurate set of applicable causes for a reported HVAC-related problem in the large search space of possible causes and to retrieve related facility and system information. By eliminating the inapplicable HVAC components and space-related factors for a reported problem, the approach increases the efficiency of the …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Contextual information requirements of cost estimators from past construction projects,"Past project data sources provide key information for construction cost estimators. Previous research studies show that relying only on one’s own experience during estimation results in estimators’ bias. Having and referring to historical databases, containing objective information on what happened in past projects, are essential for reducing estimators’ biases. The first step toward development of useful project history databases is to understand what information estimators require from past projects. The research described in this paper targets estimators’ information needs identified through interviews, brainstorming sessions, task analyses, and card games conducted with estimators with different experience levels and specialized in heavy/civil and commercial construction projects, and exploration of historical and standard databases available in companies to determine what is being currently represented …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Where do we look? An eye-tracking study of architectural features in building design,"Built environment plays an essential role in shaping the physical, physiological, and psychological human well-being given the fact that we spend more than ¾ of our times indoors. Various studies that investigated the impact of architecture on human health and well-being provided evidences on the influence of architecture with faster recovery in hospitals, better learning in schools, and more productivity in offices under variant configurations of architectural design features. This paper studied the impact of architectural design features (e.g., presence/size of windows, level of natural light and nature view) on human experience in buildings using a mobile eye-tracking solution to capture the subjects’ attention toward various design features. The subjects were exposed to two distinct virtual environments designed with polarizing features, and were instructed to conduct a series of navigational and informational …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",The need for prompt schedule update by utilizing reality capture technologies: A case study”,"Updating of construction schedules involves prompt and accurate capture of facts from a construction site for progress assessment and for learning from the assessment of site related facts to improve scheduling of upcoming activities. This paper discusses a case study being conducted on a highway construction project to understand the need for and the current practice of capturing, transferring and storing site related factual data for assessing the status of a project and of how this information is used in scheduling of upcoming activities. It highlights the challenges and opportunities for improvements observed in data collection and situation assessment processes. The case study findings are used as a basis for a discussion on possible ways of improving the current process by utilizing automated data capture technologies."
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Evaluation of visualization techniques for use by facility operators during monitoring tasks,"Facility operators interact with building automation systems (BASs) on a regular basis for various purposes such as facility maintenance, occupant comfort, equipment monitoring, safety and security. Evaluation of various BAS interfaces showed that there are challenges faced by facility operators that impede their efficiency and accuracy of their responses to reported situations. These challenges revolve mainly around the lack of spatial context for the monitored sensor readings and equipment statuses, and operators' information overloading. Various visualization techniques have been used in commercially available BASs, however, their impact on the situation awareness of facility operators is not clearly known. This study focuses on this need and evaluates various visualization techniques that best suit to the needs of facility operators. This study identifies visualization techniques that are applicable to encode …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Evaluation of different features for matching point clouds to building information models,"With the increased usage of building information models (BIMs) during construction, has BIM become a medium for delivering as-built building information. It is important to maintain accurate and up-to-date information stored in a BIM so that it can become a reliable data source throughout the service life of a facility. Laser scanning technology is able to capture accurate geometric data in the form of a point cloud and to depict the existing condition of a building. Hence, point cloud data captured by laser scans can be used as references to update a given BIM. An important step during the update process is to match segments of elements captured by a point cloud to building components modeled in a BIM, so that the discrepancies between the two data sets can be identified. Typically, features depicted within point cloud segments and BIM components are used in the matching process. However, understanding is …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Proactive productivity management at job sites: Understanding characteristics of assumptions made for construction processes during planning based on case studies and interviews,"During planning and execution of construction projects, project planners and managers make various assumptions with respect to execution of construction activities, availability of resources, suitability of construction methods, and status of preceding activities. However, not all of these assumptions are explicitly documented and verified before the construction activities start. Decisions made based on invalid assumptions can negatively impact the outcomes of construction projects, such as rework, activity delays, and extra material cost. To address the problems caused by invalid assumptions, this paper proposed to develop a formal approach to capture and represent assumptions and proactively verify assumptions to reduce the uncertainties associated with construction projects. To develop such a formal approach, an initial step is to identify characteristics of assumptions. The research team conducted two detailed …"
Semiha Ergan,https://scholar.google.com/citations?user=WYwmI0wAAAAJ&hl=en,"Construction automation, Digital twins, AI, AR/VR visualization",Owner requirements in as-built BIM deliverables and a system architecture for FM-specific BIM representation,"Construction models received by owners typically include the details of components required for construction activities; yet at the same time, they might not be in the right geometric representation for facilities management (FM) tasks. There is a need to customize BIMs for each FM task and eliminate unnecessary data in models for that task. The objective of this work is to identify information items that should be included in BIMs to support specific FM tasks and the level of geometric details of components to be represented in BIMs. The research focuses on supporting four major FM tasks as corrective and preventive maintenance management, asset management on HVAC systems, and space management tasks. This paper also provides a system architecture to enable reducing content of BIMs for FM tasks. Contributions will help practitioners to use facility data from a life cycle perspective through BIM."
